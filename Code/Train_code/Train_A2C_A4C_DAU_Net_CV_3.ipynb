{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:24.997255Z",
     "start_time": "2021-12-07T06:13:22.797931Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.python.keras.models import *\n",
    "\n",
    "from tensorflow.python.keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:25.024802Z",
     "start_time": "2021-12-07T06:13:25.000030Z"
    }
   },
   "outputs": [],
   "source": [
    "epsilon = K.epsilon()\n",
    "gamma = 0\n",
    "alpha = 0.6\n",
    "beta = 0.6\n",
    "\n",
    "  \n",
    "def recall(y_true, y_pred):\n",
    "\n",
    "    y_true_yn = K.round(K.clip(y_true, 0, 1))\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "    count_true_positive = K.sum(y_true_yn * y_pred_yn)     \n",
    "    count_true_positive_false_negative = K.sum(y_true_yn)\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_true_yn = K.round(K.clip(y_true, 0, 1))\n",
    "    count_true_positive = K.sum(y_true_yn * y_pred_yn) \n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    _recall = recall(y_true, y_pred)\n",
    "    _precision = precision(y_true, y_pred)\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "\n",
    "    return _f1score\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def balanced_loss(y_true, y_pred):\n",
    "    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n",
    "    pt = K.clip(pt, epsilon, 1-epsilon)\n",
    "    CE = -K.log(pt)\n",
    "    BL = alpha * CE\n",
    "    \n",
    "    return K.sum(BL, axis=1)\n",
    "\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n",
    "    pt = K.clip(pt, epsilon, 1-epsilon)\n",
    "    CE = -K.log(pt)\n",
    "    FL = alpha * K.pow(1-pt, gamma) * CE\n",
    "    \n",
    "    return K.sum(FL, axis=1)\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=0.001):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def cus_loss(y_true, y_pred):\n",
    "    \n",
    "    return (1 - beta) * focal_loss(y_true, y_pred) + beta * dice_coef_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "get_custom_objects().update({\n",
    "    \n",
    "    'cus_loss': cus_loss,\n",
    "    'iou_coef' : iou_coef,\n",
    "    'f1score' : f1score,\n",
    "    'precision' : precision,\n",
    "    'recall' : recall,\n",
    "    'balanced_loss' : balanced_loss,\n",
    "    'focal_loss' : focal_loss,\n",
    "    'dice_coef' : dice_coef,\n",
    "    'dice_coef_loss' : dice_coef_loss,\n",
    "    'cus_loss' : cus_loss,\n",
    "        \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:35.373883Z",
     "start_time": "2021-12-07T06:13:25.029399Z"
    }
   },
   "outputs": [],
   "source": [
    "train_a2c_image = np.load('../../data/dataset/train/train_A2C_image.npy').astype(np.float32)\n",
    "train_a2c_label = np.load('../../data/dataset/train/train_A2C_label.npy').astype(np.float32)\n",
    "\n",
    "train_a4c_image = np.load('../../data/dataset/train/train_A4C_image.npy').astype(np.float32)\n",
    "train_a4c_label = np.load('../../data/dataset/train/train_A4C_label.npy').astype(np.float32)\n",
    "\n",
    "\n",
    "test_a2c_image = np.load('../../data/dataset/test/test_A2C_image.npy').astype(np.float32)\n",
    "test_a2c_label = np.load('../../data/dataset/test/test_A2C_label.npy').astype(np.float32)\n",
    "\n",
    "test_a4c_image = np.load('../../data/dataset/test/test_A4C_image.npy').astype(np.float32)\n",
    "test_a4c_label = np.load('../../data/dataset/test/test_A4C_label.npy').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:37.014321Z",
     "start_time": "2021-12-07T06:13:35.375797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 255.0\n",
      "0.0 1.0\n",
      "0.0 255.0\n",
      "0.0 1.0\n",
      "0.0 255.0\n",
      "0.0 1.0\n",
      "0.0 255.0\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(train_a2c_image.min(), train_a2c_image.max())\n",
    "print(train_a2c_label.min(), train_a2c_label.max())\n",
    "\n",
    "\n",
    "print(train_a4c_image.min(), train_a4c_image.max())\n",
    "print(train_a4c_label.min(), train_a4c_label.max())\n",
    "\n",
    "\n",
    "print(test_a2c_image.min(), test_a2c_image.max())\n",
    "print(test_a2c_label.min(), test_a2c_label.max())\n",
    "\n",
    "\n",
    "print(test_a4c_image.min(), test_a4c_image.max())\n",
    "print(test_a4c_label.min(), test_a4c_label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:40.257181Z",
     "start_time": "2021-12-07T06:13:37.015909Z"
    }
   },
   "outputs": [],
   "source": [
    "train_a2c_image = train_a2c_image / 255\n",
    "train_a4c_image = train_a4c_image / 255\n",
    "\n",
    "test_a2c_image = test_a2c_image / 255\n",
    "test_a4c_image = test_a4c_image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:41.894301Z",
     "start_time": "2021-12-07T06:13:40.258729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(train_a2c_image.min(), train_a2c_image.max())\n",
    "print(train_a2c_label.min(), train_a2c_label.max())\n",
    "\n",
    "\n",
    "print(train_a4c_image.min(), train_a4c_image.max())\n",
    "print(train_a4c_label.min(), train_a4c_label.max())\n",
    "\n",
    "\n",
    "print(test_a2c_image.min(), test_a2c_image.max())\n",
    "print(test_a2c_label.min(), test_a2c_label.max())\n",
    "\n",
    "\n",
    "print(test_a4c_image.min(), test_a4c_image.max())\n",
    "print(test_a4c_label.min(), test_a4c_label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:41.905614Z",
     "start_time": "2021-12-07T06:13:41.897353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 512, 512, 1)\n",
      "(800, 512, 512, 1)\n",
      "(800, 512, 512, 1)\n",
      "(800, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_a2c_image.shape)\n",
    "print(train_a2c_label.shape)\n",
    "\n",
    "\n",
    "print(train_a4c_image.shape)\n",
    "print(train_a4c_label.shape)\n",
    "\n",
    "\n",
    "print(test_a2c_image.shape)\n",
    "print(test_a2c_label.shape)\n",
    "\n",
    "\n",
    "print(test_a4c_image.shape)\n",
    "print(test_a4c_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:41.930600Z",
     "start_time": "2021-12-07T06:13:41.908693Z"
    }
   },
   "outputs": [],
   "source": [
    "all_train_image = np.zeros((800,512,512,1,2))\n",
    "all_train_label = np.zeros((800,512,512,1,2))\n",
    "\n",
    "test_image = np.zeros((100,512,512,1,2))\n",
    "test_label = np.zeros((100,512,512,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.324123Z",
     "start_time": "2021-12-07T06:13:41.936156Z"
    }
   },
   "outputs": [],
   "source": [
    "all_train_image[:,:,:,:,0] = train_a2c_image\n",
    "all_train_image[:,:,:,:,1] = train_a4c_image\n",
    "\n",
    "all_train_label[:,:,:,:,0] = train_a2c_label\n",
    "all_train_label[:,:,:,:,1] = train_a4c_label\n",
    "\n",
    "test_image[:,:,:,:,0] = test_a2c_image\n",
    "test_image[:,:,:,:,1] = test_a4c_image\n",
    "\n",
    "test_label[:,:,:,:,0] = test_a2c_label\n",
    "test_label[:,:,:,:,1] = test_a4c_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.333848Z",
     "start_time": "2021-12-07T06:13:43.328380Z"
    }
   },
   "outputs": [],
   "source": [
    "train_image_fold_1 = all_train_image[:200]\n",
    "train_image_fold_2 = all_train_image[200:400]\n",
    "train_image_fold_3 = all_train_image[400:600]\n",
    "train_image_fold_4 = all_train_image[600:]\n",
    "\n",
    "\n",
    "train_label_fold_1 = all_train_label[:200]\n",
    "train_label_fold_2 = all_train_label[200:400]\n",
    "train_label_fold_3 = all_train_label[400:600]\n",
    "train_label_fold_4 = all_train_label[600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.364165Z",
     "start_time": "2021-12-07T06:13:43.338157Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CV1\n",
    "# train_image = np.concatenate((train_image_fold_1, train_image_fold_2, train_image_fold_3), axis =0)\n",
    "# train_label = np.concatenate((train_label_fold_1, train_label_fold_2, train_label_fold_3), axis =0)\n",
    "\n",
    "# validation_image = train_image_fold_4\n",
    "# validation_label = train_label_fold_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.380579Z",
     "start_time": "2021-12-07T06:13:43.368707Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CV2\n",
    "# train_image = np.concatenate((train_image_fold_1, train_image_fold_2, train_image_fold_4), axis =0)\n",
    "# train_label = np.concatenate((train_label_fold_1, train_label_fold_2, train_label_fold_4), axis =0)\n",
    "\n",
    "# validation_image = train_image_fold_3\n",
    "# validation_label = train_label_fold_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.163284Z",
     "start_time": "2021-12-07T06:13:43.385479Z"
    }
   },
   "outputs": [],
   "source": [
    "# CV3\n",
    "train_image = np.concatenate((train_image_fold_1, train_image_fold_3, train_image_fold_4), axis =0)\n",
    "train_label = np.concatenate((train_label_fold_1, train_label_fold_3, train_label_fold_4), axis =0)\n",
    "\n",
    "validation_image = train_image_fold_2\n",
    "validation_label = train_label_fold_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.167165Z",
     "start_time": "2021-12-07T06:13:44.164859Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CV4\n",
    "# train_image = np.concatenate((train_image_fold_2, train_image_fold_3, train_image_fold_4), axis =0)\n",
    "# train_label = np.concatenate((train_label_fold_2, train_label_fold_3, train_label_fold_4), axis =0)\n",
    "\n",
    "# validation_image = train_image_fold_1\n",
    "# validation_label = train_label_fold_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.196829Z",
     "start_time": "2021-12-07T06:13:44.169585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 512, 512, 1, 2)\n",
      "(600, 512, 512, 1, 2)\n",
      "(200, 512, 512, 1, 2)\n",
      "(200, 512, 512, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_image.shape)\n",
    "print(train_label.shape)\n",
    "\n",
    "print(validation_image.shape)\n",
    "print(validation_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.214536Z",
     "start_time": "2021-12-07T06:13:44.198529Z"
    }
   },
   "outputs": [],
   "source": [
    "def Conv2D_block(input_layer, out_n_filters, kernel_size=[3,3], stride=[1,1], padding='same'):\n",
    "    \n",
    "    layer = input_layer\n",
    "    \n",
    "    for i in range(2):\n",
    "        \n",
    "        layer = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, kernel_initializer = 'he_normal')(layer)\n",
    "        layer = BatchNormalization()(layer)\n",
    "        layer = Activation('relu')(layer)        \n",
    "        \n",
    "    out_layer = layer\n",
    "    \n",
    "    return out_layer\n",
    "    \n",
    "\n",
    "def Up_and_Concate(down_layer, layer):\n",
    "    \n",
    "    input_channel = down_layer.get_shape().as_list()[3]\n",
    "    output_channel = input_channel // 2\n",
    "    \n",
    "    up = UpSampling2D(size = (2,2))(down_layer) \n",
    "\n",
    "    concate = concatenate([up, layer])\n",
    "    return concate\n",
    "\n",
    "def attention_block_2d(x, g, inter_channel):\n",
    "\n",
    "\n",
    "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1])(x)\n",
    "\n",
    "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1])(g)\n",
    "\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "\n",
    "\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1])(f)\n",
    "\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "\n",
    "\n",
    "    att_x = multiply([x, rate])\n",
    "\n",
    "    return att_x\n",
    "\n",
    "\n",
    "def attention_up_and_concate(down_layer, layer):\n",
    "    in_channel = down_layer.get_shape().as_list()[3]\n",
    "\n",
    "    up = UpSampling2D((2, 2))(down_layer)\n",
    "\n",
    "    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4)\n",
    "\n",
    "    concate = concatenate([up, layer])\n",
    "    \n",
    "    return concate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.228745Z",
     "start_time": "2021-12-07T06:13:44.216092Z"
    }
   },
   "outputs": [],
   "source": [
    "def AU_Net_2D(input_shape):\n",
    "        \n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    depth = 4\n",
    "    features = 32\n",
    "    down_layer = []\n",
    "    supervision_layer = []\n",
    "    \n",
    "    for i in range(depth):\n",
    "        \n",
    "        x = Conv2D_block(x, features)\n",
    "        down_layer.append(x)\n",
    "        x = MaxPooling2D(pool_size=[2, 2], strides=[2, 2])(x)\n",
    "\n",
    "        features = features * 2\n",
    "        \n",
    "    x = Conv2D_block(x, features)\n",
    "    \n",
    "    for i in reversed(range(depth)):\n",
    "\n",
    "        features = features // 2\n",
    "        \n",
    "        x = attention_up_and_concate(x, down_layer[i])\n",
    "        x = Conv2D_block(x, features)\n",
    "        supervision_layer.append(x)\n",
    "    \n",
    "    \n",
    "\n",
    "    output_2 = UpSampling2D((4, 4))(supervision_layer[1])\n",
    "    output_4 = UpSampling2D((1, 1))(supervision_layer[3])\n",
    "    \n",
    "\n",
    "    model = Model(inputs = inputs, outputs = [output_2, output_4])\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:45.609394Z",
     "start_time": "2021-12-07T06:13:44.232428Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1207 15:13:44.271050 135054965557392 deprecation.py:506] From /opt/anaconda3/envs/powerai_162/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 32) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512, 512, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 32) 9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 256, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 64) 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 128 147584      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 128 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 256)  590080      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 512)  2359808     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 512)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 64, 64, 512)  0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  32896       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  65664       up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 128)  0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 1)    129         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 1)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 64, 64, 256)  0           activation_7[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 768)  0           up_sampling2d[0][0]              \n",
      "                                                                 multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  1769728     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 256)  1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 256)  1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 256 0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 64) 8256        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 64) 16448       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 64) 0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 64) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 1)  65          activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 128, 1)  0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 128, 128, 128 0           activation_5[0][0]               \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 384 0           up_sampling2d_1[0][0]            \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 442496      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 128 512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 128, 128, 128 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 128 147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 128 512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128, 128, 128 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 128 0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 32) 2080        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 32) 4128        up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 256, 32) 0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 256, 256, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 1)  33          activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 256, 256, 1)  0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 256, 256, 64) 0           activation_3[0][0]               \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 192 0           up_sampling2d_2[0][0]            \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 64) 110656      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256, 256, 64) 256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 256, 256, 64) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 64) 36928       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 64) 256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 256, 256, 64) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 512, 512, 64) 0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 512, 512, 16) 528         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 512, 512, 16) 1040        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 512, 512, 16) 0           conv2d_25[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 512, 512, 16) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 512, 512, 1)  17          activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 512, 512, 1)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 512, 512, 32) 0           activation_1[0][0]               \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 96) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 512, 512, 32) 27680       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 512, 512, 32) 128         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 512, 512, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 512, 512, 32) 9248        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 512, 32) 128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 512, 512, 32) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 512, 512, 128 0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 512, 512, 32) 0           activation_25[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 7,989,108\n",
      "Trainable params: 7,983,220\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = AU_Net_2D((512,512,1))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:45.621782Z",
     "start_time": "2021-12-07T06:13:45.610900Z"
    }
   },
   "outputs": [],
   "source": [
    "def Multi_View_AU_Net():\n",
    "    \n",
    "    inputs = Input(shape=(512,512,1,2), name='input')\n",
    "    \n",
    "    a2c_view = inputs[:, :, :, :, 0]\n",
    "    a4c_view = inputs[:, :, :, :, 1]\n",
    "    \n",
    "    base_model = AU_Net_2D(input_shape = (512,512,1))\n",
    "    \n",
    "    a2c_view_output_2, a2c_view_output_4 = base_model(a2c_view)\n",
    "    a4c_view_output_2, a4c_view_output_4 = base_model(a4c_view)\n",
    "    \n",
    "    \n",
    "    output_2 = Concatenate()([a2c_view_output_2, a4c_view_output_2])\n",
    "    output_4 = Concatenate()([a2c_view_output_4, a4c_view_output_4])\n",
    "\n",
    "    \n",
    "    fn_output_2 = Dense(32)(output_2)\n",
    "    fn_output_2 = Dropout(0.25)(fn_output_2)\n",
    "    fn_output_2 = Dense(2)(fn_output_2)\n",
    "    \n",
    "    \n",
    "    fn_output_4 = Dense(32)(output_4)\n",
    "    fn_output_4 = Dropout(0.25)(fn_output_4)\n",
    "    fn_output_4 = Dense(2)(fn_output_4)\n",
    "    \n",
    "    \n",
    "\n",
    "    fn_output_2 = K.expand_dims(fn_output_2, 3)\n",
    "    fn_output_4 = K.expand_dims(fn_output_4, 3)\n",
    "    \n",
    "\n",
    "    fn_output_2 = Activation('sigmoid', name='out_2')(fn_output_2)\n",
    "    fn_output_4 = Activation('sigmoid', name='out_4')(fn_output_4)\n",
    "\n",
    "\n",
    "    MVAU_Net = keras.Model(inputs = inputs, outputs = [fn_output_2, fn_output_4], name='MV_AU_Net')\n",
    "\n",
    "    \n",
    "    return MVAU_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:14:25.674286Z",
     "start_time": "2021-12-07T06:13:45.623056Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1207 15:13:46.927398 135054965557392 backend.py:548] OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MV_AU_Net\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input (InputLayer)                               [(None, 512, 512, 1, 2)]         0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (TensorFlowOpLayer)    [(None, 512, 512, 1)]            0                 input[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (TensorFlowOpLayer)  [(None, 512, 512, 1)]            0                 input[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "model_1 (Model)                                  [(None, 512, 512, 128), (None, 5 7989108           tf_op_layer_strided_slice[0][0]                   \n",
      "                                                                                                    tf_op_layer_strided_slice_1[0][0]                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)                      (None, 512, 512, 256)            0                 model_1[1][0]                                     \n",
      "                                                                                                    model_1[2][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)                      (None, 512, 512, 64)             0                 model_1[1][1]                                     \n",
      "                                                                                                    model_1[2][1]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense (Dense)                                    (None, 512, 512, 32)             8224              concatenate_8[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_2 (Dense)                                  (None, 512, 512, 32)             2080              concatenate_9[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dropout (Dropout)                                (None, 512, 512, 32)             0                 dense[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                              (None, 512, 512, 32)             0                 dense_2[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_1 (Dense)                                  (None, 512, 512, 2)              66                dropout[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_3 (Dense)                                  (None, 512, 512, 2)              66                dropout_1[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorFlowOpLayer)       [(None, 512, 512, 1, 2)]         0                 dense_1[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (TensorFlowOpLayer)     [(None, 512, 512, 1, 2)]         0                 dense_3[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "out_2 (Activation)                               (None, 512, 512, 1, 2)           0                 tf_op_layer_ExpandDims[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "out_4 (Activation)                               (None, 512, 512, 1, 2)           0                 tf_op_layer_ExpandDims_1[0][0]                    \n",
      "======================================================================================================================================================\n",
      "Total params: 7,999,544\n",
      "Trainable params: 7,993,656\n",
      "Non-trainable params: 5,888\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MVAU_Net = Multi_View_AU_Net()\n",
    "MVAU_Net.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:14:25.780623Z",
     "start_time": "2021-12-07T06:14:25.676258Z"
    }
   },
   "outputs": [],
   "source": [
    "losses ={'out_2':dice_coef_loss,\n",
    "         'out_4':dice_coef_loss}\n",
    "\n",
    "MVAU_Net.compile(optimizer=Adam(lr=0.001), loss = losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:14:25.785597Z",
     "start_time": "2021-12-07T06:14:25.782152Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-8)\n",
    "earlystopper = EarlyStopping(monitor='loss',patience=30, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5', monitor='loss', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks_list = [model_checkpoint, earlystopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:46:58.621195Z",
     "start_time": "2021-12-07T06:14:25.786845Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train on 600 samples\n",
      "Epoch 1/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.5265 - out_2_loss: 0.2434 - out_4_loss: 0.2831\n",
      "Epoch 00001: loss improved from inf to 0.52447, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 65s 108ms/sample - loss: 0.5245 - out_2_loss: 0.2425 - out_4_loss: 0.2820\n",
      "Epoch 2/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.2252 - out_2_loss: 0.1125 - out_4_loss: 0.1127\n",
      "Epoch 00002: loss improved from 0.52447 to 0.22476, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.2248 - out_2_loss: 0.1123 - out_4_loss: 0.1124\n",
      "Epoch 3/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1869 - out_2_loss: 0.0941 - out_4_loss: 0.0927\n",
      "Epoch 00003: loss improved from 0.22476 to 0.18644, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.1864 - out_2_loss: 0.0939 - out_4_loss: 0.0925\n",
      "Epoch 4/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1728 - out_2_loss: 0.0872 - out_4_loss: 0.0855\n",
      "Epoch 00004: loss improved from 0.18644 to 0.17295, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.1729 - out_2_loss: 0.0873 - out_4_loss: 0.0857\n",
      "Epoch 5/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1510 - out_2_loss: 0.0767 - out_4_loss: 0.0743\n",
      "Epoch 00005: loss improved from 0.17295 to 0.15124, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.1512 - out_2_loss: 0.0768 - out_4_loss: 0.0744\n",
      "Epoch 6/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1436 - out_2_loss: 0.0731 - out_4_loss: 0.0706\n",
      "Epoch 00006: loss improved from 0.15124 to 0.14346, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 57s 96ms/sample - loss: 0.1435 - out_2_loss: 0.0730 - out_4_loss: 0.0705\n",
      "Epoch 7/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1323 - out_2_loss: 0.0677 - out_4_loss: 0.0646\n",
      "Epoch 00007: loss improved from 0.14346 to 0.13215, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.1321 - out_2_loss: 0.0677 - out_4_loss: 0.0645\n",
      "Epoch 8/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1314 - out_2_loss: 0.0672 - out_4_loss: 0.0642\n",
      "Epoch 00008: loss improved from 0.13215 to 0.13119, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.1312 - out_2_loss: 0.0671 - out_4_loss: 0.0641\n",
      "Epoch 9/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1311 - out_2_loss: 0.0670 - out_4_loss: 0.0642\n",
      "Epoch 00009: loss did not improve from 0.13119\n",
      "600/600 [==============================] - 54s 91ms/sample - loss: 0.1312 - out_2_loss: 0.0670 - out_4_loss: 0.0642\n",
      "Epoch 10/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1188 - out_2_loss: 0.0612 - out_4_loss: 0.0576\n",
      "Epoch 00010: loss improved from 0.13119 to 0.11859, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.1186 - out_2_loss: 0.0611 - out_4_loss: 0.0575\n",
      "Epoch 11/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1193 - out_2_loss: 0.0614 - out_4_loss: 0.0579\n",
      "Epoch 00011: loss did not improve from 0.11859\n",
      "600/600 [==============================] - 57s 96ms/sample - loss: 0.1193 - out_2_loss: 0.0614 - out_4_loss: 0.0579\n",
      "Epoch 12/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1217 - out_2_loss: 0.0624 - out_4_loss: 0.0594\n",
      "Epoch 00012: loss did not improve from 0.11859\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.1216 - out_2_loss: 0.0623 - out_4_loss: 0.0593\n",
      "Epoch 13/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1070 - out_2_loss: 0.0556 - out_4_loss: 0.0515\n",
      "Epoch 00013: loss improved from 0.11859 to 0.10685, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.1069 - out_2_loss: 0.0555 - out_4_loss: 0.0514\n",
      "Epoch 14/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1051 - out_2_loss: 0.0546 - out_4_loss: 0.0504\n",
      "Epoch 00014: loss improved from 0.10685 to 0.10505, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.1050 - out_2_loss: 0.0546 - out_4_loss: 0.0504\n",
      "Epoch 15/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0993 - out_2_loss: 0.0518 - out_4_loss: 0.0475\n",
      "Epoch 00015: loss improved from 0.10505 to 0.09913, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0991 - out_2_loss: 0.0517 - out_4_loss: 0.0474\n",
      "Epoch 16/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0991 - out_2_loss: 0.0517 - out_4_loss: 0.0474\n",
      "Epoch 00016: loss improved from 0.09913 to 0.09890, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0989 - out_2_loss: 0.0516 - out_4_loss: 0.0473\n",
      "Epoch 17/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0993 - out_2_loss: 0.0518 - out_4_loss: 0.0475\n",
      "Epoch 00017: loss did not improve from 0.09890\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0994 - out_2_loss: 0.0519 - out_4_loss: 0.0475\n",
      "Epoch 18/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0992 - out_2_loss: 0.0517 - out_4_loss: 0.0475\n",
      "Epoch 00018: loss did not improve from 0.09890\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0992 - out_2_loss: 0.0517 - out_4_loss: 0.0475\n",
      "Epoch 19/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0943 - out_2_loss: 0.0494 - out_4_loss: 0.0449\n",
      "Epoch 00019: loss improved from 0.09890 to 0.09435, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0944 - out_2_loss: 0.0494 - out_4_loss: 0.0449\n",
      "Epoch 20/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0935 - out_2_loss: 0.0491 - out_4_loss: 0.0443\n",
      "Epoch 00020: loss improved from 0.09435 to 0.09353, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0935 - out_2_loss: 0.0492 - out_4_loss: 0.0444\n",
      "Epoch 21/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0892 - out_2_loss: 0.0470 - out_4_loss: 0.0423\n",
      "Epoch 00021: loss improved from 0.09353 to 0.08909, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0891 - out_2_loss: 0.0469 - out_4_loss: 0.0422\n",
      "Epoch 22/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0853 - out_2_loss: 0.0452 - out_4_loss: 0.0402\n",
      "Epoch 00022: loss improved from 0.08909 to 0.08527, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0853 - out_2_loss: 0.0451 - out_4_loss: 0.0401\n",
      "Epoch 23/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0866 - out_2_loss: 0.0457 - out_4_loss: 0.0409\n",
      "Epoch 00023: loss did not improve from 0.08527\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0865 - out_2_loss: 0.0457 - out_4_loss: 0.0408\n",
      "Epoch 24/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0851 - out_2_loss: 0.0449 - out_4_loss: 0.0401\n",
      "Epoch 00024: loss improved from 0.08527 to 0.08507, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0851 - out_2_loss: 0.0449 - out_4_loss: 0.0402\n",
      "Epoch 25/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0789 - out_2_loss: 0.0421 - out_4_loss: 0.0368\n",
      "Epoch 00025: loss improved from 0.08507 to 0.07897, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0790 - out_2_loss: 0.0421 - out_4_loss: 0.0369\n",
      "Epoch 26/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0837 - out_2_loss: 0.0444 - out_4_loss: 0.0393\n",
      "Epoch 00026: loss did not improve from 0.07897\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0839 - out_2_loss: 0.0445 - out_4_loss: 0.0394\n",
      "Epoch 27/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0777 - out_2_loss: 0.0415 - out_4_loss: 0.0362\n",
      "Epoch 00027: loss improved from 0.07897 to 0.07755, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0775 - out_2_loss: 0.0414 - out_4_loss: 0.0361\n",
      "Epoch 28/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0731 - out_2_loss: 0.0393 - out_4_loss: 0.0338\n",
      "Epoch 00028: loss improved from 0.07755 to 0.07296, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0730 - out_2_loss: 0.0393 - out_4_loss: 0.0337\n",
      "Epoch 29/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0732 - out_2_loss: 0.0393 - out_4_loss: 0.0338\n",
      "Epoch 00029: loss did not improve from 0.07296\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0731 - out_2_loss: 0.0393 - out_4_loss: 0.0338\n",
      "Epoch 30/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0726 - out_2_loss: 0.0390 - out_4_loss: 0.0335\n",
      "Epoch 00030: loss improved from 0.07296 to 0.07256, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0726 - out_2_loss: 0.0390 - out_4_loss: 0.0335\n",
      "Epoch 31/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0724 - out_2_loss: 0.0390 - out_4_loss: 0.0334\n",
      "Epoch 00031: loss improved from 0.07256 to 0.07229, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 57s 96ms/sample - loss: 0.0723 - out_2_loss: 0.0389 - out_4_loss: 0.0334\n",
      "Epoch 32/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0696 - out_2_loss: 0.0376 - out_4_loss: 0.0320\n",
      "Epoch 00032: loss improved from 0.07229 to 0.06960, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0696 - out_2_loss: 0.0376 - out_4_loss: 0.0320\n",
      "Epoch 33/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0650 - out_2_loss: 0.0355 - out_4_loss: 0.0295\n",
      "Epoch 00033: loss improved from 0.06960 to 0.06488, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0649 - out_2_loss: 0.0354 - out_4_loss: 0.0295\n",
      "Epoch 34/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0644 - out_2_loss: 0.0352 - out_4_loss: 0.0292\n",
      "Epoch 00034: loss improved from 0.06488 to 0.06451, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0645 - out_2_loss: 0.0353 - out_4_loss: 0.0292\n",
      "Epoch 35/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0605 - out_2_loss: 0.0334 - out_4_loss: 0.0271\n",
      "Epoch 00035: loss improved from 0.06451 to 0.06051, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 54s 91ms/sample - loss: 0.0605 - out_2_loss: 0.0334 - out_4_loss: 0.0271\n",
      "Epoch 36/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0588 - out_2_loss: 0.0326 - out_4_loss: 0.0262\n",
      "Epoch 00036: loss improved from 0.06051 to 0.05878, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0588 - out_2_loss: 0.0326 - out_4_loss: 0.0262\n",
      "Epoch 37/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0591 - out_2_loss: 0.0327 - out_4_loss: 0.0264\n",
      "Epoch 00037: loss did not improve from 0.05878\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0591 - out_2_loss: 0.0327 - out_4_loss: 0.0264\n",
      "Epoch 38/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0574 - out_2_loss: 0.0320 - out_4_loss: 0.0254\n",
      "Epoch 00038: loss improved from 0.05878 to 0.05734, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 54s 91ms/sample - loss: 0.0573 - out_2_loss: 0.0319 - out_4_loss: 0.0254\n",
      "Epoch 39/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0562 - out_2_loss: 0.0314 - out_4_loss: 0.0248\n",
      "Epoch 00039: loss improved from 0.05734 to 0.05628, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0563 - out_2_loss: 0.0314 - out_4_loss: 0.0249\n",
      "Epoch 40/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0599 - out_2_loss: 0.0332 - out_4_loss: 0.0267\n",
      "Epoch 00040: loss did not improve from 0.05628\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0599 - out_2_loss: 0.0332 - out_4_loss: 0.0267\n",
      "Epoch 41/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0798 - out_2_loss: 0.0424 - out_4_loss: 0.0374\n",
      "Epoch 00041: loss did not improve from 0.05628\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0799 - out_2_loss: 0.0424 - out_4_loss: 0.0375\n",
      "Epoch 42/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0623 - out_2_loss: 0.0342 - out_4_loss: 0.0280\n",
      "Epoch 00042: loss did not improve from 0.05628\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0621 - out_2_loss: 0.0342 - out_4_loss: 0.0280\n",
      "Epoch 43/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0525 - out_2_loss: 0.0297 - out_4_loss: 0.0228\n",
      "Epoch 00043: loss improved from 0.05628 to 0.05262, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0526 - out_2_loss: 0.0298 - out_4_loss: 0.0228\n",
      "Epoch 44/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0492 - out_2_loss: 0.0283 - out_4_loss: 0.0209\n",
      "Epoch 00044: loss improved from 0.05262 to 0.04919, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0492 - out_2_loss: 0.0283 - out_4_loss: 0.0209\n",
      "Epoch 45/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0480 - out_2_loss: 0.0278 - out_4_loss: 0.0202\n",
      "Epoch 00045: loss improved from 0.04919 to 0.04797, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0480 - out_2_loss: 0.0278 - out_4_loss: 0.0202\n",
      "Epoch 46/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0476 - out_2_loss: 0.0276 - out_4_loss: 0.0200\n",
      "Epoch 00046: loss improved from 0.04797 to 0.04762, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0476 - out_2_loss: 0.0276 - out_4_loss: 0.0200\n",
      "Epoch 47/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0473 - out_2_loss: 0.0274 - out_4_loss: 0.0199\n",
      "Epoch 00047: loss improved from 0.04762 to 0.04740, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0474 - out_2_loss: 0.0275 - out_4_loss: 0.0199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0468 - out_2_loss: 0.0272 - out_4_loss: 0.0196\n",
      "Epoch 00048: loss improved from 0.04740 to 0.04678, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0468 - out_2_loss: 0.0272 - out_4_loss: 0.0196\n",
      "Epoch 49/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0471 - out_2_loss: 0.0273 - out_4_loss: 0.0198\n",
      "Epoch 00049: loss did not improve from 0.04678\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0472 - out_2_loss: 0.0274 - out_4_loss: 0.0198\n",
      "Epoch 50/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0443 - out_2_loss: 0.0262 - out_4_loss: 0.0181\n",
      "Epoch 00050: loss improved from 0.04678 to 0.04441, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0444 - out_2_loss: 0.0262 - out_4_loss: 0.0182\n",
      "Epoch 51/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0439 - out_2_loss: 0.0259 - out_4_loss: 0.0180\n",
      "Epoch 00051: loss improved from 0.04441 to 0.04390, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0439 - out_2_loss: 0.0259 - out_4_loss: 0.0180\n",
      "Epoch 52/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0433 - out_2_loss: 0.0257 - out_4_loss: 0.0176\n",
      "Epoch 00052: loss improved from 0.04390 to 0.04330, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0433 - out_2_loss: 0.0257 - out_4_loss: 0.0176\n",
      "Epoch 53/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0432 - out_2_loss: 0.0257 - out_4_loss: 0.0175\n",
      "Epoch 00053: loss improved from 0.04330 to 0.04321, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0432 - out_2_loss: 0.0257 - out_4_loss: 0.0175\n",
      "Epoch 54/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0422 - out_2_loss: 0.0253 - out_4_loss: 0.0170\n",
      "Epoch 00054: loss improved from 0.04321 to 0.04226, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 54s 91ms/sample - loss: 0.0423 - out_2_loss: 0.0253 - out_4_loss: 0.0170\n",
      "Epoch 55/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0443 - out_2_loss: 0.0261 - out_4_loss: 0.0182\n",
      "Epoch 00055: loss did not improve from 0.04226\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0443 - out_2_loss: 0.0261 - out_4_loss: 0.0182\n",
      "Epoch 56/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0427 - out_2_loss: 0.0255 - out_4_loss: 0.0172\n",
      "Epoch 00056: loss did not improve from 0.04226\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0429 - out_2_loss: 0.0256 - out_4_loss: 0.0173\n",
      "Epoch 57/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0430 - out_2_loss: 0.0255 - out_4_loss: 0.0175\n",
      "Epoch 00057: loss did not improve from 0.04226\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0430 - out_2_loss: 0.0255 - out_4_loss: 0.0175\n",
      "Epoch 58/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0428 - out_2_loss: 0.0254 - out_4_loss: 0.0174\n",
      "Epoch 00058: loss did not improve from 0.04226\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0427 - out_2_loss: 0.0254 - out_4_loss: 0.0174\n",
      "Epoch 59/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0448 - out_2_loss: 0.0263 - out_4_loss: 0.0185\n",
      "Epoch 00059: loss did not improve from 0.04226\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0448 - out_2_loss: 0.0263 - out_4_loss: 0.0185\n",
      "Epoch 60/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0416 - out_2_loss: 0.0250 - out_4_loss: 0.0166\n",
      "Epoch 00060: loss improved from 0.04226 to 0.04158, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0416 - out_2_loss: 0.0250 - out_4_loss: 0.0166\n",
      "Epoch 61/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0452 - out_2_loss: 0.0265 - out_4_loss: 0.0187\n",
      "Epoch 00061: loss did not improve from 0.04158\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0452 - out_2_loss: 0.0265 - out_4_loss: 0.0187\n",
      "Epoch 62/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0414 - out_2_loss: 0.0249 - out_4_loss: 0.0165\n",
      "Epoch 00062: loss improved from 0.04158 to 0.04137, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 54s 91ms/sample - loss: 0.0414 - out_2_loss: 0.0249 - out_4_loss: 0.0165\n",
      "Epoch 63/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0394 - out_2_loss: 0.0240 - out_4_loss: 0.0154\n",
      "Epoch 00063: loss improved from 0.04137 to 0.03939, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0394 - out_2_loss: 0.0240 - out_4_loss: 0.0153\n",
      "Epoch 64/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0391 - out_2_loss: 0.0240 - out_4_loss: 0.0151\n",
      "Epoch 00064: loss improved from 0.03939 to 0.03907, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0391 - out_2_loss: 0.0240 - out_4_loss: 0.0151\n",
      "Epoch 65/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0388 - out_2_loss: 0.0238 - out_4_loss: 0.0150\n",
      "Epoch 00065: loss improved from 0.03907 to 0.03881, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0388 - out_2_loss: 0.0238 - out_4_loss: 0.0150\n",
      "Epoch 66/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0398 - out_2_loss: 0.0243 - out_4_loss: 0.0155\n",
      "Epoch 00066: loss did not improve from 0.03881\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0398 - out_2_loss: 0.0243 - out_4_loss: 0.0155\n",
      "Epoch 67/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0382 - out_2_loss: 0.0236 - out_4_loss: 0.0147\n",
      "Epoch 00067: loss improved from 0.03881 to 0.03821, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 54s 91ms/sample - loss: 0.0382 - out_2_loss: 0.0236 - out_4_loss: 0.0146\n",
      "Epoch 68/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0385 - out_2_loss: 0.0237 - out_4_loss: 0.0147\n",
      "Epoch 00068: loss did not improve from 0.03821\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0385 - out_2_loss: 0.0238 - out_4_loss: 0.0148\n",
      "Epoch 69/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0385 - out_2_loss: 0.0237 - out_4_loss: 0.0148\n",
      "Epoch 00069: loss did not improve from 0.03821\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0385 - out_2_loss: 0.0237 - out_4_loss: 0.0148\n",
      "Epoch 70/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0375 - out_2_loss: 0.0233 - out_4_loss: 0.0141\n",
      "Epoch 00070: loss improved from 0.03821 to 0.03746, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0375 - out_2_loss: 0.0233 - out_4_loss: 0.0141\n",
      "Epoch 71/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0374 - out_2_loss: 0.0233 - out_4_loss: 0.0142\n",
      "Epoch 00071: loss improved from 0.03746 to 0.03745, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0374 - out_2_loss: 0.0233 - out_4_loss: 0.0142\n",
      "Epoch 72/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0379 - out_2_loss: 0.0235 - out_4_loss: 0.0144\n",
      "Epoch 00072: loss did not improve from 0.03745\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0379 - out_2_loss: 0.0235 - out_4_loss: 0.0144\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/600 [============================>.] - ETA: 0s - loss: 0.0373 - out_2_loss: 0.0232 - out_4_loss: 0.0141\n",
      "Epoch 00073: loss improved from 0.03745 to 0.03729, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0373 - out_2_loss: 0.0232 - out_4_loss: 0.0141\n",
      "Epoch 74/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0377 - out_2_loss: 0.0234 - out_4_loss: 0.0143\n",
      "Epoch 00074: loss did not improve from 0.03729\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0377 - out_2_loss: 0.0234 - out_4_loss: 0.0143\n",
      "Epoch 75/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0382 - out_2_loss: 0.0236 - out_4_loss: 0.0146\n",
      "Epoch 00075: loss did not improve from 0.03729\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0381 - out_2_loss: 0.0236 - out_4_loss: 0.0145\n",
      "Epoch 76/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0381 - out_2_loss: 0.0236 - out_4_loss: 0.0145\n",
      "Epoch 00076: loss did not improve from 0.03729\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0382 - out_2_loss: 0.0236 - out_4_loss: 0.0145\n",
      "Epoch 77/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0373 - out_2_loss: 0.0232 - out_4_loss: 0.0141\n",
      "Epoch 00077: loss did not improve from 0.03729\n",
      "600/600 [==============================] - 54s 91ms/sample - loss: 0.0373 - out_2_loss: 0.0232 - out_4_loss: 0.0141\n",
      "Epoch 78/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0368 - out_2_loss: 0.0230 - out_4_loss: 0.0138\n",
      "Epoch 00078: loss improved from 0.03729 to 0.03681, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0368 - out_2_loss: 0.0230 - out_4_loss: 0.0138\n",
      "Epoch 79/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0374 - out_2_loss: 0.0232 - out_4_loss: 0.0142\n",
      "Epoch 00079: loss did not improve from 0.03681\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0375 - out_2_loss: 0.0233 - out_4_loss: 0.0142\n",
      "Epoch 80/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0360 - out_2_loss: 0.0228 - out_4_loss: 0.0133\n",
      "Epoch 00080: loss improved from 0.03681 to 0.03606, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0361 - out_2_loss: 0.0228 - out_4_loss: 0.0133\n",
      "Epoch 81/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0356 - out_2_loss: 0.0226 - out_4_loss: 0.0130\n",
      "Epoch 00081: loss improved from 0.03606 to 0.03560, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0356 - out_2_loss: 0.0226 - out_4_loss: 0.0130\n",
      "Epoch 82/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0372 - out_2_loss: 0.0232 - out_4_loss: 0.0140\n",
      "Epoch 00082: loss did not improve from 0.03560\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0372 - out_2_loss: 0.0232 - out_4_loss: 0.0140\n",
      "Epoch 83/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0363 - out_2_loss: 0.0229 - out_4_loss: 0.0134\n",
      "Epoch 00083: loss did not improve from 0.03560\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0363 - out_2_loss: 0.0229 - out_4_loss: 0.0134\n",
      "Epoch 84/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0350 - out_2_loss: 0.0224 - out_4_loss: 0.0126\n",
      "Epoch 00084: loss improved from 0.03560 to 0.03501, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0350 - out_2_loss: 0.0224 - out_4_loss: 0.0126\n",
      "Epoch 85/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0345 - out_2_loss: 0.0222 - out_4_loss: 0.0123\n",
      "Epoch 00085: loss improved from 0.03501 to 0.03447, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0345 - out_2_loss: 0.0222 - out_4_loss: 0.0123\n",
      "Epoch 86/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0349 - out_2_loss: 0.0223 - out_4_loss: 0.0126\n",
      "Epoch 00086: loss did not improve from 0.03447\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0349 - out_2_loss: 0.0223 - out_4_loss: 0.0126\n",
      "Epoch 87/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0349 - out_2_loss: 0.0224 - out_4_loss: 0.0126\n",
      "Epoch 00087: loss did not improve from 0.03447\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0349 - out_2_loss: 0.0224 - out_4_loss: 0.0126\n",
      "Epoch 88/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0354 - out_2_loss: 0.0225 - out_4_loss: 0.0129\n",
      "Epoch 00088: loss did not improve from 0.03447\n",
      "600/600 [==============================] - 54s 89ms/sample - loss: 0.0354 - out_2_loss: 0.0225 - out_4_loss: 0.0129\n",
      "Epoch 89/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0356 - out_2_loss: 0.0226 - out_4_loss: 0.0130\n",
      "Epoch 00089: loss did not improve from 0.03447\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0356 - out_2_loss: 0.0226 - out_4_loss: 0.0130\n",
      "Epoch 90/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0351 - out_2_loss: 0.0225 - out_4_loss: 0.0126\n",
      "Epoch 00090: loss did not improve from 0.03447\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0351 - out_2_loss: 0.0225 - out_4_loss: 0.0126\n",
      "Epoch 91/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0347 - out_2_loss: 0.0223 - out_4_loss: 0.0125\n",
      "Epoch 00091: loss did not improve from 0.03447\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0347 - out_2_loss: 0.0223 - out_4_loss: 0.0124\n",
      "Epoch 92/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0340 - out_2_loss: 0.0220 - out_4_loss: 0.0120\n",
      "Epoch 00092: loss improved from 0.03447 to 0.03399, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0340 - out_2_loss: 0.0220 - out_4_loss: 0.0120\n",
      "Epoch 93/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0344 - out_2_loss: 0.0221 - out_4_loss: 0.0122\n",
      "Epoch 00093: loss did not improve from 0.03399\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0344 - out_2_loss: 0.0221 - out_4_loss: 0.0123\n",
      "Epoch 94/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0345 - out_2_loss: 0.0222 - out_4_loss: 0.0123\n",
      "Epoch 00094: loss did not improve from 0.03399\n",
      "600/600 [==============================] - 54s 89ms/sample - loss: 0.0345 - out_2_loss: 0.0222 - out_4_loss: 0.0123\n",
      "Epoch 95/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0341 - out_2_loss: 0.0221 - out_4_loss: 0.0120\n",
      "Epoch 00095: loss did not improve from 0.03399\n",
      "600/600 [==============================] - 54s 91ms/sample - loss: 0.0341 - out_2_loss: 0.0221 - out_4_loss: 0.0120\n",
      "Epoch 96/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0340 - out_2_loss: 0.0220 - out_4_loss: 0.0120\n",
      "Epoch 00096: loss did not improve from 0.03399\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0340 - out_2_loss: 0.0220 - out_4_loss: 0.0120\n",
      "Epoch 97/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0343 - out_2_loss: 0.0221 - out_4_loss: 0.0122\n",
      "Epoch 00097: loss did not improve from 0.03399\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0343 - out_2_loss: 0.0221 - out_4_loss: 0.0122\n",
      "Epoch 98/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0360 - out_2_loss: 0.0228 - out_4_loss: 0.0132\n",
      "Epoch 00098: loss did not improve from 0.03399\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0360 - out_2_loss: 0.0228 - out_4_loss: 0.0133\n",
      "Epoch 99/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0355 - out_2_loss: 0.0225 - out_4_loss: 0.0129\n",
      "Epoch 00099: loss did not improve from 0.03399\n",
      "600/600 [==============================] - 54s 90ms/sample - loss: 0.0354 - out_2_loss: 0.0225 - out_4_loss: 0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0339 - out_2_loss: 0.0221 - out_4_loss: 0.0118\n",
      "Epoch 00100: loss improved from 0.03399 to 0.03390, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_3.h5\n",
      "600/600 [==============================] - 55s 91ms/sample - loss: 0.0339 - out_2_loss: 0.0221 - out_4_loss: 0.0118\n"
     ]
    }
   ],
   "source": [
    "print('Fitting model...')\n",
    "print('-'*200)\n",
    "hist = MVAU_Net.fit(train_image, [train_label, train_label], batch_size=4, epochs=100, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:59:01.462413Z",
     "start_time": "2021-12-07T07:58:52.402689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 8s 41ms/sample\n"
     ]
    }
   ],
   "source": [
    "a2c_a4c_pred_2, a2c_a4c_pred_4 = MVAU_Net.predict(validation_image, verbose=1)\n",
    "a2c_a4c_pred_4 = np.array(a2c_a4c_pred_4 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:59:05.947313Z",
     "start_time": "2021-12-07T07:59:01.642947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 4s 39ms/sample\n"
     ]
    }
   ],
   "source": [
    "_, test_prediction = MVAU_Net.predict(test_image, verbose=1)\n",
    "test_prediction = np.array(test_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:59:06.492721Z",
     "start_time": "2021-12-07T07:59:06.132496Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('../../result/CV/CV_3_valid_prediction.npy', a2c_a4c_pred_4)\n",
    "np.save('../../result/CV/CV_3_test_prediction.npy', test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:47:19.218802Z",
     "start_time": "2021-12-07T07:47:14.079443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall    :  0.952  0.045\n",
      "Precision :  0.906  0.126\n",
      "Accuracy  :  0.993  0.006\n",
      "DSC       :  0.921  0.075\n",
      "Jaccard   :  0.861  0.113\n"
     ]
    }
   ],
   "source": [
    "a2c_a4c_pred_2 = np.array(a2c_a4c_pred_2 > 0.5)\n",
    "a2c_a4c_pred_4 = np.array(a2c_a4c_pred_4 > 0.5)\n",
    "\n",
    "recall_list = []\n",
    "pricision_list = []\n",
    "acc_list = []\n",
    "dice_list = []\n",
    "jaccard_list = []\n",
    "\n",
    "\n",
    "for i in range(test_label.shape[0]):\n",
    "    \n",
    "    seg1 = a2c_a4c_pred_4[i,:,:,0,0]\n",
    "    gt1 = validation_label[i,:,:,0,0]\n",
    "\n",
    "    seg1_n = seg1 == 0\n",
    "    seg1_t = seg1 == 1\n",
    "\n",
    "    gt1_n = gt1 == 0\n",
    "    gt1_t = gt1 == 1\n",
    "\n",
    "\n",
    "    tp = np.sum(seg1_t&gt1_t)\n",
    "\n",
    "    fp = np.sum(seg1_t&gt1_n)\n",
    "\n",
    "    tn = np.sum(seg1_n&gt1_n)\n",
    "\n",
    "    fn = np.sum(gt1_t&seg1_n)\n",
    "\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "#     print('Sensitivity : ', sensitivity)\n",
    "\n",
    "\n",
    "    pricision = tp / (tp+fp)\n",
    "    pricision_list.append(pricision)\n",
    "\n",
    "#     print('Specificity : ', specificity)\n",
    "\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    acc_list.append(acc)\n",
    "#     print('Accuracy : ', acc)\n",
    "\n",
    "    dice = (2*tp) / (2*tp + fp + fn)\n",
    "    dice_list.append(dice)\n",
    "#     print('DSC : ', dice)\n",
    "    \n",
    "    jaccard_list.append(jaccard_score(gt1, seg1, average='micro'))\n",
    "    \n",
    "    \n",
    "dice_list_1 = np.array(dice_list)\n",
    "recall_list_1 = np.array(recall_list)\n",
    "pricision_list_1 = np.array(pricision_list)\n",
    "jaccard_list_1 = np.array(jaccard_list)\n",
    "\n",
    "dice_list_1 = dice_list_1[~np.isnan(dice_list_1)]\n",
    "recall_list_1 = recall_list_1[~np.isnan(recall_list_1)]\n",
    "pricision_list_1 = pricision_list_1[~np.isnan(pricision_list_1)]\n",
    "jaccard_list_1 = jaccard_list_1[~np.isnan(jaccard_list_1)]\n",
    "\n",
    "print('Recall    : ', round(np.mean(recall_list_1), 3), '', round(np.std(recall_list_1), 3))\n",
    "print('Precision : ', round( np.mean(pricision_list_1), 3), '', round( np.std(pricision_list_1), 3))\n",
    "print('Accuracy  : ', round(np.mean(acc_list), 3), '', round( np.std(acc_list), 3))\n",
    "print('DSC       : ', round(np.mean(dice_list_1), 3), '', round( np.std(dice_list_1), 3))\n",
    "print('Jaccard   : ', round(np.mean(jaccard_list_1), 3), '', round( np.std(jaccard_list_1), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:54:45.791935Z",
     "start_time": "2021-12-07T07:54:38.480648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall    :  0.965  0.031\n",
      "Precision :  0.953  0.052\n",
      "Accuracy  :  0.997  0.002\n",
      "DSC       :  0.958  0.029\n",
      "Jaccard   :  0.92  0.049\n"
     ]
    }
   ],
   "source": [
    "recall_list = []\n",
    "pricision_list = []\n",
    "acc_list = []\n",
    "dice_list = []\n",
    "jaccard_list = []\n",
    "\n",
    "\n",
    "for i in range(validation_label.shape[0]):\n",
    "    \n",
    "    seg1 = a2c_a4c_pred_4[i,:,:,0,1]\n",
    "    gt1 = validation_label[i,:,:,0,1]\n",
    "\n",
    "    seg1_n = seg1 == 0\n",
    "    seg1_t = seg1 == 1\n",
    "\n",
    "    gt1_n = gt1 == 0\n",
    "    gt1_t = gt1 == 1\n",
    "\n",
    "\n",
    "    tp = np.sum(seg1_t&gt1_t)\n",
    "\n",
    "    fp = np.sum(seg1_t&gt1_n)\n",
    "\n",
    "    tn = np.sum(seg1_n&gt1_n)\n",
    "\n",
    "    fn = np.sum(gt1_t&seg1_n)\n",
    "\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "#     print('Sensitivity : ', sensitivity)\n",
    "\n",
    "\n",
    "    pricision = tp / (tp+fp)\n",
    "    pricision_list.append(pricision)\n",
    "\n",
    "#     print('Specificity : ', specificity)\n",
    "\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    acc_list.append(acc)\n",
    "#     print('Accuracy : ', acc)\n",
    "\n",
    "    dice = (2*tp) / (2*tp + fp + fn)\n",
    "    dice_list.append(dice)\n",
    "#     print('DSC : ', dice)\n",
    "    \n",
    "    jaccard_list.append(jaccard_score(gt1, seg1, average='micro'))\n",
    "    \n",
    "    \n",
    "dice_list_1 = np.array(dice_list)\n",
    "recall_list_1 = np.array(recall_list)\n",
    "pricision_list_1 = np.array(pricision_list)\n",
    "jaccard_list_1 = np.array(jaccard_list)\n",
    "\n",
    "dice_list_1 = dice_list_1[~np.isnan(dice_list_1)]\n",
    "recall_list_1 = recall_list_1[~np.isnan(recall_list_1)]\n",
    "pricision_list_1 = pricision_list_1[~np.isnan(pricision_list_1)]\n",
    "jaccard_list_1 = jaccard_list_1[~np.isnan(jaccard_list_1)]\n",
    "\n",
    "print('Recall    : ', round(np.mean(recall_list_1), 3), '', round(np.std(recall_list_1), 3))\n",
    "print('Precision : ', round( np.mean(pricision_list_1), 3), '', round( np.std(pricision_list_1), 3))\n",
    "print('Accuracy  : ', round(np.mean(acc_list), 3), '', round( np.std(acc_list), 3))\n",
    "print('DSC       : ', round(np.mean(dice_list_1), 3), '', round( np.std(dice_list_1), 3))\n",
    "print('Jaccard   : ', round(np.mean(jaccard_list_1), 3), '', round( np.std(jaccard_list_1), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:47:37.907084Z",
     "start_time": "2021-12-07T07:47:22.800535Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sl in range(20):\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(test_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(test_label[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(test_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.imshow(test_label[sl,:,:,:,0], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(test_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.imshow(test_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,0], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:47:53.250767Z",
     "start_time": "2021-12-07T07:47:37.910416Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sl in range(20):\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(test_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(test_label[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(test_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.imshow(test_label[sl,:,:,:,1], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(test_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.imshow(test_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,1], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
