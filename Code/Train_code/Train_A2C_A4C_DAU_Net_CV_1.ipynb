{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:25.592272Z",
     "start_time": "2021-12-07T06:13:23.338719Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.python.keras.models import *\n",
    "\n",
    "from tensorflow.python.keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:25.616852Z",
     "start_time": "2021-12-07T06:13:25.593858Z"
    }
   },
   "outputs": [],
   "source": [
    "epsilon = K.epsilon()\n",
    "gamma = 0\n",
    "alpha = 0.6\n",
    "beta = 0.6\n",
    "\n",
    "  \n",
    "def recall(y_true, y_pred):\n",
    "\n",
    "    y_true_yn = K.round(K.clip(y_true, 0, 1))\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "    count_true_positive = K.sum(y_true_yn * y_pred_yn)     \n",
    "    count_true_positive_false_negative = K.sum(y_true_yn)\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_true_yn = K.round(K.clip(y_true, 0, 1))\n",
    "    count_true_positive = K.sum(y_true_yn * y_pred_yn) \n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    _recall = recall(y_true, y_pred)\n",
    "    _precision = precision(y_true, y_pred)\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "\n",
    "    return _f1score\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def balanced_loss(y_true, y_pred):\n",
    "    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n",
    "    pt = K.clip(pt, epsilon, 1-epsilon)\n",
    "    CE = -K.log(pt)\n",
    "    BL = alpha * CE\n",
    "    \n",
    "    return K.sum(BL, axis=1)\n",
    "\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n",
    "    pt = K.clip(pt, epsilon, 1-epsilon)\n",
    "    CE = -K.log(pt)\n",
    "    FL = alpha * K.pow(1-pt, gamma) * CE\n",
    "    \n",
    "    return K.sum(FL, axis=1)\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=0.001):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def cus_loss(y_true, y_pred):\n",
    "    \n",
    "    return (1 - beta) * focal_loss(y_true, y_pred) + beta * dice_coef_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "get_custom_objects().update({\n",
    "    \n",
    "    'cus_loss': cus_loss,\n",
    "    'iou_coef' : iou_coef,\n",
    "    'f1score' : f1score,\n",
    "    'precision' : precision,\n",
    "    'recall' : recall,\n",
    "    'balanced_loss' : balanced_loss,\n",
    "    'focal_loss' : focal_loss,\n",
    "    'dice_coef' : dice_coef,\n",
    "    'dice_coef_loss' : dice_coef_loss,\n",
    "    'cus_loss' : cus_loss,\n",
    "        \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:35.400826Z",
     "start_time": "2021-12-07T06:13:25.618589Z"
    }
   },
   "outputs": [],
   "source": [
    "train_a2c_image = np.load('../../data/dataset/train/train_A2C_image.npy').astype(np.float32)\n",
    "train_a2c_label = np.load('../../data/dataset/train/train_A2C_label.npy').astype(np.float32)\n",
    "\n",
    "train_a4c_image = np.load('../../data/dataset/train/train_A4C_image.npy').astype(np.float32)\n",
    "train_a4c_label = np.load('../../data/dataset/train/train_A4C_label.npy').astype(np.float32)\n",
    "\n",
    "\n",
    "test_a2c_image = np.load('../../data/dataset/test/test_A2C_image.npy').astype(np.float32)\n",
    "test_a2c_label = np.load('../../data/dataset/test/test_A2C_label.npy').astype(np.float32)\n",
    "\n",
    "test_a4c_image = np.load('../../data/dataset/test/test_A4C_image.npy').astype(np.float32)\n",
    "test_a4c_label = np.load('../../data/dataset/test/test_A4C_label.npy').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:37.039956Z",
     "start_time": "2021-12-07T06:13:35.403867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 255.0\n",
      "0.0 1.0\n",
      "0.0 255.0\n",
      "0.0 1.0\n",
      "0.0 255.0\n",
      "0.0 1.0\n",
      "0.0 255.0\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(train_a2c_image.min(), train_a2c_image.max())\n",
    "print(train_a2c_label.min(), train_a2c_label.max())\n",
    "\n",
    "\n",
    "print(train_a4c_image.min(), train_a4c_image.max())\n",
    "print(train_a4c_label.min(), train_a4c_label.max())\n",
    "\n",
    "\n",
    "print(test_a2c_image.min(), test_a2c_image.max())\n",
    "print(test_a2c_label.min(), test_a2c_label.max())\n",
    "\n",
    "\n",
    "print(test_a4c_image.min(), test_a4c_image.max())\n",
    "print(test_a4c_label.min(), test_a4c_label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:39.729146Z",
     "start_time": "2021-12-07T06:13:37.041877Z"
    }
   },
   "outputs": [],
   "source": [
    "train_a2c_image = train_a2c_image / 255\n",
    "train_a4c_image = train_a4c_image / 255\n",
    "\n",
    "test_a2c_image = test_a2c_image / 255\n",
    "test_a4c_image = test_a4c_image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:41.363649Z",
     "start_time": "2021-12-07T06:13:39.730701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(train_a2c_image.min(), train_a2c_image.max())\n",
    "print(train_a2c_label.min(), train_a2c_label.max())\n",
    "\n",
    "\n",
    "print(train_a4c_image.min(), train_a4c_image.max())\n",
    "print(train_a4c_label.min(), train_a4c_label.max())\n",
    "\n",
    "\n",
    "print(test_a2c_image.min(), test_a2c_image.max())\n",
    "print(test_a2c_label.min(), test_a2c_label.max())\n",
    "\n",
    "\n",
    "print(test_a4c_image.min(), test_a4c_image.max())\n",
    "print(test_a4c_label.min(), test_a4c_label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:41.371469Z",
     "start_time": "2021-12-07T06:13:41.366398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 512, 512, 1)\n",
      "(800, 512, 512, 1)\n",
      "(800, 512, 512, 1)\n",
      "(800, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_a2c_image.shape)\n",
    "print(train_a2c_label.shape)\n",
    "\n",
    "\n",
    "print(train_a4c_image.shape)\n",
    "print(train_a4c_label.shape)\n",
    "\n",
    "\n",
    "print(test_a2c_image.shape)\n",
    "print(test_a2c_label.shape)\n",
    "\n",
    "\n",
    "print(test_a4c_image.shape)\n",
    "print(test_a4c_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:41.400146Z",
     "start_time": "2021-12-07T06:13:41.373905Z"
    }
   },
   "outputs": [],
   "source": [
    "all_train_image = np.zeros((800,512,512,1,2))\n",
    "all_train_label = np.zeros((800,512,512,1,2))\n",
    "\n",
    "test_image = np.zeros((100,512,512,1,2))\n",
    "test_label = np.zeros((100,512,512,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:42.803185Z",
     "start_time": "2021-12-07T06:13:41.404555Z"
    }
   },
   "outputs": [],
   "source": [
    "all_train_image[:,:,:,:,0] = train_a2c_image\n",
    "all_train_image[:,:,:,:,1] = train_a4c_image\n",
    "\n",
    "all_train_label[:,:,:,:,0] = train_a2c_label\n",
    "all_train_label[:,:,:,:,1] = train_a4c_label\n",
    "\n",
    "test_image[:,:,:,:,0] = test_a2c_image\n",
    "test_image[:,:,:,:,1] = test_a4c_image\n",
    "\n",
    "test_label[:,:,:,:,0] = test_a2c_label\n",
    "test_label[:,:,:,:,1] = test_a4c_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:42.813193Z",
     "start_time": "2021-12-07T06:13:42.805985Z"
    }
   },
   "outputs": [],
   "source": [
    "train_image_fold_1 = all_train_image[:200]\n",
    "train_image_fold_2 = all_train_image[200:400]\n",
    "train_image_fold_3 = all_train_image[400:600]\n",
    "train_image_fold_4 = all_train_image[600:]\n",
    "\n",
    "\n",
    "train_label_fold_1 = all_train_label[:200]\n",
    "train_label_fold_2 = all_train_label[200:400]\n",
    "train_label_fold_3 = all_train_label[400:600]\n",
    "train_label_fold_4 = all_train_label[600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.614681Z",
     "start_time": "2021-12-07T06:13:42.815668Z"
    }
   },
   "outputs": [],
   "source": [
    "# CV1\n",
    "train_image = np.concatenate((train_image_fold_1, train_image_fold_2, train_image_fold_3), axis =0)\n",
    "train_label = np.concatenate((train_label_fold_1, train_label_fold_2, train_label_fold_3), axis =0)\n",
    "\n",
    "validation_image = train_image_fold_4\n",
    "validation_label = train_label_fold_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.620067Z",
     "start_time": "2021-12-07T06:13:43.617821Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CV2\n",
    "# train_image = np.concatenate((train_image_fold_1, train_image_fold_2, train_image_fold_4), axis =0)\n",
    "# train_label = np.concatenate((train_label_fold_1, train_label_fold_2, train_label_fold_4), axis =0)\n",
    "\n",
    "# validation_image = train_image_fold_3\n",
    "# validation_label = train_label_fold_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.641787Z",
     "start_time": "2021-12-07T06:13:43.622965Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CV3\n",
    "# train_image = np.concatenate((train_image_fold_1, train_image_fold_3, train_image_fold_4), axis =0)\n",
    "# train_label = np.concatenate((train_label_fold_1, train_label_fold_3, train_label_fold_4), axis =0)\n",
    "\n",
    "# validation_image = train_image_fold_2\n",
    "# validation_label = train_label_fold_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.657245Z",
     "start_time": "2021-12-07T06:13:43.644295Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CV4\n",
    "# train_image = np.concatenate((train_image_fold_2, train_image_fold_3, train_image_fold_4), axis =0)\n",
    "# train_label = np.concatenate((train_label_fold_2, train_label_fold_3, train_label_fold_4), axis =0)\n",
    "\n",
    "# validation_image = train_image_fold_1\n",
    "# validation_label = train_label_fold_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.671361Z",
     "start_time": "2021-12-07T06:13:43.659898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 512, 512, 1, 2)\n",
      "(600, 512, 512, 1, 2)\n",
      "(200, 512, 512, 1, 2)\n",
      "(200, 512, 512, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_image.shape)\n",
    "print(train_label.shape)\n",
    "\n",
    "print(validation_image.shape)\n",
    "print(validation_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.688761Z",
     "start_time": "2021-12-07T06:13:43.673123Z"
    }
   },
   "outputs": [],
   "source": [
    "def Conv2D_block(input_layer, out_n_filters, kernel_size=[3,3], stride=[1,1], padding='same'):\n",
    "    \n",
    "    layer = input_layer\n",
    "    \n",
    "    for i in range(2):\n",
    "        \n",
    "        layer = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, kernel_initializer = 'he_normal')(layer)\n",
    "        layer = BatchNormalization()(layer)\n",
    "        layer = Activation('relu')(layer)        \n",
    "        \n",
    "    out_layer = layer\n",
    "    \n",
    "    return out_layer\n",
    "    \n",
    "\n",
    "def Up_and_Concate(down_layer, layer):\n",
    "    \n",
    "    input_channel = down_layer.get_shape().as_list()[3]\n",
    "    output_channel = input_channel // 2\n",
    "    \n",
    "    up = UpSampling2D(size = (2,2))(down_layer) \n",
    "\n",
    "    concate = concatenate([up, layer])\n",
    "    return concate\n",
    "\n",
    "def attention_block_2d(x, g, inter_channel):\n",
    "\n",
    "\n",
    "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1])(x)\n",
    "\n",
    "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1])(g)\n",
    "\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "\n",
    "\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1])(f)\n",
    "\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "\n",
    "\n",
    "    att_x = multiply([x, rate])\n",
    "\n",
    "    return att_x\n",
    "\n",
    "\n",
    "def attention_up_and_concate(down_layer, layer):\n",
    "    in_channel = down_layer.get_shape().as_list()[3]\n",
    "\n",
    "    up = UpSampling2D((2, 2))(down_layer)\n",
    "\n",
    "    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4)\n",
    "\n",
    "    concate = concatenate([up, layer])\n",
    "    \n",
    "    return concate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.711720Z",
     "start_time": "2021-12-07T06:13:43.691222Z"
    }
   },
   "outputs": [],
   "source": [
    "def AU_Net_2D(input_shape):\n",
    "        \n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    depth = 4\n",
    "    features = 32\n",
    "    down_layer = []\n",
    "    supervision_layer = []\n",
    "    \n",
    "    for i in range(depth):\n",
    "        \n",
    "        x = Conv2D_block(x, features)\n",
    "        down_layer.append(x)\n",
    "        x = MaxPooling2D(pool_size=[2, 2], strides=[2, 2])(x)\n",
    "\n",
    "        features = features * 2\n",
    "        \n",
    "    x = Conv2D_block(x, features)\n",
    "    \n",
    "    for i in reversed(range(depth)):\n",
    "\n",
    "        features = features // 2\n",
    "        \n",
    "        x = attention_up_and_concate(x, down_layer[i])\n",
    "        x = Conv2D_block(x, features)\n",
    "        supervision_layer.append(x)\n",
    "    \n",
    "    \n",
    "\n",
    "    output_2 = UpSampling2D((4, 4))(supervision_layer[1])\n",
    "    output_4 = UpSampling2D((1, 1))(supervision_layer[3])\n",
    "    \n",
    "\n",
    "    model = Model(inputs = inputs, outputs = [output_2, output_4])\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:45.412058Z",
     "start_time": "2021-12-07T06:13:43.714140Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1207 15:13:43.758435 124774492162192 deprecation.py:506] From /opt/anaconda3/envs/powerai_162/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 32) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512, 512, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 32) 9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 256, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 64) 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 128 147584      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 128 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 256)  590080      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 512)  2359808     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 512)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 64, 64, 512)  0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  32896       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  65664       up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 128)  0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 1)    129         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 1)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 64, 64, 256)  0           activation_7[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 768)  0           up_sampling2d[0][0]              \n",
      "                                                                 multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  1769728     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 256)  1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 256)  1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 256 0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 64) 8256        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 64) 16448       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 64) 0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 64) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 1)  65          activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 128, 1)  0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 128, 128, 128 0           activation_5[0][0]               \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 384 0           up_sampling2d_1[0][0]            \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 442496      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 128 512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 128, 128, 128 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 128 147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 128 512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128, 128, 128 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 128 0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 32) 2080        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 32) 4128        up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 256, 32) 0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 256, 256, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 1)  33          activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 256, 256, 1)  0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 256, 256, 64) 0           activation_3[0][0]               \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 192 0           up_sampling2d_2[0][0]            \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 64) 110656      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256, 256, 64) 256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 256, 256, 64) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 64) 36928       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 64) 256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 256, 256, 64) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 512, 512, 64) 0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 512, 512, 16) 528         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 512, 512, 16) 1040        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 512, 512, 16) 0           conv2d_25[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 512, 512, 16) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 512, 512, 1)  17          activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 512, 512, 1)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 512, 512, 32) 0           activation_1[0][0]               \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 96) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 512, 512, 32) 27680       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 512, 512, 32) 128         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 512, 512, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 512, 512, 32) 9248        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 512, 32) 128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 512, 512, 32) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 512, 512, 128 0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 512, 512, 32) 0           activation_25[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 7,989,108\n",
      "Trainable params: 7,983,220\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = AU_Net_2D((512,512,1))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:45.426597Z",
     "start_time": "2021-12-07T06:13:45.415233Z"
    }
   },
   "outputs": [],
   "source": [
    "def Multi_View_AU_Net():\n",
    "    \n",
    "    inputs = Input(shape=(512,512,1,2), name='input')\n",
    "    \n",
    "    a2c_view = inputs[:, :, :, :, 0]\n",
    "    a4c_view = inputs[:, :, :, :, 1]\n",
    "    \n",
    "    base_model = AU_Net_2D(input_shape = (512,512,1))\n",
    "    \n",
    "    a2c_view_output_2, a2c_view_output_4 = base_model(a2c_view)\n",
    "    a4c_view_output_2, a4c_view_output_4 = base_model(a4c_view)\n",
    "    \n",
    "    \n",
    "    output_2 = Concatenate()([a2c_view_output_2, a4c_view_output_2])\n",
    "    output_4 = Concatenate()([a2c_view_output_4, a4c_view_output_4])\n",
    "\n",
    "    \n",
    "    fn_output_2 = Dense(32)(output_2)\n",
    "    fn_output_2 = Dropout(0.25)(fn_output_2)\n",
    "    fn_output_2 = Dense(2)(fn_output_2)\n",
    "    \n",
    "    \n",
    "    fn_output_4 = Dense(32)(output_4)\n",
    "    fn_output_4 = Dropout(0.25)(fn_output_4)\n",
    "    fn_output_4 = Dense(2)(fn_output_4)\n",
    "    \n",
    "    \n",
    "\n",
    "    fn_output_2 = K.expand_dims(fn_output_2, 3)\n",
    "    fn_output_4 = K.expand_dims(fn_output_4, 3)\n",
    "    \n",
    "\n",
    "    fn_output_2 = Activation('sigmoid', name='out_2')(fn_output_2)\n",
    "    fn_output_4 = Activation('sigmoid', name='out_4')(fn_output_4)\n",
    "\n",
    "\n",
    "    MVAU_Net = keras.Model(inputs = inputs, outputs = [fn_output_2, fn_output_4], name='MV_AU_Net')\n",
    "\n",
    "    \n",
    "    return MVAU_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:14:25.337062Z",
     "start_time": "2021-12-07T06:13:45.429751Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1207 15:13:46.738753 124774492162192 backend.py:548] OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MV_AU_Net\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input (InputLayer)                               [(None, 512, 512, 1, 2)]         0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (TensorFlowOpLayer)    [(None, 512, 512, 1)]            0                 input[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (TensorFlowOpLayer)  [(None, 512, 512, 1)]            0                 input[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "model_1 (Model)                                  [(None, 512, 512, 128), (None, 5 7989108           tf_op_layer_strided_slice[0][0]                   \n",
      "                                                                                                    tf_op_layer_strided_slice_1[0][0]                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)                      (None, 512, 512, 256)            0                 model_1[1][0]                                     \n",
      "                                                                                                    model_1[2][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)                      (None, 512, 512, 64)             0                 model_1[1][1]                                     \n",
      "                                                                                                    model_1[2][1]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense (Dense)                                    (None, 512, 512, 32)             8224              concatenate_8[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_2 (Dense)                                  (None, 512, 512, 32)             2080              concatenate_9[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dropout (Dropout)                                (None, 512, 512, 32)             0                 dense[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                              (None, 512, 512, 32)             0                 dense_2[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_1 (Dense)                                  (None, 512, 512, 2)              66                dropout[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_3 (Dense)                                  (None, 512, 512, 2)              66                dropout_1[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorFlowOpLayer)       [(None, 512, 512, 1, 2)]         0                 dense_1[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (TensorFlowOpLayer)     [(None, 512, 512, 1, 2)]         0                 dense_3[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "out_2 (Activation)                               (None, 512, 512, 1, 2)           0                 tf_op_layer_ExpandDims[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "out_4 (Activation)                               (None, 512, 512, 1, 2)           0                 tf_op_layer_ExpandDims_1[0][0]                    \n",
      "======================================================================================================================================================\n",
      "Total params: 7,999,544\n",
      "Trainable params: 7,993,656\n",
      "Non-trainable params: 5,888\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MVAU_Net = Multi_View_AU_Net()\n",
    "MVAU_Net.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:14:25.446676Z",
     "start_time": "2021-12-07T06:14:25.339995Z"
    }
   },
   "outputs": [],
   "source": [
    "losses ={'out_2':dice_coef_loss,\n",
    "         'out_4':dice_coef_loss}\n",
    "\n",
    "MVAU_Net.compile(optimizer=Adam(lr=0.001), loss = losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:14:25.451571Z",
     "start_time": "2021-12-07T06:14:25.448040Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-8)\n",
    "earlystopper = EarlyStopping(monitor='loss',patience=30, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5', monitor='loss', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks_list = [model_checkpoint, earlystopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:51:52.573330Z",
     "start_time": "2021-12-07T06:14:25.457219Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train on 600 samples\n",
      "Epoch 1/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.5108 - out_2_loss: 0.2334 - out_4_loss: 0.2774\n",
      "Epoch 00001: loss improved from inf to 0.50893, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 69s 114ms/sample - loss: 0.5089 - out_2_loss: 0.2327 - out_4_loss: 0.2763\n",
      "Epoch 2/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.2282 - out_2_loss: 0.1140 - out_4_loss: 0.1143\n",
      "Epoch 00002: loss improved from 0.50893 to 0.22759, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 61s 102ms/sample - loss: 0.2276 - out_2_loss: 0.1137 - out_4_loss: 0.1139\n",
      "Epoch 3/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1947 - out_2_loss: 0.0977 - out_4_loss: 0.0970\n",
      "Epoch 00003: loss improved from 0.22759 to 0.19460, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 61s 102ms/sample - loss: 0.1946 - out_2_loss: 0.0977 - out_4_loss: 0.0969\n",
      "Epoch 4/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1789 - out_2_loss: 0.0901 - out_4_loss: 0.0889\n",
      "Epoch 00004: loss improved from 0.19460 to 0.17941, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 64s 107ms/sample - loss: 0.1794 - out_2_loss: 0.0903 - out_4_loss: 0.0891\n",
      "Epoch 5/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1630 - out_2_loss: 0.0825 - out_4_loss: 0.0805\n",
      "Epoch 00005: loss improved from 0.17941 to 0.16299, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 60s 101ms/sample - loss: 0.1630 - out_2_loss: 0.0825 - out_4_loss: 0.0805\n",
      "Epoch 6/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1452 - out_2_loss: 0.0739 - out_4_loss: 0.0713\n",
      "Epoch 00006: loss improved from 0.16299 to 0.14533, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 61s 102ms/sample - loss: 0.1453 - out_2_loss: 0.0740 - out_4_loss: 0.0714\n",
      "Epoch 7/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1403 - out_2_loss: 0.0715 - out_4_loss: 0.0688\n",
      "Epoch 00007: loss improved from 0.14533 to 0.14045, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 61s 102ms/sample - loss: 0.1404 - out_2_loss: 0.0715 - out_4_loss: 0.0689\n",
      "Epoch 8/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1392 - out_2_loss: 0.0710 - out_4_loss: 0.0682\n",
      "Epoch 00008: loss improved from 0.14045 to 0.13927, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.1393 - out_2_loss: 0.0710 - out_4_loss: 0.0683\n",
      "Epoch 9/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1260 - out_2_loss: 0.0646 - out_4_loss: 0.0614\n",
      "Epoch 00009: loss improved from 0.13927 to 0.12587, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 61s 102ms/sample - loss: 0.1259 - out_2_loss: 0.0645 - out_4_loss: 0.0613\n",
      "Epoch 10/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1272 - out_2_loss: 0.0652 - out_4_loss: 0.0620\n",
      "Epoch 00010: loss did not improve from 0.12587\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.1271 - out_2_loss: 0.0652 - out_4_loss: 0.0619\n",
      "Epoch 11/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1244 - out_2_loss: 0.0638 - out_4_loss: 0.0606\n",
      "Epoch 00011: loss improved from 0.12587 to 0.12433, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.1243 - out_2_loss: 0.0638 - out_4_loss: 0.0606\n",
      "Epoch 12/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1193 - out_2_loss: 0.0614 - out_4_loss: 0.0579\n",
      "Epoch 00012: loss improved from 0.12433 to 0.11928, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.1193 - out_2_loss: 0.0614 - out_4_loss: 0.0579\n",
      "Epoch 13/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1146 - out_2_loss: 0.0592 - out_4_loss: 0.0554\n",
      "Epoch 00013: loss improved from 0.11928 to 0.11431, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 60s 99ms/sample - loss: 0.1143 - out_2_loss: 0.0590 - out_4_loss: 0.0553\n",
      "Epoch 14/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1086 - out_2_loss: 0.0563 - out_4_loss: 0.0523\n",
      "Epoch 00014: loss improved from 0.11431 to 0.10875, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.1088 - out_2_loss: 0.0564 - out_4_loss: 0.0524\n",
      "Epoch 15/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1044 - out_2_loss: 0.0543 - out_4_loss: 0.0501\n",
      "Epoch 00015: loss improved from 0.10875 to 0.10482, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.1048 - out_2_loss: 0.0545 - out_4_loss: 0.0503\n",
      "Epoch 16/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1030 - out_2_loss: 0.0536 - out_4_loss: 0.0493\n",
      "Epoch 00016: loss improved from 0.10482 to 0.10289, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.1029 - out_2_loss: 0.0536 - out_4_loss: 0.0493\n",
      "Epoch 17/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1010 - out_2_loss: 0.0526 - out_4_loss: 0.0484\n",
      "Epoch 00017: loss improved from 0.10289 to 0.10114, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.1011 - out_2_loss: 0.0527 - out_4_loss: 0.0485\n",
      "Epoch 18/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1015 - out_2_loss: 0.0528 - out_4_loss: 0.0487\n",
      "Epoch 00018: loss did not improve from 0.10114\n",
      "600/600 [==============================] - 57s 96ms/sample - loss: 0.1017 - out_2_loss: 0.0529 - out_4_loss: 0.0488\n",
      "Epoch 19/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1003 - out_2_loss: 0.0523 - out_4_loss: 0.0480\n",
      "Epoch 00019: loss improved from 0.10114 to 0.10041, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.1004 - out_2_loss: 0.0524 - out_4_loss: 0.0481\n",
      "Epoch 20/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0934 - out_2_loss: 0.0490 - out_4_loss: 0.0445\n",
      "Epoch 00020: loss improved from 0.10041 to 0.09352, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0935 - out_2_loss: 0.0490 - out_4_loss: 0.0445\n",
      "Epoch 21/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0957 - out_2_loss: 0.0502 - out_4_loss: 0.0455\n",
      "Epoch 00021: loss did not improve from 0.09352\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0958 - out_2_loss: 0.0502 - out_4_loss: 0.0456\n",
      "Epoch 22/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0991 - out_2_loss: 0.0517 - out_4_loss: 0.0474\n",
      "Epoch 00022: loss did not improve from 0.09352\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0995 - out_2_loss: 0.0519 - out_4_loss: 0.0476\n",
      "Epoch 23/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0931 - out_2_loss: 0.0488 - out_4_loss: 0.0443\n",
      "Epoch 00023: loss improved from 0.09352 to 0.09310, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0931 - out_2_loss: 0.0488 - out_4_loss: 0.0443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0853 - out_2_loss: 0.0451 - out_4_loss: 0.0403\n",
      "Epoch 00024: loss improved from 0.09310 to 0.08554, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0855 - out_2_loss: 0.0452 - out_4_loss: 0.0404\n",
      "Epoch 25/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0839 - out_2_loss: 0.0445 - out_4_loss: 0.0394\n",
      "Epoch 00025: loss improved from 0.08554 to 0.08389, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0839 - out_2_loss: 0.0445 - out_4_loss: 0.0394\n",
      "Epoch 26/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0779 - out_2_loss: 0.0416 - out_4_loss: 0.0363\n",
      "Epoch 00026: loss improved from 0.08389 to 0.07795, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 61s 101ms/sample - loss: 0.0779 - out_2_loss: 0.0416 - out_4_loss: 0.0364\n",
      "Epoch 27/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0762 - out_2_loss: 0.0408 - out_4_loss: 0.0355\n",
      "Epoch 00027: loss improved from 0.07795 to 0.07641, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0764 - out_2_loss: 0.0408 - out_4_loss: 0.0356\n",
      "Epoch 28/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0717 - out_2_loss: 0.0387 - out_4_loss: 0.0330\n",
      "Epoch 00028: loss improved from 0.07641 to 0.07230, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0723 - out_2_loss: 0.0390 - out_4_loss: 0.0333\n",
      "Epoch 29/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0726 - out_2_loss: 0.0391 - out_4_loss: 0.0335\n",
      "Epoch 00029: loss did not improve from 0.07230\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0725 - out_2_loss: 0.0390 - out_4_loss: 0.0335\n",
      "Epoch 30/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0750 - out_2_loss: 0.0402 - out_4_loss: 0.0348\n",
      "Epoch 00030: loss did not improve from 0.07230\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0751 - out_2_loss: 0.0402 - out_4_loss: 0.0348\n",
      "Epoch 31/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0744 - out_2_loss: 0.0399 - out_4_loss: 0.0345\n",
      "Epoch 00031: loss did not improve from 0.07230\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0744 - out_2_loss: 0.0399 - out_4_loss: 0.0345\n",
      "Epoch 32/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0714 - out_2_loss: 0.0385 - out_4_loss: 0.0329\n",
      "Epoch 00032: loss improved from 0.07230 to 0.07146, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0715 - out_2_loss: 0.0386 - out_4_loss: 0.0329\n",
      "Epoch 33/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0753 - out_2_loss: 0.0403 - out_4_loss: 0.0350\n",
      "Epoch 00033: loss did not improve from 0.07146\n",
      "600/600 [==============================] - 62s 103ms/sample - loss: 0.0753 - out_2_loss: 0.0403 - out_4_loss: 0.0350\n",
      "Epoch 34/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0647 - out_2_loss: 0.0354 - out_4_loss: 0.0293\n",
      "Epoch 00034: loss improved from 0.07146 to 0.06468, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0647 - out_2_loss: 0.0354 - out_4_loss: 0.0293\n",
      "Epoch 35/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0605 - out_2_loss: 0.0334 - out_4_loss: 0.0271\n",
      "Epoch 00035: loss improved from 0.06468 to 0.06052, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0605 - out_2_loss: 0.0334 - out_4_loss: 0.0271\n",
      "Epoch 36/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0586 - out_2_loss: 0.0326 - out_4_loss: 0.0260\n",
      "Epoch 00036: loss improved from 0.06052 to 0.05867, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0587 - out_2_loss: 0.0326 - out_4_loss: 0.0261\n",
      "Epoch 37/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0587 - out_2_loss: 0.0326 - out_4_loss: 0.0262\n",
      "Epoch 00037: loss did not improve from 0.05867\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0588 - out_2_loss: 0.0326 - out_4_loss: 0.0262\n",
      "Epoch 38/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0577 - out_2_loss: 0.0322 - out_4_loss: 0.0256\n",
      "Epoch 00038: loss improved from 0.05867 to 0.05782, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0578 - out_2_loss: 0.0322 - out_4_loss: 0.0256\n",
      "Epoch 39/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0582 - out_2_loss: 0.0323 - out_4_loss: 0.0259\n",
      "Epoch 00039: loss did not improve from 0.05782\n",
      "600/600 [==============================] - 60s 99ms/sample - loss: 0.0581 - out_2_loss: 0.0322 - out_4_loss: 0.0259\n",
      "Epoch 40/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0552 - out_2_loss: 0.0310 - out_4_loss: 0.0242\n",
      "Epoch 00040: loss improved from 0.05782 to 0.05515, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0551 - out_2_loss: 0.0309 - out_4_loss: 0.0242\n",
      "Epoch 41/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0539 - out_2_loss: 0.0304 - out_4_loss: 0.0235\n",
      "Epoch 00041: loss improved from 0.05515 to 0.05395, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0540 - out_2_loss: 0.0304 - out_4_loss: 0.0236\n",
      "Epoch 42/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0513 - out_2_loss: 0.0292 - out_4_loss: 0.0221\n",
      "Epoch 00042: loss improved from 0.05395 to 0.05129, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0513 - out_2_loss: 0.0292 - out_4_loss: 0.0221\n",
      "Epoch 43/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0513 - out_2_loss: 0.0292 - out_4_loss: 0.0221\n",
      "Epoch 00043: loss did not improve from 0.05129\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0513 - out_2_loss: 0.0292 - out_4_loss: 0.0221\n",
      "Epoch 44/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0498 - out_2_loss: 0.0285 - out_4_loss: 0.0213\n",
      "Epoch 00044: loss improved from 0.05129 to 0.04993, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0499 - out_2_loss: 0.0286 - out_4_loss: 0.0214\n",
      "Epoch 45/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0486 - out_2_loss: 0.0280 - out_4_loss: 0.0207\n",
      "Epoch 00045: loss improved from 0.04993 to 0.04855, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 60s 99ms/sample - loss: 0.0486 - out_2_loss: 0.0279 - out_4_loss: 0.0206\n",
      "Epoch 46/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0472 - out_2_loss: 0.0274 - out_4_loss: 0.0198\n",
      "Epoch 00046: loss improved from 0.04855 to 0.04713, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0471 - out_2_loss: 0.0274 - out_4_loss: 0.0198\n",
      "Epoch 47/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0488 - out_2_loss: 0.0280 - out_4_loss: 0.0208\n",
      "Epoch 00047: loss did not improve from 0.04713\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0487 - out_2_loss: 0.0279 - out_4_loss: 0.0208\n",
      "Epoch 48/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0471 - out_2_loss: 0.0274 - out_4_loss: 0.0197\n",
      "Epoch 00048: loss improved from 0.04713 to 0.04706, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0471 - out_2_loss: 0.0274 - out_4_loss: 0.0197\n",
      "Epoch 49/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0453 - out_2_loss: 0.0266 - out_4_loss: 0.0187\n",
      "Epoch 00049: loss improved from 0.04706 to 0.04527, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0453 - out_2_loss: 0.0266 - out_4_loss: 0.0187\n",
      "Epoch 50/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0450 - out_2_loss: 0.0265 - out_4_loss: 0.0186\n",
      "Epoch 00050: loss improved from 0.04527 to 0.04499, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0450 - out_2_loss: 0.0264 - out_4_loss: 0.0186\n",
      "Epoch 51/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0435 - out_2_loss: 0.0258 - out_4_loss: 0.0177\n",
      "Epoch 00051: loss improved from 0.04499 to 0.04354, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0435 - out_2_loss: 0.0258 - out_4_loss: 0.0177\n",
      "Epoch 52/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0434 - out_2_loss: 0.0258 - out_4_loss: 0.0177\n",
      "Epoch 00052: loss improved from 0.04354 to 0.04344, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0434 - out_2_loss: 0.0258 - out_4_loss: 0.0177\n",
      "Epoch 53/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0449 - out_2_loss: 0.0264 - out_4_loss: 0.0185\n",
      "Epoch 00053: loss did not improve from 0.04344\n",
      "600/600 [==============================] - 57s 96ms/sample - loss: 0.0448 - out_2_loss: 0.0263 - out_4_loss: 0.0185\n",
      "Epoch 54/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0461 - out_2_loss: 0.0268 - out_4_loss: 0.0193\n",
      "Epoch 00054: loss did not improve from 0.04344\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0460 - out_2_loss: 0.0268 - out_4_loss: 0.0193\n",
      "Epoch 55/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0439 - out_2_loss: 0.0259 - out_4_loss: 0.0180\n",
      "Epoch 00055: loss did not improve from 0.04344\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0439 - out_2_loss: 0.0259 - out_4_loss: 0.0180\n",
      "Epoch 56/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0417 - out_2_loss: 0.0251 - out_4_loss: 0.0166\n",
      "Epoch 00056: loss improved from 0.04344 to 0.04171, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0417 - out_2_loss: 0.0251 - out_4_loss: 0.0166\n",
      "Epoch 57/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0402 - out_2_loss: 0.0244 - out_4_loss: 0.0158\n",
      "Epoch 00057: loss improved from 0.04171 to 0.04026, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 57s 96ms/sample - loss: 0.0403 - out_2_loss: 0.0245 - out_4_loss: 0.0158\n",
      "Epoch 58/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0402 - out_2_loss: 0.0244 - out_4_loss: 0.0158\n",
      "Epoch 00058: loss improved from 0.04026 to 0.04013, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0401 - out_2_loss: 0.0244 - out_4_loss: 0.0157\n",
      "Epoch 59/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0407 - out_2_loss: 0.0246 - out_4_loss: 0.0161\n",
      "Epoch 00059: loss did not improve from 0.04013\n",
      "600/600 [==============================] - 57s 96ms/sample - loss: 0.0407 - out_2_loss: 0.0246 - out_4_loss: 0.0161\n",
      "Epoch 60/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0405 - out_2_loss: 0.0246 - out_4_loss: 0.0159\n",
      "Epoch 00060: loss did not improve from 0.04013\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0405 - out_2_loss: 0.0246 - out_4_loss: 0.0159\n",
      "Epoch 61/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0398 - out_2_loss: 0.0242 - out_4_loss: 0.0155\n",
      "Epoch 00061: loss improved from 0.04013 to 0.03975, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0398 - out_2_loss: 0.0242 - out_4_loss: 0.0155\n",
      "Epoch 62/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0611 - out_2_loss: 0.0338 - out_4_loss: 0.0273\n",
      "Epoch 00062: loss did not improve from 0.03975\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0610 - out_2_loss: 0.0338 - out_4_loss: 0.0272\n",
      "Epoch 63/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0448 - out_2_loss: 0.0263 - out_4_loss: 0.0186\n",
      "Epoch 00063: loss did not improve from 0.03975\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0448 - out_2_loss: 0.0263 - out_4_loss: 0.0185\n",
      "Epoch 64/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0394 - out_2_loss: 0.0241 - out_4_loss: 0.0153\n",
      "Epoch 00064: loss improved from 0.03975 to 0.03934, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0393 - out_2_loss: 0.0241 - out_4_loss: 0.0152\n",
      "Epoch 65/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0371 - out_2_loss: 0.0232 - out_4_loss: 0.0139\n",
      "Epoch 00065: loss improved from 0.03934 to 0.03708, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0371 - out_2_loss: 0.0232 - out_4_loss: 0.0139\n",
      "Epoch 66/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0366 - out_2_loss: 0.0230 - out_4_loss: 0.0135\n",
      "Epoch 00066: loss improved from 0.03708 to 0.03656, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0366 - out_2_loss: 0.0230 - out_4_loss: 0.0135\n",
      "Epoch 67/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0365 - out_2_loss: 0.0230 - out_4_loss: 0.0134\n",
      "Epoch 00067: loss improved from 0.03656 to 0.03648, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0365 - out_2_loss: 0.0230 - out_4_loss: 0.0135\n",
      "Epoch 68/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0368 - out_2_loss: 0.0231 - out_4_loss: 0.0136\n",
      "Epoch 00068: loss did not improve from 0.03648\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0368 - out_2_loss: 0.0231 - out_4_loss: 0.0136\n",
      "Epoch 69/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0363 - out_2_loss: 0.0229 - out_4_loss: 0.0134\n",
      "Epoch 00069: loss improved from 0.03648 to 0.03636, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0364 - out_2_loss: 0.0229 - out_4_loss: 0.0134\n",
      "Epoch 70/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0361 - out_2_loss: 0.0229 - out_4_loss: 0.0132\n",
      "Epoch 00070: loss improved from 0.03636 to 0.03606, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0361 - out_2_loss: 0.0228 - out_4_loss: 0.0132\n",
      "Epoch 71/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0363 - out_2_loss: 0.0229 - out_4_loss: 0.0134\n",
      "Epoch 00071: loss did not improve from 0.03606\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0363 - out_2_loss: 0.0229 - out_4_loss: 0.0134\n",
      "Epoch 72/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0362 - out_2_loss: 0.0229 - out_4_loss: 0.0133\n",
      "Epoch 00072: loss did not improve from 0.03606\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0362 - out_2_loss: 0.0229 - out_4_loss: 0.0133\n",
      "Epoch 73/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0365 - out_2_loss: 0.0230 - out_4_loss: 0.0135\n",
      "Epoch 00073: loss did not improve from 0.03606\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0365 - out_2_loss: 0.0230 - out_4_loss: 0.0135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0374 - out_2_loss: 0.0233 - out_4_loss: 0.0141\n",
      "Epoch 00074: loss did not improve from 0.03606\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0374 - out_2_loss: 0.0233 - out_4_loss: 0.0141\n",
      "Epoch 75/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0365 - out_2_loss: 0.0230 - out_4_loss: 0.0134\n",
      "Epoch 00075: loss did not improve from 0.03606\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0365 - out_2_loss: 0.0230 - out_4_loss: 0.0134\n",
      "Epoch 76/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0365 - out_2_loss: 0.0230 - out_4_loss: 0.0135\n",
      "Epoch 00076: loss did not improve from 0.03606\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0365 - out_2_loss: 0.0230 - out_4_loss: 0.0135\n",
      "Epoch 77/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0376 - out_2_loss: 0.0234 - out_4_loss: 0.0142\n",
      "Epoch 00077: loss did not improve from 0.03606\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0376 - out_2_loss: 0.0234 - out_4_loss: 0.0142\n",
      "Epoch 78/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0377 - out_2_loss: 0.0235 - out_4_loss: 0.0143\n",
      "Epoch 00078: loss did not improve from 0.03606\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0377 - out_2_loss: 0.0234 - out_4_loss: 0.0142\n",
      "Epoch 79/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0359 - out_2_loss: 0.0228 - out_4_loss: 0.0131\n",
      "Epoch 00079: loss improved from 0.03606 to 0.03589, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0359 - out_2_loss: 0.0228 - out_4_loss: 0.0131\n",
      "Epoch 80/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0350 - out_2_loss: 0.0224 - out_4_loss: 0.0125\n",
      "Epoch 00080: loss improved from 0.03589 to 0.03497, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0350 - out_2_loss: 0.0224 - out_4_loss: 0.0125\n",
      "Epoch 81/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0350 - out_2_loss: 0.0225 - out_4_loss: 0.0126\n",
      "Epoch 00081: loss did not improve from 0.03497\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0350 - out_2_loss: 0.0225 - out_4_loss: 0.0126\n",
      "Epoch 82/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0348 - out_2_loss: 0.0224 - out_4_loss: 0.0124\n",
      "Epoch 00082: loss improved from 0.03497 to 0.03477, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0348 - out_2_loss: 0.0224 - out_4_loss: 0.0124\n",
      "Epoch 83/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0353 - out_2_loss: 0.0226 - out_4_loss: 0.0128\n",
      "Epoch 00083: loss did not improve from 0.03477\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0353 - out_2_loss: 0.0225 - out_4_loss: 0.0127\n",
      "Epoch 84/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0354 - out_2_loss: 0.0226 - out_4_loss: 0.0128\n",
      "Epoch 00084: loss did not improve from 0.03477\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0354 - out_2_loss: 0.0226 - out_4_loss: 0.0128\n",
      "Epoch 85/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0351 - out_2_loss: 0.0224 - out_4_loss: 0.0127\n",
      "Epoch 00085: loss did not improve from 0.03477\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0351 - out_2_loss: 0.0224 - out_4_loss: 0.0127\n",
      "Epoch 86/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0358 - out_2_loss: 0.0227 - out_4_loss: 0.0131\n",
      "Epoch 00086: loss did not improve from 0.03477\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0358 - out_2_loss: 0.0227 - out_4_loss: 0.0131\n",
      "Epoch 87/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0481 - out_2_loss: 0.0280 - out_4_loss: 0.0202\n",
      "Epoch 00087: loss did not improve from 0.03477\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0483 - out_2_loss: 0.0280 - out_4_loss: 0.0202\n",
      "Epoch 88/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0422 - out_2_loss: 0.0253 - out_4_loss: 0.0168\n",
      "Epoch 00088: loss did not improve from 0.03477\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0421 - out_2_loss: 0.0253 - out_4_loss: 0.0168\n",
      "Epoch 89/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0357 - out_2_loss: 0.0228 - out_4_loss: 0.0130\n",
      "Epoch 00089: loss did not improve from 0.03477\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0357 - out_2_loss: 0.0228 - out_4_loss: 0.0130\n",
      "Epoch 90/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0344 - out_2_loss: 0.0222 - out_4_loss: 0.0121\n",
      "Epoch 00090: loss improved from 0.03477 to 0.03440, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0344 - out_2_loss: 0.0223 - out_4_loss: 0.0121\n",
      "Epoch 91/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0338 - out_2_loss: 0.0220 - out_4_loss: 0.0118\n",
      "Epoch 00091: loss improved from 0.03440 to 0.03378, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0338 - out_2_loss: 0.0220 - out_4_loss: 0.0118\n",
      "Epoch 92/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0333 - out_2_loss: 0.0218 - out_4_loss: 0.0115\n",
      "Epoch 00092: loss improved from 0.03378 to 0.03330, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0333 - out_2_loss: 0.0218 - out_4_loss: 0.0115\n",
      "Epoch 93/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0327 - out_2_loss: 0.0217 - out_4_loss: 0.0111\n",
      "Epoch 00093: loss improved from 0.03330 to 0.03277, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_1.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0328 - out_2_loss: 0.0217 - out_4_loss: 0.0111\n",
      "Epoch 94/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0331 - out_2_loss: 0.0218 - out_4_loss: 0.0113\n",
      "Epoch 00094: loss did not improve from 0.03277\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0331 - out_2_loss: 0.0218 - out_4_loss: 0.0113\n",
      "Epoch 95/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0329 - out_2_loss: 0.0218 - out_4_loss: 0.0111\n",
      "Epoch 00095: loss did not improve from 0.03277\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0329 - out_2_loss: 0.0217 - out_4_loss: 0.0111\n",
      "Epoch 96/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0330 - out_2_loss: 0.0217 - out_4_loss: 0.0112\n",
      "Epoch 00096: loss did not improve from 0.03277\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0330 - out_2_loss: 0.0218 - out_4_loss: 0.0112\n",
      "Epoch 97/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0332 - out_2_loss: 0.0219 - out_4_loss: 0.0114\n",
      "Epoch 00097: loss did not improve from 0.03277\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0332 - out_2_loss: 0.0219 - out_4_loss: 0.0114\n",
      "Epoch 98/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0334 - out_2_loss: 0.0219 - out_4_loss: 0.0115\n",
      "Epoch 00098: loss did not improve from 0.03277\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0334 - out_2_loss: 0.0219 - out_4_loss: 0.0115\n",
      "Epoch 99/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0332 - out_2_loss: 0.0219 - out_4_loss: 0.0113\n",
      "Epoch 00099: loss did not improve from 0.03277\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0332 - out_2_loss: 0.0219 - out_4_loss: 0.0113\n",
      "Epoch 100/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0328 - out_2_loss: 0.0217 - out_4_loss: 0.0111\n",
      "Epoch 00100: loss did not improve from 0.03277\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0328 - out_2_loss: 0.0217 - out_4_loss: 0.0111\n"
     ]
    }
   ],
   "source": [
    "print('Fitting model...')\n",
    "print('-'*200)\n",
    "hist = MVAU_Net.fit(train_image, [train_label, train_label], batch_size=4, epochs=100, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:52:08.313658Z",
     "start_time": "2021-12-07T07:51:52.576370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 15s 77ms/sample\n"
     ]
    }
   ],
   "source": [
    "a2c_a4c_pred_2, a2c_a4c_pred_4 = MVAU_Net.predict(validation_image, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:56:59.449979Z",
     "start_time": "2021-12-07T07:56:55.815517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 4s 36ms/sample\n"
     ]
    }
   ],
   "source": [
    "_, test_prediction = MVAU_Net.predict(test_image, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:57:34.630229Z",
     "start_time": "2021-12-07T07:57:34.306695Z"
    }
   },
   "outputs": [],
   "source": [
    "test_prediction = np.array(test_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:57:47.603522Z",
     "start_time": "2021-12-07T07:57:47.304647Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('../../result/CV/CV_1_valid_prediction.npy', a2c_a4c_pred_4)\n",
    "np.save('../../result/CV/CV_1_test_prediction.npy', test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:52:13.323115Z",
     "start_time": "2021-12-07T07:52:08.315267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall    :  0.936  0.065\n",
      "Precision :  0.927  0.105\n",
      "Accuracy  :  0.993  0.008\n",
      "DSC       :  0.926  0.066\n",
      "Jaccard   :  0.868  0.102\n"
     ]
    }
   ],
   "source": [
    "a2c_a4c_pred_2 = np.array(a2c_a4c_pred_2 > 0.5)\n",
    "a2c_a4c_pred_4 = np.array(a2c_a4c_pred_4 > 0.5)\n",
    "\n",
    "recall_list = []\n",
    "pricision_list = []\n",
    "acc_list = []\n",
    "dice_list = []\n",
    "jaccard_list = []\n",
    "\n",
    "\n",
    "for i in range(test_label.shape[0]):\n",
    "    \n",
    "    seg1 = a2c_a4c_pred_4[i,:,:,0,0]\n",
    "    gt1 = validation_label[i,:,:,0,0]\n",
    "\n",
    "    seg1_n = seg1 == 0\n",
    "    seg1_t = seg1 == 1\n",
    "\n",
    "    gt1_n = gt1 == 0\n",
    "    gt1_t = gt1 == 1\n",
    "\n",
    "\n",
    "    tp = np.sum(seg1_t&gt1_t)\n",
    "\n",
    "    fp = np.sum(seg1_t&gt1_n)\n",
    "\n",
    "    tn = np.sum(seg1_n&gt1_n)\n",
    "\n",
    "    fn = np.sum(gt1_t&seg1_n)\n",
    "\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "#     print('Sensitivity : ', sensitivity)\n",
    "\n",
    "\n",
    "    pricision = tp / (tp+fp)\n",
    "    pricision_list.append(pricision)\n",
    "\n",
    "#     print('Specificity : ', specificity)\n",
    "\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    acc_list.append(acc)\n",
    "#     print('Accuracy : ', acc)\n",
    "\n",
    "    dice = (2*tp) / (2*tp + fp + fn)\n",
    "    dice_list.append(dice)\n",
    "#     print('DSC : ', dice)\n",
    "    \n",
    "    jaccard_list.append(jaccard_score(gt1, seg1, average='micro'))\n",
    "    \n",
    "    \n",
    "dice_list_1 = np.array(dice_list)\n",
    "recall_list_1 = np.array(recall_list)\n",
    "pricision_list_1 = np.array(pricision_list)\n",
    "jaccard_list_1 = np.array(jaccard_list)\n",
    "\n",
    "dice_list_1 = dice_list_1[~np.isnan(dice_list_1)]\n",
    "recall_list_1 = recall_list_1[~np.isnan(recall_list_1)]\n",
    "pricision_list_1 = pricision_list_1[~np.isnan(pricision_list_1)]\n",
    "jaccard_list_1 = jaccard_list_1[~np.isnan(jaccard_list_1)]\n",
    "\n",
    "print('Recall    : ', round(np.mean(recall_list_1), 3), '', round(np.std(recall_list_1), 3))\n",
    "print('Precision : ', round( np.mean(pricision_list_1), 3), '', round( np.std(pricision_list_1), 3))\n",
    "print('Accuracy  : ', round(np.mean(acc_list), 3), '', round( np.std(acc_list), 3))\n",
    "print('DSC       : ', round(np.mean(dice_list_1), 3), '', round( np.std(dice_list_1), 3))\n",
    "print('Jaccard   : ', round(np.mean(jaccard_list_1), 3), '', round( np.std(jaccard_list_1), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:54:31.357821Z",
     "start_time": "2021-12-07T07:54:24.211543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall    :  0.961  0.032\n",
      "Precision :  0.96  0.039\n",
      "Accuracy  :  0.996  0.003\n",
      "DSC       :  0.959  0.023\n",
      "Jaccard   :  0.923  0.041\n"
     ]
    }
   ],
   "source": [
    "recall_list = []\n",
    "pricision_list = []\n",
    "acc_list = []\n",
    "dice_list = []\n",
    "jaccard_list = []\n",
    "\n",
    "\n",
    "for i in range(validation_label.shape[0]):\n",
    "    \n",
    "    seg1 = a2c_a4c_pred_4[i,:,:,0,1]\n",
    "    gt1 = validation_label[i,:,:,0,1]\n",
    "\n",
    "    seg1_n = seg1 == 0\n",
    "    seg1_t = seg1 == 1\n",
    "\n",
    "    gt1_n = gt1 == 0\n",
    "    gt1_t = gt1 == 1\n",
    "\n",
    "\n",
    "    tp = np.sum(seg1_t&gt1_t)\n",
    "\n",
    "    fp = np.sum(seg1_t&gt1_n)\n",
    "\n",
    "    tn = np.sum(seg1_n&gt1_n)\n",
    "\n",
    "    fn = np.sum(gt1_t&seg1_n)\n",
    "\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "#     print('Sensitivity : ', sensitivity)\n",
    "\n",
    "\n",
    "    pricision = tp / (tp+fp)\n",
    "    pricision_list.append(pricision)\n",
    "\n",
    "#     print('Specificity : ', specificity)\n",
    "\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    acc_list.append(acc)\n",
    "#     print('Accuracy : ', acc)\n",
    "\n",
    "    dice = (2*tp) / (2*tp + fp + fn)\n",
    "    dice_list.append(dice)\n",
    "#     print('DSC : ', dice)\n",
    "    \n",
    "    jaccard_list.append(jaccard_score(gt1, seg1, average='micro'))\n",
    "    \n",
    "    \n",
    "dice_list_1 = np.array(dice_list)\n",
    "recall_list_1 = np.array(recall_list)\n",
    "pricision_list_1 = np.array(pricision_list)\n",
    "jaccard_list_1 = np.array(jaccard_list)\n",
    "\n",
    "dice_list_1 = dice_list_1[~np.isnan(dice_list_1)]\n",
    "recall_list_1 = recall_list_1[~np.isnan(recall_list_1)]\n",
    "pricision_list_1 = pricision_list_1[~np.isnan(pricision_list_1)]\n",
    "jaccard_list_1 = jaccard_list_1[~np.isnan(jaccard_list_1)]\n",
    "\n",
    "print('Recall    : ', round(np.mean(recall_list_1), 3), '', round(np.std(recall_list_1), 3))\n",
    "print('Precision : ', round( np.mean(pricision_list_1), 3), '', round( np.std(pricision_list_1), 3))\n",
    "print('Accuracy  : ', round(np.mean(acc_list), 3), '', round( np.std(acc_list), 3))\n",
    "print('DSC       : ', round(np.mean(dice_list_1), 3), '', round( np.std(dice_list_1), 3))\n",
    "print('Jaccard   : ', round(np.mean(jaccard_list_1), 3), '', round( np.std(jaccard_list_1), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:54:07.729416Z",
     "start_time": "2021-12-07T07:53:52.652831Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sl in range(20):\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(validation_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(validation_label[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(validation_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.imshow(validation_label[sl,:,:,:,0], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(validation_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.imshow(validation_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,0], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:55:16.146856Z",
     "start_time": "2021-12-07T07:55:00.430810Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sl in range(20):\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(validation_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(validation_label[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(validation_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.imshow(validation_label[sl,:,:,:,1], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(validation_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.imshow(validation_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,1], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
