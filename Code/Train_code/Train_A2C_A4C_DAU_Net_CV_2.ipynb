{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:25.004711Z",
     "start_time": "2021-12-07T06:13:22.795453Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.python.keras.models import *\n",
    "\n",
    "from tensorflow.python.keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:25.030236Z",
     "start_time": "2021-12-07T06:13:25.007390Z"
    }
   },
   "outputs": [],
   "source": [
    "epsilon = K.epsilon()\n",
    "gamma = 0\n",
    "alpha = 0.6\n",
    "beta = 0.6\n",
    "\n",
    "  \n",
    "def recall(y_true, y_pred):\n",
    "\n",
    "    y_true_yn = K.round(K.clip(y_true, 0, 1))\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "    count_true_positive = K.sum(y_true_yn * y_pred_yn)     \n",
    "    count_true_positive_false_negative = K.sum(y_true_yn)\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_true_yn = K.round(K.clip(y_true, 0, 1))\n",
    "    count_true_positive = K.sum(y_true_yn * y_pred_yn) \n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    _recall = recall(y_true, y_pred)\n",
    "    _precision = precision(y_true, y_pred)\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "\n",
    "    return _f1score\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def balanced_loss(y_true, y_pred):\n",
    "    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n",
    "    pt = K.clip(pt, epsilon, 1-epsilon)\n",
    "    CE = -K.log(pt)\n",
    "    BL = alpha * CE\n",
    "    \n",
    "    return K.sum(BL, axis=1)\n",
    "\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n",
    "    pt = K.clip(pt, epsilon, 1-epsilon)\n",
    "    CE = -K.log(pt)\n",
    "    FL = alpha * K.pow(1-pt, gamma) * CE\n",
    "    \n",
    "    return K.sum(FL, axis=1)\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=0.001):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def cus_loss(y_true, y_pred):\n",
    "    \n",
    "    return (1 - beta) * focal_loss(y_true, y_pred) + beta * dice_coef_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "get_custom_objects().update({\n",
    "    \n",
    "    'cus_loss': cus_loss,\n",
    "    'iou_coef' : iou_coef,\n",
    "    'f1score' : f1score,\n",
    "    'precision' : precision,\n",
    "    'recall' : recall,\n",
    "    'balanced_loss' : balanced_loss,\n",
    "    'focal_loss' : focal_loss,\n",
    "    'dice_coef' : dice_coef,\n",
    "    'dice_coef_loss' : dice_coef_loss,\n",
    "    'cus_loss' : cus_loss,\n",
    "        \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:35.402944Z",
     "start_time": "2021-12-07T06:13:25.033606Z"
    }
   },
   "outputs": [],
   "source": [
    "train_a2c_image = np.load('../../data/dataset/train/train_A2C_image.npy').astype(np.float32)\n",
    "train_a2c_label = np.load('../../data/dataset/train/train_A2C_label.npy').astype(np.float32)\n",
    "\n",
    "train_a4c_image = np.load('../../data/dataset/train/train_A4C_image.npy').astype(np.float32)\n",
    "train_a4c_label = np.load('../../data/dataset/train/train_A4C_label.npy').astype(np.float32)\n",
    "\n",
    "\n",
    "test_a2c_image = np.load('../../data/dataset/test/test_A2C_image.npy').astype(np.float32)\n",
    "test_a2c_label = np.load('../../data/dataset/test/test_A2C_label.npy').astype(np.float32)\n",
    "\n",
    "test_a4c_image = np.load('../../data/dataset/test/test_A4C_image.npy').astype(np.float32)\n",
    "test_a4c_label = np.load('../../data/dataset/test/test_A4C_label.npy').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:37.044983Z",
     "start_time": "2021-12-07T06:13:35.406866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 255.0\n",
      "0.0 1.0\n",
      "0.0 255.0\n",
      "0.0 1.0\n",
      "0.0 255.0\n",
      "0.0 1.0\n",
      "0.0 255.0\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(train_a2c_image.min(), train_a2c_image.max())\n",
    "print(train_a2c_label.min(), train_a2c_label.max())\n",
    "\n",
    "\n",
    "print(train_a4c_image.min(), train_a4c_image.max())\n",
    "print(train_a4c_label.min(), train_a4c_label.max())\n",
    "\n",
    "\n",
    "print(test_a2c_image.min(), test_a2c_image.max())\n",
    "print(test_a2c_label.min(), test_a2c_label.max())\n",
    "\n",
    "\n",
    "print(test_a4c_image.min(), test_a4c_image.max())\n",
    "print(test_a4c_label.min(), test_a4c_label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:40.429401Z",
     "start_time": "2021-12-07T06:13:37.046432Z"
    }
   },
   "outputs": [],
   "source": [
    "train_a2c_image = train_a2c_image / 255\n",
    "train_a4c_image = train_a4c_image / 255\n",
    "\n",
    "test_a2c_image = test_a2c_image / 255\n",
    "test_a4c_image = test_a4c_image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:42.252220Z",
     "start_time": "2021-12-07T06:13:40.432561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(train_a2c_image.min(), train_a2c_image.max())\n",
    "print(train_a2c_label.min(), train_a2c_label.max())\n",
    "\n",
    "\n",
    "print(train_a4c_image.min(), train_a4c_image.max())\n",
    "print(train_a4c_label.min(), train_a4c_label.max())\n",
    "\n",
    "\n",
    "print(test_a2c_image.min(), test_a2c_image.max())\n",
    "print(test_a2c_label.min(), test_a2c_label.max())\n",
    "\n",
    "\n",
    "print(test_a4c_image.min(), test_a4c_image.max())\n",
    "print(test_a4c_label.min(), test_a4c_label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:42.261094Z",
     "start_time": "2021-12-07T06:13:42.254114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 512, 512, 1)\n",
      "(800, 512, 512, 1)\n",
      "(800, 512, 512, 1)\n",
      "(800, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_a2c_image.shape)\n",
    "print(train_a2c_label.shape)\n",
    "\n",
    "\n",
    "print(train_a4c_image.shape)\n",
    "print(train_a4c_label.shape)\n",
    "\n",
    "\n",
    "print(test_a2c_image.shape)\n",
    "print(test_a2c_label.shape)\n",
    "\n",
    "\n",
    "print(test_a4c_image.shape)\n",
    "print(test_a4c_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:42.282643Z",
     "start_time": "2021-12-07T06:13:42.265952Z"
    }
   },
   "outputs": [],
   "source": [
    "all_train_image = np.zeros((800,512,512,1,2))\n",
    "all_train_label = np.zeros((800,512,512,1,2))\n",
    "\n",
    "test_image = np.zeros((100,512,512,1,2))\n",
    "test_label = np.zeros((100,512,512,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.771671Z",
     "start_time": "2021-12-07T06:13:42.289227Z"
    }
   },
   "outputs": [],
   "source": [
    "all_train_image[:,:,:,:,0] = train_a2c_image\n",
    "all_train_image[:,:,:,:,1] = train_a4c_image\n",
    "\n",
    "all_train_label[:,:,:,:,0] = train_a2c_label\n",
    "all_train_label[:,:,:,:,1] = train_a4c_label\n",
    "\n",
    "test_image[:,:,:,:,0] = test_a2c_image\n",
    "test_image[:,:,:,:,1] = test_a4c_image\n",
    "\n",
    "test_label[:,:,:,:,0] = test_a2c_label\n",
    "test_label[:,:,:,:,1] = test_a4c_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.782541Z",
     "start_time": "2021-12-07T06:13:43.776048Z"
    }
   },
   "outputs": [],
   "source": [
    "train_image_fold_1 = all_train_image[:200]\n",
    "train_image_fold_2 = all_train_image[200:400]\n",
    "train_image_fold_3 = all_train_image[400:600]\n",
    "train_image_fold_4 = all_train_image[600:]\n",
    "\n",
    "\n",
    "train_label_fold_1 = all_train_label[:200]\n",
    "train_label_fold_2 = all_train_label[200:400]\n",
    "train_label_fold_3 = all_train_label[400:600]\n",
    "train_label_fold_4 = all_train_label[600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.797307Z",
     "start_time": "2021-12-07T06:13:43.787050Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CV1\n",
    "# train_image = np.concatenate((train_image_fold_1, train_image_fold_2, train_image_fold_3), axis =0)\n",
    "# train_label = np.concatenate((train_label_fold_1, train_label_fold_2, train_label_fold_3), axis =0)\n",
    "\n",
    "# validation_image = train_image_fold_4\n",
    "# validation_label = train_label_fold_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.582992Z",
     "start_time": "2021-12-07T06:13:43.801760Z"
    }
   },
   "outputs": [],
   "source": [
    "# CV2\n",
    "train_image = np.concatenate((train_image_fold_1, train_image_fold_2, train_image_fold_4), axis =0)\n",
    "train_label = np.concatenate((train_label_fold_1, train_label_fold_2, train_label_fold_4), axis =0)\n",
    "\n",
    "validation_image = train_image_fold_3\n",
    "validation_label = train_label_fold_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.592222Z",
     "start_time": "2021-12-07T06:13:44.588029Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CV3\n",
    "# train_image = np.concatenate((train_image_fold_1, train_image_fold_3, train_image_fold_4), axis =0)\n",
    "# train_label = np.concatenate((train_label_fold_1, train_label_fold_3, train_label_fold_4), axis =0)\n",
    "\n",
    "# validation_image = train_image_fold_2\n",
    "# validation_label = train_label_fold_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.610309Z",
     "start_time": "2021-12-07T06:13:44.596681Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CV4\n",
    "# train_image = np.concatenate((train_image_fold_2, train_image_fold_3, train_image_fold_4), axis =0)\n",
    "# train_label = np.concatenate((train_label_fold_2, train_label_fold_3, train_label_fold_4), axis =0)\n",
    "\n",
    "# validation_image = train_image_fold_1\n",
    "# validation_label = train_label_fold_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.620539Z",
     "start_time": "2021-12-07T06:13:44.613627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 512, 512, 1, 2)\n",
      "(600, 512, 512, 1, 2)\n",
      "(200, 512, 512, 1, 2)\n",
      "(200, 512, 512, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_image.shape)\n",
    "print(train_label.shape)\n",
    "\n",
    "print(validation_image.shape)\n",
    "print(validation_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.642635Z",
     "start_time": "2021-12-07T06:13:44.623248Z"
    }
   },
   "outputs": [],
   "source": [
    "def Conv2D_block(input_layer, out_n_filters, kernel_size=[3,3], stride=[1,1], padding='same'):\n",
    "    \n",
    "    layer = input_layer\n",
    "    \n",
    "    for i in range(2):\n",
    "        \n",
    "        layer = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, kernel_initializer = 'he_normal')(layer)\n",
    "        layer = BatchNormalization()(layer)\n",
    "        layer = Activation('relu')(layer)        \n",
    "        \n",
    "    out_layer = layer\n",
    "    \n",
    "    return out_layer\n",
    "    \n",
    "\n",
    "def Up_and_Concate(down_layer, layer):\n",
    "    \n",
    "    input_channel = down_layer.get_shape().as_list()[3]\n",
    "    output_channel = input_channel // 2\n",
    "    \n",
    "    up = UpSampling2D(size = (2,2))(down_layer) \n",
    "\n",
    "    concate = concatenate([up, layer])\n",
    "    return concate\n",
    "\n",
    "def attention_block_2d(x, g, inter_channel):\n",
    "\n",
    "\n",
    "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1])(x)\n",
    "\n",
    "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1])(g)\n",
    "\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "\n",
    "\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1])(f)\n",
    "\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "\n",
    "\n",
    "    att_x = multiply([x, rate])\n",
    "\n",
    "    return att_x\n",
    "\n",
    "\n",
    "def attention_up_and_concate(down_layer, layer):\n",
    "    in_channel = down_layer.get_shape().as_list()[3]\n",
    "\n",
    "    up = UpSampling2D((2, 2))(down_layer)\n",
    "\n",
    "    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4)\n",
    "\n",
    "    concate = concatenate([up, layer])\n",
    "    \n",
    "    return concate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.673654Z",
     "start_time": "2021-12-07T06:13:44.647094Z"
    }
   },
   "outputs": [],
   "source": [
    "def AU_Net_2D(input_shape):\n",
    "        \n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    depth = 4\n",
    "    features = 32\n",
    "    down_layer = []\n",
    "    supervision_layer = []\n",
    "    \n",
    "    for i in range(depth):\n",
    "        \n",
    "        x = Conv2D_block(x, features)\n",
    "        down_layer.append(x)\n",
    "        x = MaxPooling2D(pool_size=[2, 2], strides=[2, 2])(x)\n",
    "\n",
    "        features = features * 2\n",
    "        \n",
    "    x = Conv2D_block(x, features)\n",
    "    \n",
    "    for i in reversed(range(depth)):\n",
    "\n",
    "        features = features // 2\n",
    "        \n",
    "        x = attention_up_and_concate(x, down_layer[i])\n",
    "        x = Conv2D_block(x, features)\n",
    "        supervision_layer.append(x)\n",
    "    \n",
    "    \n",
    "\n",
    "    output_2 = UpSampling2D((4, 4))(supervision_layer[1])\n",
    "    output_4 = UpSampling2D((1, 1))(supervision_layer[3])\n",
    "    \n",
    "\n",
    "    model = Model(inputs = inputs, outputs = [output_2, output_4])\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:46.068740Z",
     "start_time": "2021-12-07T06:13:44.677584Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1207 15:13:44.722079 139067977648272 deprecation.py:506] From /opt/anaconda3/envs/powerai_162/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 32) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512, 512, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 32) 9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 256, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 64) 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 128 147584      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 128 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 256)  590080      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 512)  2359808     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 512)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 64, 64, 512)  0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  32896       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  65664       up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 128)  0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 1)    129         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 1)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 64, 64, 256)  0           activation_7[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 768)  0           up_sampling2d[0][0]              \n",
      "                                                                 multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  1769728     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 256)  1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 256)  1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 256 0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 64) 8256        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 64) 16448       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 64) 0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 64) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 1)  65          activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 128, 1)  0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 128, 128, 128 0           activation_5[0][0]               \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 384 0           up_sampling2d_1[0][0]            \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 442496      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 128 512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 128, 128, 128 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 128 147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 128 512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128, 128, 128 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 128 0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 32) 2080        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 32) 4128        up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 256, 32) 0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 256, 256, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 1)  33          activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 256, 256, 1)  0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 256, 256, 64) 0           activation_3[0][0]               \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 192 0           up_sampling2d_2[0][0]            \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 64) 110656      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256, 256, 64) 256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 256, 256, 64) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 64) 36928       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 64) 256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 256, 256, 64) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 512, 512, 64) 0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 512, 512, 16) 528         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 512, 512, 16) 1040        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 512, 512, 16) 0           conv2d_25[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 512, 512, 16) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 512, 512, 1)  17          activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 512, 512, 1)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 512, 512, 32) 0           activation_1[0][0]               \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 96) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 512, 512, 32) 27680       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 512, 512, 32) 128         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 512, 512, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 512, 512, 32) 9248        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 512, 32) 128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 512, 512, 32) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 512, 512, 128 0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 512, 512, 32) 0           activation_25[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 7,989,108\n",
      "Trainable params: 7,983,220\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = AU_Net_2D((512,512,1))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:46.081930Z",
     "start_time": "2021-12-07T06:13:46.071539Z"
    }
   },
   "outputs": [],
   "source": [
    "def Multi_View_AU_Net():\n",
    "    \n",
    "    inputs = Input(shape=(512,512,1,2), name='input')\n",
    "    \n",
    "    a2c_view = inputs[:, :, :, :, 0]\n",
    "    a4c_view = inputs[:, :, :, :, 1]\n",
    "    \n",
    "    base_model = AU_Net_2D(input_shape = (512,512,1))\n",
    "    \n",
    "    a2c_view_output_2, a2c_view_output_4 = base_model(a2c_view)\n",
    "    a4c_view_output_2, a4c_view_output_4 = base_model(a4c_view)\n",
    "    \n",
    "    \n",
    "    output_2 = Concatenate()([a2c_view_output_2, a4c_view_output_2])\n",
    "    output_4 = Concatenate()([a2c_view_output_4, a4c_view_output_4])\n",
    "\n",
    "    \n",
    "    fn_output_2 = Dense(32)(output_2)\n",
    "    fn_output_2 = Dropout(0.25)(fn_output_2)\n",
    "    fn_output_2 = Dense(2)(fn_output_2)\n",
    "    \n",
    "    \n",
    "    fn_output_4 = Dense(32)(output_4)\n",
    "    fn_output_4 = Dropout(0.25)(fn_output_4)\n",
    "    fn_output_4 = Dense(2)(fn_output_4)\n",
    "    \n",
    "    \n",
    "\n",
    "    fn_output_2 = K.expand_dims(fn_output_2, 3)\n",
    "    fn_output_4 = K.expand_dims(fn_output_4, 3)\n",
    "    \n",
    "\n",
    "    fn_output_2 = Activation('sigmoid', name='out_2')(fn_output_2)\n",
    "    fn_output_4 = Activation('sigmoid', name='out_4')(fn_output_4)\n",
    "\n",
    "\n",
    "    MVAU_Net = keras.Model(inputs = inputs, outputs = [fn_output_2, fn_output_4], name='MV_AU_Net')\n",
    "\n",
    "    \n",
    "    return MVAU_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:14:26.116283Z",
     "start_time": "2021-12-07T06:13:46.084403Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1207 15:13:47.408190 139067977648272 backend.py:548] OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MV_AU_Net\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input (InputLayer)                               [(None, 512, 512, 1, 2)]         0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (TensorFlowOpLayer)    [(None, 512, 512, 1)]            0                 input[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (TensorFlowOpLayer)  [(None, 512, 512, 1)]            0                 input[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "model_1 (Model)                                  [(None, 512, 512, 128), (None, 5 7989108           tf_op_layer_strided_slice[0][0]                   \n",
      "                                                                                                    tf_op_layer_strided_slice_1[0][0]                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)                      (None, 512, 512, 256)            0                 model_1[1][0]                                     \n",
      "                                                                                                    model_1[2][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)                      (None, 512, 512, 64)             0                 model_1[1][1]                                     \n",
      "                                                                                                    model_1[2][1]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense (Dense)                                    (None, 512, 512, 32)             8224              concatenate_8[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_2 (Dense)                                  (None, 512, 512, 32)             2080              concatenate_9[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dropout (Dropout)                                (None, 512, 512, 32)             0                 dense[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                              (None, 512, 512, 32)             0                 dense_2[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_1 (Dense)                                  (None, 512, 512, 2)              66                dropout[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_3 (Dense)                                  (None, 512, 512, 2)              66                dropout_1[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorFlowOpLayer)       [(None, 512, 512, 1, 2)]         0                 dense_1[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (TensorFlowOpLayer)     [(None, 512, 512, 1, 2)]         0                 dense_3[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "out_2 (Activation)                               (None, 512, 512, 1, 2)           0                 tf_op_layer_ExpandDims[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "out_4 (Activation)                               (None, 512, 512, 1, 2)           0                 tf_op_layer_ExpandDims_1[0][0]                    \n",
      "======================================================================================================================================================\n",
      "Total params: 7,999,544\n",
      "Trainable params: 7,993,656\n",
      "Non-trainable params: 5,888\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MVAU_Net = Multi_View_AU_Net()\n",
    "MVAU_Net.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:14:26.225455Z",
     "start_time": "2021-12-07T06:14:26.117733Z"
    }
   },
   "outputs": [],
   "source": [
    "losses ={'out_2':dice_coef_loss,\n",
    "         'out_4':dice_coef_loss}\n",
    "\n",
    "MVAU_Net.compile(optimizer=Adam(lr=0.001), loss = losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:14:26.232411Z",
     "start_time": "2021-12-07T06:14:26.227916Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-8)\n",
    "earlystopper = EarlyStopping(monitor='loss',patience=30, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5', monitor='loss', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks_list = [model_checkpoint, earlystopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:53:10.031490Z",
     "start_time": "2021-12-07T06:14:26.235659Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train on 600 samples\n",
      "Epoch 1/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.4904 - out_2_loss: 0.2206 - out_4_loss: 0.2698\n",
      "Epoch 00001: loss improved from inf to 0.48896, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 66s 110ms/sample - loss: 0.4890 - out_2_loss: 0.2200 - out_4_loss: 0.2689\n",
      "Epoch 2/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.2128 - out_2_loss: 0.1060 - out_4_loss: 0.1068\n",
      "Epoch 00002: loss improved from 0.48896 to 0.21243, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.2124 - out_2_loss: 0.1058 - out_4_loss: 0.1066\n",
      "Epoch 3/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1837 - out_2_loss: 0.0924 - out_4_loss: 0.0913\n",
      "Epoch 00003: loss improved from 0.21243 to 0.18373, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.1837 - out_2_loss: 0.0924 - out_4_loss: 0.0913\n",
      "Epoch 4/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1657 - out_2_loss: 0.0837 - out_4_loss: 0.0820\n",
      "Epoch 00004: loss improved from 0.18373 to 0.16600, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 62s 103ms/sample - loss: 0.1660 - out_2_loss: 0.0839 - out_4_loss: 0.0821\n",
      "Epoch 5/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1508 - out_2_loss: 0.0765 - out_4_loss: 0.0743\n",
      "Epoch 00005: loss improved from 0.16600 to 0.15123, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.1512 - out_2_loss: 0.0767 - out_4_loss: 0.0745\n",
      "Epoch 6/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1388 - out_2_loss: 0.0708 - out_4_loss: 0.0680\n",
      "Epoch 00006: loss improved from 0.15123 to 0.13862, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.1386 - out_2_loss: 0.0707 - out_4_loss: 0.0679\n",
      "Epoch 7/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1345 - out_2_loss: 0.0687 - out_4_loss: 0.0658\n",
      "Epoch 00007: loss improved from 0.13862 to 0.13475, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.1348 - out_2_loss: 0.0688 - out_4_loss: 0.0659\n",
      "Epoch 8/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1374 - out_2_loss: 0.0701 - out_4_loss: 0.0672\n",
      "Epoch 00008: loss did not improve from 0.13475\n",
      "600/600 [==============================] - 60s 99ms/sample - loss: 0.1370 - out_2_loss: 0.0699 - out_4_loss: 0.0670\n",
      "Epoch 9/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1240 - out_2_loss: 0.0638 - out_4_loss: 0.0602\n",
      "Epoch 00009: loss improved from 0.13475 to 0.12380, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 99ms/sample - loss: 0.1238 - out_2_loss: 0.0637 - out_4_loss: 0.0601\n",
      "Epoch 10/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1188 - out_2_loss: 0.0614 - out_4_loss: 0.0575\n",
      "Epoch 00010: loss improved from 0.12380 to 0.11954, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.1195 - out_2_loss: 0.0617 - out_4_loss: 0.0578\n",
      "Epoch 11/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1172 - out_2_loss: 0.0604 - out_4_loss: 0.0568\n",
      "Epoch 00011: loss improved from 0.11954 to 0.11757, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.1176 - out_2_loss: 0.0606 - out_4_loss: 0.0570\n",
      "Epoch 12/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1122 - out_2_loss: 0.0580 - out_4_loss: 0.0542\n",
      "Epoch 00012: loss improved from 0.11757 to 0.11201, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.1120 - out_2_loss: 0.0579 - out_4_loss: 0.0541\n",
      "Epoch 13/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1124 - out_2_loss: 0.0581 - out_4_loss: 0.0543\n",
      "Epoch 00013: loss did not improve from 0.11201\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.1127 - out_2_loss: 0.0582 - out_4_loss: 0.0545\n",
      "Epoch 14/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1077 - out_2_loss: 0.0560 - out_4_loss: 0.0517\n",
      "Epoch 00014: loss improved from 0.11201 to 0.10744, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 101ms/sample - loss: 0.1074 - out_2_loss: 0.0558 - out_4_loss: 0.0516\n",
      "Epoch 15/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1125 - out_2_loss: 0.0582 - out_4_loss: 0.0544\n",
      "Epoch 00015: loss did not improve from 0.10744\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.1124 - out_2_loss: 0.0581 - out_4_loss: 0.0543\n",
      "Epoch 16/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1049 - out_2_loss: 0.0544 - out_4_loss: 0.0504\n",
      "Epoch 00016: loss improved from 0.10744 to 0.10486, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.1049 - out_2_loss: 0.0545 - out_4_loss: 0.0504\n",
      "Epoch 17/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1045 - out_2_loss: 0.0543 - out_4_loss: 0.0503\n",
      "Epoch 00017: loss improved from 0.10486 to 0.10434, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.1043 - out_2_loss: 0.0542 - out_4_loss: 0.0502\n",
      "Epoch 18/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0958 - out_2_loss: 0.0502 - out_4_loss: 0.0456\n",
      "Epoch 00018: loss improved from 0.10434 to 0.09574, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0957 - out_2_loss: 0.0502 - out_4_loss: 0.0456\n",
      "Epoch 19/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0944 - out_2_loss: 0.0495 - out_4_loss: 0.0449\n",
      "Epoch 00019: loss improved from 0.09574 to 0.09425, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0943 - out_2_loss: 0.0494 - out_4_loss: 0.0449\n",
      "Epoch 20/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0927 - out_2_loss: 0.0487 - out_4_loss: 0.0440\n",
      "Epoch 00020: loss improved from 0.09425 to 0.09257, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0926 - out_2_loss: 0.0486 - out_4_loss: 0.0439\n",
      "Epoch 21/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0927 - out_2_loss: 0.0487 - out_4_loss: 0.0441\n",
      "Epoch 00021: loss did not improve from 0.09257\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0929 - out_2_loss: 0.0487 - out_4_loss: 0.0441\n",
      "Epoch 22/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0874 - out_2_loss: 0.0462 - out_4_loss: 0.0412\n",
      "Epoch 00022: loss improved from 0.09257 to 0.08728, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0873 - out_2_loss: 0.0462 - out_4_loss: 0.0411\n",
      "Epoch 23/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0834 - out_2_loss: 0.0443 - out_4_loss: 0.0391\n",
      "Epoch 00023: loss improved from 0.08728 to 0.08364, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 61s 101ms/sample - loss: 0.0836 - out_2_loss: 0.0444 - out_4_loss: 0.0393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0823 - out_2_loss: 0.0437 - out_4_loss: 0.0386\n",
      "Epoch 00024: loss improved from 0.08364 to 0.08214, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0821 - out_2_loss: 0.0437 - out_4_loss: 0.0385\n",
      "Epoch 25/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0837 - out_2_loss: 0.0443 - out_4_loss: 0.0394\n",
      "Epoch 00025: loss did not improve from 0.08214\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0837 - out_2_loss: 0.0443 - out_4_loss: 0.0394\n",
      "Epoch 26/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0790 - out_2_loss: 0.0421 - out_4_loss: 0.0369\n",
      "Epoch 00026: loss improved from 0.08214 to 0.07890, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0789 - out_2_loss: 0.0421 - out_4_loss: 0.0368\n",
      "Epoch 27/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0758 - out_2_loss: 0.0407 - out_4_loss: 0.0351\n",
      "Epoch 00027: loss improved from 0.07890 to 0.07601, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 61s 102ms/sample - loss: 0.0760 - out_2_loss: 0.0408 - out_4_loss: 0.0352\n",
      "Epoch 28/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0874 - out_2_loss: 0.0460 - out_4_loss: 0.0414\n",
      "Epoch 00028: loss did not improve from 0.07601\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0873 - out_2_loss: 0.0460 - out_4_loss: 0.0413\n",
      "Epoch 29/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0817 - out_2_loss: 0.0433 - out_4_loss: 0.0384\n",
      "Epoch 00029: loss did not improve from 0.07601\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0818 - out_2_loss: 0.0433 - out_4_loss: 0.0385\n",
      "Epoch 30/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0761 - out_2_loss: 0.0408 - out_4_loss: 0.0353\n",
      "Epoch 00030: loss did not improve from 0.07601\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0762 - out_2_loss: 0.0409 - out_4_loss: 0.0354\n",
      "Epoch 31/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0676 - out_2_loss: 0.0368 - out_4_loss: 0.0308\n",
      "Epoch 00031: loss improved from 0.07601 to 0.06752, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0675 - out_2_loss: 0.0368 - out_4_loss: 0.0307\n",
      "Epoch 32/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0638 - out_2_loss: 0.0350 - out_4_loss: 0.0288\n",
      "Epoch 00032: loss improved from 0.06752 to 0.06375, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0637 - out_2_loss: 0.0350 - out_4_loss: 0.0288\n",
      "Epoch 33/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0625 - out_2_loss: 0.0344 - out_4_loss: 0.0281\n",
      "Epoch 00033: loss improved from 0.06375 to 0.06282, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 61s 101ms/sample - loss: 0.0628 - out_2_loss: 0.0345 - out_4_loss: 0.0283\n",
      "Epoch 34/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0620 - out_2_loss: 0.0342 - out_4_loss: 0.0278\n",
      "Epoch 00034: loss improved from 0.06282 to 0.06209, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0621 - out_2_loss: 0.0342 - out_4_loss: 0.0278\n",
      "Epoch 35/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0618 - out_2_loss: 0.0341 - out_4_loss: 0.0277\n",
      "Epoch 00035: loss improved from 0.06209 to 0.06178, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0618 - out_2_loss: 0.0341 - out_4_loss: 0.0277\n",
      "Epoch 36/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0582 - out_2_loss: 0.0324 - out_4_loss: 0.0258\n",
      "Epoch 00036: loss improved from 0.06178 to 0.05826, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0583 - out_2_loss: 0.0324 - out_4_loss: 0.0259\n",
      "Epoch 37/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0619 - out_2_loss: 0.0340 - out_4_loss: 0.0279\n",
      "Epoch 00037: loss did not improve from 0.05826\n",
      "600/600 [==============================] - 60s 99ms/sample - loss: 0.0621 - out_2_loss: 0.0341 - out_4_loss: 0.0280\n",
      "Epoch 38/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0654 - out_2_loss: 0.0357 - out_4_loss: 0.0297\n",
      "Epoch 00038: loss did not improve from 0.05826\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0653 - out_2_loss: 0.0357 - out_4_loss: 0.0296\n",
      "Epoch 39/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0590 - out_2_loss: 0.0327 - out_4_loss: 0.0263\n",
      "Epoch 00039: loss did not improve from 0.05826\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0590 - out_2_loss: 0.0327 - out_4_loss: 0.0263\n",
      "Epoch 40/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0536 - out_2_loss: 0.0304 - out_4_loss: 0.0232\n",
      "Epoch 00040: loss improved from 0.05826 to 0.05377, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 99ms/sample - loss: 0.0538 - out_2_loss: 0.0305 - out_4_loss: 0.0233\n",
      "Epoch 41/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0507 - out_2_loss: 0.0291 - out_4_loss: 0.0216\n",
      "Epoch 00041: loss improved from 0.05377 to 0.05067, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 99ms/sample - loss: 0.0507 - out_2_loss: 0.0290 - out_4_loss: 0.0216\n",
      "Epoch 42/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0503 - out_2_loss: 0.0288 - out_4_loss: 0.0215\n",
      "Epoch 00042: loss improved from 0.05067 to 0.05024, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0502 - out_2_loss: 0.0288 - out_4_loss: 0.0215\n",
      "Epoch 43/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0495 - out_2_loss: 0.0284 - out_4_loss: 0.0210\n",
      "Epoch 00043: loss improved from 0.05024 to 0.04956, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0496 - out_2_loss: 0.0285 - out_4_loss: 0.0211\n",
      "Epoch 44/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0484 - out_2_loss: 0.0280 - out_4_loss: 0.0205\n",
      "Epoch 00044: loss improved from 0.04956 to 0.04839, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0484 - out_2_loss: 0.0279 - out_4_loss: 0.0204\n",
      "Epoch 45/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0475 - out_2_loss: 0.0275 - out_4_loss: 0.0199\n",
      "Epoch 00045: loss improved from 0.04839 to 0.04741, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 61s 101ms/sample - loss: 0.0474 - out_2_loss: 0.0275 - out_4_loss: 0.0199\n",
      "Epoch 46/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0471 - out_2_loss: 0.0274 - out_4_loss: 0.0197\n",
      "Epoch 00046: loss improved from 0.04741 to 0.04699, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0470 - out_2_loss: 0.0273 - out_4_loss: 0.0196\n",
      "Epoch 47/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0471 - out_2_loss: 0.0273 - out_4_loss: 0.0198\n",
      "Epoch 00047: loss did not improve from 0.04699\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0472 - out_2_loss: 0.0273 - out_4_loss: 0.0198\n",
      "Epoch 48/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0465 - out_2_loss: 0.0271 - out_4_loss: 0.0194\n",
      "Epoch 00048: loss improved from 0.04699 to 0.04655, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0466 - out_2_loss: 0.0271 - out_4_loss: 0.0194\n",
      "Epoch 49/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0466 - out_2_loss: 0.0271 - out_4_loss: 0.0194\n",
      "Epoch 00049: loss did not improve from 0.04655\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0466 - out_2_loss: 0.0272 - out_4_loss: 0.0195\n",
      "Epoch 50/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0447 - out_2_loss: 0.0263 - out_4_loss: 0.0184\n",
      "Epoch 00050: loss improved from 0.04655 to 0.04463, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0446 - out_2_loss: 0.0262 - out_4_loss: 0.0184\n",
      "Epoch 51/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0430 - out_2_loss: 0.0257 - out_4_loss: 0.0173\n",
      "Epoch 00051: loss improved from 0.04463 to 0.04292, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0429 - out_2_loss: 0.0257 - out_4_loss: 0.0172\n",
      "Epoch 52/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0431 - out_2_loss: 0.0257 - out_4_loss: 0.0174\n",
      "Epoch 00052: loss did not improve from 0.04292\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0430 - out_2_loss: 0.0256 - out_4_loss: 0.0174\n",
      "Epoch 53/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0429 - out_2_loss: 0.0255 - out_4_loss: 0.0173\n",
      "Epoch 00053: loss improved from 0.04292 to 0.04288, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0429 - out_2_loss: 0.0255 - out_4_loss: 0.0173\n",
      "Epoch 54/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0423 - out_2_loss: 0.0254 - out_4_loss: 0.0169\n",
      "Epoch 00054: loss improved from 0.04288 to 0.04226, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0423 - out_2_loss: 0.0254 - out_4_loss: 0.0169\n",
      "Epoch 55/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0411 - out_2_loss: 0.0248 - out_4_loss: 0.0163\n",
      "Epoch 00055: loss improved from 0.04226 to 0.04123, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0412 - out_2_loss: 0.0249 - out_4_loss: 0.0163\n",
      "Epoch 56/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0407 - out_2_loss: 0.0247 - out_4_loss: 0.0160\n",
      "Epoch 00056: loss improved from 0.04123 to 0.04074, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0407 - out_2_loss: 0.0247 - out_4_loss: 0.0160\n",
      "Epoch 57/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0411 - out_2_loss: 0.0248 - out_4_loss: 0.0163\n",
      "Epoch 00057: loss did not improve from 0.04074\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0411 - out_2_loss: 0.0248 - out_4_loss: 0.0163\n",
      "Epoch 58/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0403 - out_2_loss: 0.0245 - out_4_loss: 0.0158\n",
      "Epoch 00058: loss improved from 0.04074 to 0.04028, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0403 - out_2_loss: 0.0245 - out_4_loss: 0.0158\n",
      "Epoch 59/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0403 - out_2_loss: 0.0245 - out_4_loss: 0.0158\n",
      "Epoch 00059: loss improved from 0.04028 to 0.04027, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0403 - out_2_loss: 0.0245 - out_4_loss: 0.0158\n",
      "Epoch 60/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0396 - out_2_loss: 0.0242 - out_4_loss: 0.0154\n",
      "Epoch 00060: loss improved from 0.04027 to 0.03962, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0396 - out_2_loss: 0.0242 - out_4_loss: 0.0154\n",
      "Epoch 61/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0400 - out_2_loss: 0.0244 - out_4_loss: 0.0156\n",
      "Epoch 00061: loss did not improve from 0.03962\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0400 - out_2_loss: 0.0244 - out_4_loss: 0.0156\n",
      "Epoch 62/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0395 - out_2_loss: 0.0242 - out_4_loss: 0.0153\n",
      "Epoch 00062: loss improved from 0.03962 to 0.03950, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0395 - out_2_loss: 0.0242 - out_4_loss: 0.0153\n",
      "Epoch 63/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0387 - out_2_loss: 0.0240 - out_4_loss: 0.0148\n",
      "Epoch 00063: loss improved from 0.03950 to 0.03870, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0387 - out_2_loss: 0.0239 - out_4_loss: 0.0147\n",
      "Epoch 64/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0403 - out_2_loss: 0.0245 - out_4_loss: 0.0158\n",
      "Epoch 00064: loss did not improve from 0.03870\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0402 - out_2_loss: 0.0244 - out_4_loss: 0.0158\n",
      "Epoch 65/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0439 - out_2_loss: 0.0260 - out_4_loss: 0.0179\n",
      "Epoch 00065: loss did not improve from 0.03870\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0439 - out_2_loss: 0.0260 - out_4_loss: 0.0179\n",
      "Epoch 66/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0397 - out_2_loss: 0.0243 - out_4_loss: 0.0155\n",
      "Epoch 00066: loss did not improve from 0.03870\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0397 - out_2_loss: 0.0243 - out_4_loss: 0.0154\n",
      "Epoch 67/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0543 - out_2_loss: 0.0307 - out_4_loss: 0.0236\n",
      "Epoch 00067: loss did not improve from 0.03870\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0546 - out_2_loss: 0.0309 - out_4_loss: 0.0237\n",
      "Epoch 68/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0435 - out_2_loss: 0.0258 - out_4_loss: 0.0177\n",
      "Epoch 00068: loss did not improve from 0.03870\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0435 - out_2_loss: 0.0258 - out_4_loss: 0.0177\n",
      "Epoch 69/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0372 - out_2_loss: 0.0233 - out_4_loss: 0.0139\n",
      "Epoch 00069: loss improved from 0.03870 to 0.03724, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0372 - out_2_loss: 0.0233 - out_4_loss: 0.0139\n",
      "Epoch 70/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0360 - out_2_loss: 0.0229 - out_4_loss: 0.0131\n",
      "Epoch 00070: loss improved from 0.03724 to 0.03599, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0360 - out_2_loss: 0.0229 - out_4_loss: 0.0131\n",
      "Epoch 71/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0357 - out_2_loss: 0.0228 - out_4_loss: 0.0130\n",
      "Epoch 00071: loss improved from 0.03599 to 0.03573, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0357 - out_2_loss: 0.0228 - out_4_loss: 0.0130\n",
      "Epoch 72/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0354 - out_2_loss: 0.0226 - out_4_loss: 0.0127\n",
      "Epoch 00072: loss improved from 0.03573 to 0.03537, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0354 - out_2_loss: 0.0226 - out_4_loss: 0.0127\n",
      "Epoch 73/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0349 - out_2_loss: 0.0224 - out_4_loss: 0.0125\n",
      "Epoch 00073: loss improved from 0.03537 to 0.03492, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 61s 101ms/sample - loss: 0.0349 - out_2_loss: 0.0224 - out_4_loss: 0.0125\n",
      "Epoch 74/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0348 - out_2_loss: 0.0224 - out_4_loss: 0.0123\n",
      "Epoch 00074: loss improved from 0.03492 to 0.03479, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 99ms/sample - loss: 0.0348 - out_2_loss: 0.0224 - out_4_loss: 0.0123\n",
      "Epoch 75/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0346 - out_2_loss: 0.0224 - out_4_loss: 0.0123\n",
      "Epoch 00075: loss improved from 0.03479 to 0.03467, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0347 - out_2_loss: 0.0224 - out_4_loss: 0.0123\n",
      "Epoch 76/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0346 - out_2_loss: 0.0224 - out_4_loss: 0.0123\n",
      "Epoch 00076: loss improved from 0.03467 to 0.03466, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0347 - out_2_loss: 0.0224 - out_4_loss: 0.0123\n",
      "Epoch 77/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0341 - out_2_loss: 0.0222 - out_4_loss: 0.0119\n",
      "Epoch 00077: loss improved from 0.03466 to 0.03409, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 99ms/sample - loss: 0.0341 - out_2_loss: 0.0222 - out_4_loss: 0.0119\n",
      "Epoch 78/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0347 - out_2_loss: 0.0224 - out_4_loss: 0.0123\n",
      "Epoch 00078: loss did not improve from 0.03409\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0346 - out_2_loss: 0.0224 - out_4_loss: 0.0123\n",
      "Epoch 79/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0343 - out_2_loss: 0.0223 - out_4_loss: 0.0120\n",
      "Epoch 00079: loss did not improve from 0.03409\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0343 - out_2_loss: 0.0223 - out_4_loss: 0.0120\n",
      "Epoch 80/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0349 - out_2_loss: 0.0225 - out_4_loss: 0.0125\n",
      "Epoch 00080: loss did not improve from 0.03409\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0349 - out_2_loss: 0.0225 - out_4_loss: 0.0125\n",
      "Epoch 81/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0355 - out_2_loss: 0.0226 - out_4_loss: 0.0129\n",
      "Epoch 00081: loss did not improve from 0.03409\n",
      "600/600 [==============================] - 60s 99ms/sample - loss: 0.0355 - out_2_loss: 0.0226 - out_4_loss: 0.0129\n",
      "Epoch 82/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0416 - out_2_loss: 0.0252 - out_4_loss: 0.0164\n",
      "Epoch 00082: loss did not improve from 0.03409\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.0416 - out_2_loss: 0.0252 - out_4_loss: 0.0164\n",
      "Epoch 83/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0378 - out_2_loss: 0.0236 - out_4_loss: 0.0143\n",
      "Epoch 00083: loss did not improve from 0.03409\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0378 - out_2_loss: 0.0236 - out_4_loss: 0.0142\n",
      "Epoch 84/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0353 - out_2_loss: 0.0226 - out_4_loss: 0.0127\n",
      "Epoch 00084: loss did not improve from 0.03409\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0353 - out_2_loss: 0.0226 - out_4_loss: 0.0127\n",
      "Epoch 85/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0344 - out_2_loss: 0.0223 - out_4_loss: 0.0121\n",
      "Epoch 00085: loss did not improve from 0.03409\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0344 - out_2_loss: 0.0223 - out_4_loss: 0.0121\n",
      "Epoch 86/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0337 - out_2_loss: 0.0221 - out_4_loss: 0.0117\n",
      "Epoch 00086: loss improved from 0.03409 to 0.03376, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0338 - out_2_loss: 0.0221 - out_4_loss: 0.0117\n",
      "Epoch 87/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0336 - out_2_loss: 0.0220 - out_4_loss: 0.0116\n",
      "Epoch 00087: loss improved from 0.03376 to 0.03362, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0336 - out_2_loss: 0.0220 - out_4_loss: 0.0116\n",
      "Epoch 88/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0378 - out_2_loss: 0.0236 - out_4_loss: 0.0143\n",
      "Epoch 00088: loss did not improve from 0.03362\n",
      "600/600 [==============================] - 60s 99ms/sample - loss: 0.0378 - out_2_loss: 0.0236 - out_4_loss: 0.0142\n",
      "Epoch 89/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0355 - out_2_loss: 0.0227 - out_4_loss: 0.0128\n",
      "Epoch 00089: loss did not improve from 0.03362\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0355 - out_2_loss: 0.0227 - out_4_loss: 0.0128\n",
      "Epoch 90/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0333 - out_2_loss: 0.0219 - out_4_loss: 0.0114\n",
      "Epoch 00090: loss improved from 0.03362 to 0.03330, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0333 - out_2_loss: 0.0219 - out_4_loss: 0.0114\n",
      "Epoch 91/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0330 - out_2_loss: 0.0218 - out_4_loss: 0.0112\n",
      "Epoch 00091: loss improved from 0.03330 to 0.03300, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0330 - out_2_loss: 0.0218 - out_4_loss: 0.0112\n",
      "Epoch 92/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0330 - out_2_loss: 0.0218 - out_4_loss: 0.0112\n",
      "Epoch 00092: loss improved from 0.03300 to 0.03298, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0330 - out_2_loss: 0.0218 - out_4_loss: 0.0112\n",
      "Epoch 93/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0326 - out_2_loss: 0.0217 - out_4_loss: 0.0109\n",
      "Epoch 00093: loss improved from 0.03298 to 0.03263, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_2.h5\n",
      "600/600 [==============================] - 60s 99ms/sample - loss: 0.0326 - out_2_loss: 0.0217 - out_4_loss: 0.0109\n",
      "Epoch 94/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0333 - out_2_loss: 0.0219 - out_4_loss: 0.0114\n",
      "Epoch 00094: loss did not improve from 0.03263\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0333 - out_2_loss: 0.0219 - out_4_loss: 0.0114\n",
      "Epoch 95/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0333 - out_2_loss: 0.0219 - out_4_loss: 0.0114\n",
      "Epoch 00095: loss did not improve from 0.03263\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0332 - out_2_loss: 0.0219 - out_4_loss: 0.0113\n",
      "Epoch 96/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0332 - out_2_loss: 0.0218 - out_4_loss: 0.0113\n",
      "Epoch 00096: loss did not improve from 0.03263\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0332 - out_2_loss: 0.0218 - out_4_loss: 0.0113\n",
      "Epoch 97/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0338 - out_2_loss: 0.0221 - out_4_loss: 0.0117\n",
      "Epoch 00097: loss did not improve from 0.03263\n",
      "600/600 [==============================] - 61s 101ms/sample - loss: 0.0338 - out_2_loss: 0.0221 - out_4_loss: 0.0117\n",
      "Epoch 98/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0332 - out_2_loss: 0.0219 - out_4_loss: 0.0113\n",
      "Epoch 00098: loss did not improve from 0.03263\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0332 - out_2_loss: 0.0219 - out_4_loss: 0.0113\n",
      "Epoch 99/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0340 - out_2_loss: 0.0221 - out_4_loss: 0.0119\n",
      "Epoch 00099: loss did not improve from 0.03263\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0340 - out_2_loss: 0.0221 - out_4_loss: 0.0119\n",
      "Epoch 100/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0343 - out_2_loss: 0.0222 - out_4_loss: 0.0120\n",
      "Epoch 00100: loss did not improve from 0.03263\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0342 - out_2_loss: 0.0222 - out_4_loss: 0.0120\n"
     ]
    }
   ],
   "source": [
    "print('Fitting model...')\n",
    "print('-'*200)\n",
    "hist = MVAU_Net.fit(train_image, [train_label, train_label], batch_size=4, epochs=100, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:58:34.074955Z",
     "start_time": "2021-12-07T07:58:24.703596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 8s 39ms/sample\n"
     ]
    }
   ],
   "source": [
    "a2c_a4c_pred_2, a2c_a4c_pred_4 = MVAU_Net.predict(validation_image, verbose=1)\n",
    "a2c_a4c_pred_4 = np.array(a2c_a4c_pred_4 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:58:12.685558Z",
     "start_time": "2021-12-07T07:58:08.386114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 4s 39ms/sample\n"
     ]
    }
   ],
   "source": [
    "_, test_prediction = MVAU_Net.predict(test_image, verbose=1)\n",
    "test_prediction = np.array(test_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:58:36.627312Z",
     "start_time": "2021-12-07T07:58:36.294328Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('../../result/CV/CV_2_valid_prediction.npy', a2c_a4c_pred_4)\n",
    "np.save('../../result/CV/CV_2_test_prediction.npy', test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:53:29.814120Z",
     "start_time": "2021-12-07T07:53:24.797635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall    :  0.937  0.062\n",
      "Precision :  0.932  0.094\n",
      "Accuracy  :  0.994  0.005\n",
      "DSC       :  0.929  0.057\n",
      "Jaccard   :  0.873  0.091\n"
     ]
    }
   ],
   "source": [
    "a2c_a4c_pred_2 = np.array(a2c_a4c_pred_2 > 0.5)\n",
    "a2c_a4c_pred_4 = np.array(a2c_a4c_pred_4 > 0.5)\n",
    "\n",
    "recall_list = []\n",
    "pricision_list = []\n",
    "acc_list = []\n",
    "dice_list = []\n",
    "jaccard_list = []\n",
    "\n",
    "\n",
    "for i in range(test_label.shape[0]):\n",
    "    \n",
    "    seg1 = a2c_a4c_pred_4[i,:,:,0,0]\n",
    "    gt1 = validation_label[i,:,:,0,0]\n",
    "\n",
    "    seg1_n = seg1 == 0\n",
    "    seg1_t = seg1 == 1\n",
    "\n",
    "    gt1_n = gt1 == 0\n",
    "    gt1_t = gt1 == 1\n",
    "\n",
    "\n",
    "    tp = np.sum(seg1_t&gt1_t)\n",
    "\n",
    "    fp = np.sum(seg1_t&gt1_n)\n",
    "\n",
    "    tn = np.sum(seg1_n&gt1_n)\n",
    "\n",
    "    fn = np.sum(gt1_t&seg1_n)\n",
    "\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "#     print('Sensitivity : ', sensitivity)\n",
    "\n",
    "\n",
    "    pricision = tp / (tp+fp)\n",
    "    pricision_list.append(pricision)\n",
    "\n",
    "#     print('Specificity : ', specificity)\n",
    "\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    acc_list.append(acc)\n",
    "#     print('Accuracy : ', acc)\n",
    "\n",
    "    dice = (2*tp) / (2*tp + fp + fn)\n",
    "    dice_list.append(dice)\n",
    "#     print('DSC : ', dice)\n",
    "    \n",
    "    jaccard_list.append(jaccard_score(gt1, seg1, average='micro'))\n",
    "    \n",
    "    \n",
    "dice_list_1 = np.array(dice_list)\n",
    "recall_list_1 = np.array(recall_list)\n",
    "pricision_list_1 = np.array(pricision_list)\n",
    "jaccard_list_1 = np.array(jaccard_list)\n",
    "\n",
    "dice_list_1 = dice_list_1[~np.isnan(dice_list_1)]\n",
    "recall_list_1 = recall_list_1[~np.isnan(recall_list_1)]\n",
    "pricision_list_1 = pricision_list_1[~np.isnan(pricision_list_1)]\n",
    "jaccard_list_1 = jaccard_list_1[~np.isnan(jaccard_list_1)]\n",
    "\n",
    "print('Recall    : ', round(np.mean(recall_list_1), 3), '', round(np.std(recall_list_1), 3))\n",
    "print('Precision : ', round( np.mean(pricision_list_1), 3), '', round( np.std(pricision_list_1), 3))\n",
    "print('Accuracy  : ', round(np.mean(acc_list), 3), '', round( np.std(acc_list), 3))\n",
    "print('DSC       : ', round(np.mean(dice_list_1), 3), '', round( np.std(dice_list_1), 3))\n",
    "print('Jaccard   : ', round(np.mean(jaccard_list_1), 3), '', round( np.std(jaccard_list_1), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:54:38.184358Z",
     "start_time": "2021-12-07T07:54:31.070135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall    :  0.95  0.045\n",
      "Precision :  0.962  0.042\n",
      "Accuracy  :  0.996  0.003\n",
      "DSC       :  0.955  0.031\n",
      "Jaccard   :  0.915  0.052\n"
     ]
    }
   ],
   "source": [
    "recall_list = []\n",
    "pricision_list = []\n",
    "acc_list = []\n",
    "dice_list = []\n",
    "jaccard_list = []\n",
    "\n",
    "\n",
    "for i in range(validation_label.shape[0]):\n",
    "    \n",
    "    seg1 = a2c_a4c_pred_4[i,:,:,0,1]\n",
    "    gt1 = validation_label[i,:,:,0,1]\n",
    "\n",
    "    seg1_n = seg1 == 0\n",
    "    seg1_t = seg1 == 1\n",
    "\n",
    "    gt1_n = gt1 == 0\n",
    "    gt1_t = gt1 == 1\n",
    "\n",
    "\n",
    "    tp = np.sum(seg1_t&gt1_t)\n",
    "\n",
    "    fp = np.sum(seg1_t&gt1_n)\n",
    "\n",
    "    tn = np.sum(seg1_n&gt1_n)\n",
    "\n",
    "    fn = np.sum(gt1_t&seg1_n)\n",
    "\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "#     print('Sensitivity : ', sensitivity)\n",
    "\n",
    "\n",
    "    pricision = tp / (tp+fp)\n",
    "    pricision_list.append(pricision)\n",
    "\n",
    "#     print('Specificity : ', specificity)\n",
    "\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    acc_list.append(acc)\n",
    "#     print('Accuracy : ', acc)\n",
    "\n",
    "    dice = (2*tp) / (2*tp + fp + fn)\n",
    "    dice_list.append(dice)\n",
    "#     print('DSC : ', dice)\n",
    "    \n",
    "    jaccard_list.append(jaccard_score(gt1, seg1, average='micro'))\n",
    "    \n",
    "    \n",
    "dice_list_1 = np.array(dice_list)\n",
    "recall_list_1 = np.array(recall_list)\n",
    "pricision_list_1 = np.array(pricision_list)\n",
    "jaccard_list_1 = np.array(jaccard_list)\n",
    "\n",
    "dice_list_1 = dice_list_1[~np.isnan(dice_list_1)]\n",
    "recall_list_1 = recall_list_1[~np.isnan(recall_list_1)]\n",
    "pricision_list_1 = pricision_list_1[~np.isnan(pricision_list_1)]\n",
    "jaccard_list_1 = jaccard_list_1[~np.isnan(jaccard_list_1)]\n",
    "\n",
    "print('Recall    : ', round(np.mean(recall_list_1), 3), '', round(np.std(recall_list_1), 3))\n",
    "print('Precision : ', round( np.mean(pricision_list_1), 3), '', round( np.std(pricision_list_1), 3))\n",
    "print('Accuracy  : ', round(np.mean(acc_list), 3), '', round( np.std(acc_list), 3))\n",
    "print('DSC       : ', round(np.mean(dice_list_1), 3), '', round( np.std(dice_list_1), 3))\n",
    "print('Jaccard   : ', round(np.mean(jaccard_list_1), 3), '', round( np.std(jaccard_list_1), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:53:49.035025Z",
     "start_time": "2021-12-07T07:53:33.434196Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sl in range(20):\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(test_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(test_label[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(test_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.imshow(test_label[sl,:,:,:,0], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(test_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.imshow(test_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,0], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:54:04.705223Z",
     "start_time": "2021-12-07T07:53:49.039874Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sl in range(20):\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(test_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(test_label[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(test_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.imshow(test_label[sl,:,:,:,1], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(test_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.imshow(test_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,1], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
