{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:26.569388Z",
     "start_time": "2021-12-07T06:13:24.296034Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.python.keras.models import *\n",
    "\n",
    "from tensorflow.python.keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:26.599306Z",
     "start_time": "2021-12-07T06:13:26.573413Z"
    }
   },
   "outputs": [],
   "source": [
    "epsilon = K.epsilon()\n",
    "gamma = 0\n",
    "alpha = 0.6\n",
    "beta = 0.6\n",
    "\n",
    "  \n",
    "def recall(y_true, y_pred):\n",
    "\n",
    "    y_true_yn = K.round(K.clip(y_true, 0, 1))\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "    count_true_positive = K.sum(y_true_yn * y_pred_yn)     \n",
    "    count_true_positive_false_negative = K.sum(y_true_yn)\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_true_yn = K.round(K.clip(y_true, 0, 1))\n",
    "    count_true_positive = K.sum(y_true_yn * y_pred_yn) \n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    _recall = recall(y_true, y_pred)\n",
    "    _precision = precision(y_true, y_pred)\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "\n",
    "    return _f1score\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def balanced_loss(y_true, y_pred):\n",
    "    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n",
    "    pt = K.clip(pt, epsilon, 1-epsilon)\n",
    "    CE = -K.log(pt)\n",
    "    BL = alpha * CE\n",
    "    \n",
    "    return K.sum(BL, axis=1)\n",
    "\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n",
    "    pt = K.clip(pt, epsilon, 1-epsilon)\n",
    "    CE = -K.log(pt)\n",
    "    FL = alpha * K.pow(1-pt, gamma) * CE\n",
    "    \n",
    "    return K.sum(FL, axis=1)\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=0.001):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def cus_loss(y_true, y_pred):\n",
    "    \n",
    "    return (1 - beta) * focal_loss(y_true, y_pred) + beta * dice_coef_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "get_custom_objects().update({\n",
    "    \n",
    "    'cus_loss': cus_loss,\n",
    "    'iou_coef' : iou_coef,\n",
    "    'f1score' : f1score,\n",
    "    'precision' : precision,\n",
    "    'recall' : recall,\n",
    "    'balanced_loss' : balanced_loss,\n",
    "    'focal_loss' : focal_loss,\n",
    "    'dice_coef' : dice_coef,\n",
    "    'dice_coef_loss' : dice_coef_loss,\n",
    "    'cus_loss' : cus_loss,\n",
    "        \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:35.416015Z",
     "start_time": "2021-12-07T06:13:26.602602Z"
    }
   },
   "outputs": [],
   "source": [
    "train_a2c_image = np.load('../../data/dataset/train/train_A2C_image.npy').astype(np.float32)\n",
    "train_a2c_label = np.load('../../data/dataset/train/train_A2C_label.npy').astype(np.float32)\n",
    "\n",
    "train_a4c_image = np.load('../../data/dataset/train/train_A4C_image.npy').astype(np.float32)\n",
    "train_a4c_label = np.load('../../data/dataset/train/train_A4C_label.npy').astype(np.float32)\n",
    "\n",
    "\n",
    "test_a2c_image = np.load('../../data/dataset/test/test_A2C_image.npy').astype(np.float32)\n",
    "test_a2c_label = np.load('../../data/dataset/test/test_A2C_label.npy').astype(np.float32)\n",
    "\n",
    "test_a4c_image = np.load('../../data/dataset/test/test_A4C_image.npy').astype(np.float32)\n",
    "test_a4c_label = np.load('../../data/dataset/test/test_A4C_label.npy').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:37.378626Z",
     "start_time": "2021-12-07T06:13:35.419820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 255.0\n",
      "0.0 1.0\n",
      "0.0 255.0\n",
      "0.0 1.0\n",
      "0.0 255.0\n",
      "0.0 1.0\n",
      "0.0 255.0\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(train_a2c_image.min(), train_a2c_image.max())\n",
    "print(train_a2c_label.min(), train_a2c_label.max())\n",
    "\n",
    "\n",
    "print(train_a4c_image.min(), train_a4c_image.max())\n",
    "print(train_a4c_label.min(), train_a4c_label.max())\n",
    "\n",
    "\n",
    "print(test_a2c_image.min(), test_a2c_image.max())\n",
    "print(test_a2c_label.min(), test_a2c_label.max())\n",
    "\n",
    "\n",
    "print(test_a4c_image.min(), test_a4c_image.max())\n",
    "print(test_a4c_label.min(), test_a4c_label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:40.310351Z",
     "start_time": "2021-12-07T06:13:37.380173Z"
    }
   },
   "outputs": [],
   "source": [
    "train_a2c_image = train_a2c_image / 255\n",
    "train_a4c_image = train_a4c_image / 255\n",
    "\n",
    "test_a2c_image = test_a2c_image / 255\n",
    "test_a4c_image = test_a4c_image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:41.951146Z",
     "start_time": "2021-12-07T06:13:40.312036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(train_a2c_image.min(), train_a2c_image.max())\n",
    "print(train_a2c_label.min(), train_a2c_label.max())\n",
    "\n",
    "\n",
    "print(train_a4c_image.min(), train_a4c_image.max())\n",
    "print(train_a4c_label.min(), train_a4c_label.max())\n",
    "\n",
    "\n",
    "print(test_a2c_image.min(), test_a2c_image.max())\n",
    "print(test_a2c_label.min(), test_a2c_label.max())\n",
    "\n",
    "\n",
    "print(test_a4c_image.min(), test_a4c_image.max())\n",
    "print(test_a4c_label.min(), test_a4c_label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:41.958587Z",
     "start_time": "2021-12-07T06:13:41.952720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 512, 512, 1)\n",
      "(800, 512, 512, 1)\n",
      "(800, 512, 512, 1)\n",
      "(800, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n",
      "(100, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_a2c_image.shape)\n",
    "print(train_a2c_label.shape)\n",
    "\n",
    "\n",
    "print(train_a4c_image.shape)\n",
    "print(train_a4c_label.shape)\n",
    "\n",
    "\n",
    "print(test_a2c_image.shape)\n",
    "print(test_a2c_label.shape)\n",
    "\n",
    "\n",
    "print(test_a4c_image.shape)\n",
    "print(test_a4c_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:41.976200Z",
     "start_time": "2021-12-07T06:13:41.961338Z"
    }
   },
   "outputs": [],
   "source": [
    "all_train_image = np.zeros((800,512,512,1,2))\n",
    "all_train_label = np.zeros((800,512,512,1,2))\n",
    "\n",
    "test_image = np.zeros((100,512,512,1,2))\n",
    "test_label = np.zeros((100,512,512,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.363866Z",
     "start_time": "2021-12-07T06:13:41.978325Z"
    }
   },
   "outputs": [],
   "source": [
    "all_train_image[:,:,:,:,0] = train_a2c_image\n",
    "all_train_image[:,:,:,:,1] = train_a4c_image\n",
    "\n",
    "all_train_label[:,:,:,:,0] = train_a2c_label\n",
    "all_train_label[:,:,:,:,1] = train_a4c_label\n",
    "\n",
    "test_image[:,:,:,:,0] = test_a2c_image\n",
    "test_image[:,:,:,:,1] = test_a4c_image\n",
    "\n",
    "test_label[:,:,:,:,0] = test_a2c_label\n",
    "test_label[:,:,:,:,1] = test_a4c_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.372867Z",
     "start_time": "2021-12-07T06:13:43.367464Z"
    }
   },
   "outputs": [],
   "source": [
    "train_image_fold_1 = all_train_image[:200]\n",
    "train_image_fold_2 = all_train_image[200:400]\n",
    "train_image_fold_3 = all_train_image[400:600]\n",
    "train_image_fold_4 = all_train_image[600:]\n",
    "\n",
    "\n",
    "train_label_fold_1 = all_train_label[:200]\n",
    "train_label_fold_2 = all_train_label[200:400]\n",
    "train_label_fold_3 = all_train_label[400:600]\n",
    "train_label_fold_4 = all_train_label[600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.442803Z",
     "start_time": "2021-12-07T06:13:43.376146Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CV1\n",
    "# train_image = np.concatenate((train_image_fold_1, train_image_fold_2, train_image_fold_3), axis =0)\n",
    "# train_label = np.concatenate((train_label_fold_1, train_label_fold_2, train_label_fold_3), axis =0)\n",
    "\n",
    "# validation_image = train_image_fold_4\n",
    "# validation_label = train_label_fold_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.456474Z",
     "start_time": "2021-12-07T06:13:43.446448Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CV2\n",
    "# train_image = np.concatenate((train_image_fold_1, train_image_fold_2, train_image_fold_4), axis =0)\n",
    "# train_label = np.concatenate((train_label_fold_1, train_label_fold_2, train_label_fold_4), axis =0)\n",
    "\n",
    "# validation_image = train_image_fold_3\n",
    "# validation_label = train_label_fold_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:43.480975Z",
     "start_time": "2021-12-07T06:13:43.460026Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CV3\n",
    "# train_image = np.concatenate((train_image_fold_1, train_image_fold_3, train_image_fold_4), axis =0)\n",
    "# train_label = np.concatenate((train_label_fold_1, train_label_fold_3, train_label_fold_4), axis =0)\n",
    "\n",
    "# validation_image = train_image_fold_2\n",
    "# validation_label = train_label_fold_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.253762Z",
     "start_time": "2021-12-07T06:13:43.484754Z"
    }
   },
   "outputs": [],
   "source": [
    "# CV4\n",
    "train_image = np.concatenate((train_image_fold_2, train_image_fold_3, train_image_fold_4), axis =0)\n",
    "train_label = np.concatenate((train_label_fold_2, train_label_fold_3, train_label_fold_4), axis =0)\n",
    "\n",
    "validation_image = train_image_fold_1\n",
    "validation_label = train_label_fold_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.263098Z",
     "start_time": "2021-12-07T06:13:44.257209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 512, 512, 1, 2)\n",
      "(600, 512, 512, 1, 2)\n",
      "(200, 512, 512, 1, 2)\n",
      "(200, 512, 512, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_image.shape)\n",
    "print(train_label.shape)\n",
    "\n",
    "print(validation_image.shape)\n",
    "print(validation_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.296538Z",
     "start_time": "2021-12-07T06:13:44.266160Z"
    }
   },
   "outputs": [],
   "source": [
    "def Conv2D_block(input_layer, out_n_filters, kernel_size=[3,3], stride=[1,1], padding='same'):\n",
    "    \n",
    "    layer = input_layer\n",
    "    \n",
    "    for i in range(2):\n",
    "        \n",
    "        layer = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, kernel_initializer = 'he_normal')(layer)\n",
    "        layer = BatchNormalization()(layer)\n",
    "        layer = Activation('relu')(layer)        \n",
    "        \n",
    "    out_layer = layer\n",
    "    \n",
    "    return out_layer\n",
    "    \n",
    "\n",
    "def Up_and_Concate(down_layer, layer):\n",
    "    \n",
    "    input_channel = down_layer.get_shape().as_list()[3]\n",
    "    output_channel = input_channel // 2\n",
    "    \n",
    "    up = UpSampling2D(size = (2,2))(down_layer) \n",
    "\n",
    "    concate = concatenate([up, layer])\n",
    "    return concate\n",
    "\n",
    "def attention_block_2d(x, g, inter_channel):\n",
    "\n",
    "\n",
    "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1])(x)\n",
    "\n",
    "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1])(g)\n",
    "\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "\n",
    "\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1])(f)\n",
    "\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "\n",
    "\n",
    "    att_x = multiply([x, rate])\n",
    "\n",
    "    return att_x\n",
    "\n",
    "\n",
    "def attention_up_and_concate(down_layer, layer):\n",
    "    in_channel = down_layer.get_shape().as_list()[3]\n",
    "\n",
    "    up = UpSampling2D((2, 2))(down_layer)\n",
    "\n",
    "    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4)\n",
    "\n",
    "    concate = concatenate([up, layer])\n",
    "    \n",
    "    return concate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:44.320004Z",
     "start_time": "2021-12-07T06:13:44.299830Z"
    }
   },
   "outputs": [],
   "source": [
    "def AU_Net_2D(input_shape):\n",
    "        \n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    depth = 4\n",
    "    features = 32\n",
    "    down_layer = []\n",
    "    supervision_layer = []\n",
    "    \n",
    "    for i in range(depth):\n",
    "        \n",
    "        x = Conv2D_block(x, features)\n",
    "        down_layer.append(x)\n",
    "        x = MaxPooling2D(pool_size=[2, 2], strides=[2, 2])(x)\n",
    "\n",
    "        features = features * 2\n",
    "        \n",
    "    x = Conv2D_block(x, features)\n",
    "    \n",
    "    for i in reversed(range(depth)):\n",
    "\n",
    "        features = features // 2\n",
    "        \n",
    "        x = attention_up_and_concate(x, down_layer[i])\n",
    "        x = Conv2D_block(x, features)\n",
    "        supervision_layer.append(x)\n",
    "    \n",
    "    \n",
    "\n",
    "    output_2 = UpSampling2D((4, 4))(supervision_layer[1])\n",
    "    output_4 = UpSampling2D((1, 1))(supervision_layer[3])\n",
    "    \n",
    "\n",
    "    model = Model(inputs = inputs, outputs = [output_2, output_4])\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:45.891623Z",
     "start_time": "2021-12-07T06:13:44.322650Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1207 15:13:44.358204 124420638591120 deprecation.py:506] From /opt/anaconda3/envs/powerai_162/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 32) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512, 512, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 32) 9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 256, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 64) 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 128 147584      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 128 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 256)  590080      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 512)  2359808     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 512)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 64, 64, 512)  0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  32896       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  65664       up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 128)  0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 1)    129         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 1)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 64, 64, 256)  0           activation_7[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 768)  0           up_sampling2d[0][0]              \n",
      "                                                                 multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  1769728     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 256)  1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 256)  1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 256 0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 64) 8256        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 64) 16448       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 64) 0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 64) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 1)  65          activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 128, 1)  0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 128, 128, 128 0           activation_5[0][0]               \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 384 0           up_sampling2d_1[0][0]            \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 442496      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 128 512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 128, 128, 128 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 128 147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 128 512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128, 128, 128 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 128 0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 32) 2080        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 32) 4128        up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 256, 32) 0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 256, 256, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 1)  33          activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 256, 256, 1)  0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 256, 256, 64) 0           activation_3[0][0]               \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 192 0           up_sampling2d_2[0][0]            \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 64) 110656      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256, 256, 64) 256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 256, 256, 64) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 64) 36928       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 64) 256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 256, 256, 64) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 512, 512, 64) 0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 512, 512, 16) 528         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 512, 512, 16) 1040        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 512, 512, 16) 0           conv2d_25[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 512, 512, 16) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 512, 512, 1)  17          activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 512, 512, 1)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 512, 512, 32) 0           activation_1[0][0]               \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 96) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 512, 512, 32) 27680       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 512, 512, 32) 128         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 512, 512, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 512, 512, 32) 9248        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 512, 32) 128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 512, 512, 32) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 512, 512, 128 0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 512, 512, 32) 0           activation_25[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 7,989,108\n",
      "Trainable params: 7,983,220\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = AU_Net_2D((512,512,1))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:13:45.902579Z",
     "start_time": "2021-12-07T06:13:45.892937Z"
    }
   },
   "outputs": [],
   "source": [
    "def Multi_View_AU_Net():\n",
    "    \n",
    "    inputs = Input(shape=(512,512,1,2), name='input')\n",
    "    \n",
    "    a2c_view = inputs[:, :, :, :, 0]\n",
    "    a4c_view = inputs[:, :, :, :, 1]\n",
    "    \n",
    "    base_model = AU_Net_2D(input_shape = (512,512,1))\n",
    "    \n",
    "    a2c_view_output_2, a2c_view_output_4 = base_model(a2c_view)\n",
    "    a4c_view_output_2, a4c_view_output_4 = base_model(a4c_view)\n",
    "    \n",
    "    \n",
    "    output_2 = Concatenate()([a2c_view_output_2, a4c_view_output_2])\n",
    "    output_4 = Concatenate()([a2c_view_output_4, a4c_view_output_4])\n",
    "\n",
    "    \n",
    "    fn_output_2 = Dense(32)(output_2)\n",
    "    fn_output_2 = Dropout(0.25)(fn_output_2)\n",
    "    fn_output_2 = Dense(2)(fn_output_2)\n",
    "    \n",
    "    \n",
    "    fn_output_4 = Dense(32)(output_4)\n",
    "    fn_output_4 = Dropout(0.25)(fn_output_4)\n",
    "    fn_output_4 = Dense(2)(fn_output_4)\n",
    "    \n",
    "    \n",
    "\n",
    "    fn_output_2 = K.expand_dims(fn_output_2, 3)\n",
    "    fn_output_4 = K.expand_dims(fn_output_4, 3)\n",
    "    \n",
    "\n",
    "    fn_output_2 = Activation('sigmoid', name='out_2')(fn_output_2)\n",
    "    fn_output_4 = Activation('sigmoid', name='out_4')(fn_output_4)\n",
    "\n",
    "\n",
    "    MVAU_Net = keras.Model(inputs = inputs, outputs = [fn_output_2, fn_output_4], name='MV_AU_Net')\n",
    "\n",
    "    \n",
    "    return MVAU_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:14:25.892716Z",
     "start_time": "2021-12-07T06:13:45.903846Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1207 15:13:47.208445 124420638591120 backend.py:548] OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MV_AU_Net\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input (InputLayer)                               [(None, 512, 512, 1, 2)]         0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (TensorFlowOpLayer)    [(None, 512, 512, 1)]            0                 input[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (TensorFlowOpLayer)  [(None, 512, 512, 1)]            0                 input[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "model_1 (Model)                                  [(None, 512, 512, 128), (None, 5 7989108           tf_op_layer_strided_slice[0][0]                   \n",
      "                                                                                                    tf_op_layer_strided_slice_1[0][0]                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)                      (None, 512, 512, 256)            0                 model_1[1][0]                                     \n",
      "                                                                                                    model_1[2][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)                      (None, 512, 512, 64)             0                 model_1[1][1]                                     \n",
      "                                                                                                    model_1[2][1]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense (Dense)                                    (None, 512, 512, 32)             8224              concatenate_8[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_2 (Dense)                                  (None, 512, 512, 32)             2080              concatenate_9[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dropout (Dropout)                                (None, 512, 512, 32)             0                 dense[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                              (None, 512, 512, 32)             0                 dense_2[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_1 (Dense)                                  (None, 512, 512, 2)              66                dropout[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_3 (Dense)                                  (None, 512, 512, 2)              66                dropout_1[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorFlowOpLayer)       [(None, 512, 512, 1, 2)]         0                 dense_1[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (TensorFlowOpLayer)     [(None, 512, 512, 1, 2)]         0                 dense_3[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "out_2 (Activation)                               (None, 512, 512, 1, 2)           0                 tf_op_layer_ExpandDims[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "out_4 (Activation)                               (None, 512, 512, 1, 2)           0                 tf_op_layer_ExpandDims_1[0][0]                    \n",
      "======================================================================================================================================================\n",
      "Total params: 7,999,544\n",
      "Trainable params: 7,993,656\n",
      "Non-trainable params: 5,888\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MVAU_Net = Multi_View_AU_Net()\n",
    "MVAU_Net.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:14:26.001153Z",
     "start_time": "2021-12-07T06:14:25.895271Z"
    }
   },
   "outputs": [],
   "source": [
    "losses ={'out_2':dice_coef_loss,\n",
    "         'out_4':dice_coef_loss}\n",
    "\n",
    "MVAU_Net.compile(optimizer=Adam(lr=0.001), loss = losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T06:14:26.006005Z",
     "start_time": "2021-12-07T06:14:26.002650Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=5, verbose=1, min_delta=1e-8)\n",
    "earlystopper = EarlyStopping(monitor='loss',patience=30, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5', monitor='loss', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks_list = [model_checkpoint, earlystopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:49:11.312954Z",
     "start_time": "2021-12-07T06:14:26.010148Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train on 600 samples\n",
      "Epoch 1/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.5062 - out_2_loss: 0.2249 - out_4_loss: 0.2813\n",
      "Epoch 00001: loss improved from inf to 0.50416, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 66s 111ms/sample - loss: 0.5042 - out_2_loss: 0.2241 - out_4_loss: 0.2801\n",
      "Epoch 2/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.2201 - out_2_loss: 0.1091 - out_4_loss: 0.1110\n",
      "Epoch 00002: loss improved from 0.50416 to 0.21973, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.2197 - out_2_loss: 0.1089 - out_4_loss: 0.1108\n",
      "Epoch 3/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1853 - out_2_loss: 0.0928 - out_4_loss: 0.0925\n",
      "Epoch 00003: loss improved from 0.21973 to 0.18509, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 63s 105ms/sample - loss: 0.1851 - out_2_loss: 0.0927 - out_4_loss: 0.0924\n",
      "Epoch 4/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1664 - out_2_loss: 0.0840 - out_4_loss: 0.0824\n",
      "Epoch 00004: loss improved from 0.18509 to 0.16683, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.1668 - out_2_loss: 0.0842 - out_4_loss: 0.0826\n",
      "Epoch 5/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1533 - out_2_loss: 0.0778 - out_4_loss: 0.0755\n",
      "Epoch 00005: loss improved from 0.16683 to 0.15360, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.1536 - out_2_loss: 0.0779 - out_4_loss: 0.0757\n",
      "Epoch 6/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1430 - out_2_loss: 0.0728 - out_4_loss: 0.0702\n",
      "Epoch 00006: loss improved from 0.15360 to 0.14317, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.1432 - out_2_loss: 0.0729 - out_4_loss: 0.0703\n",
      "Epoch 7/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1359 - out_2_loss: 0.0694 - out_4_loss: 0.0665\n",
      "Epoch 00007: loss improved from 0.14317 to 0.13610, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.1361 - out_2_loss: 0.0695 - out_4_loss: 0.0666\n",
      "Epoch 8/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1275 - out_2_loss: 0.0655 - out_4_loss: 0.0621\n",
      "Epoch 00008: loss improved from 0.13610 to 0.12742, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.1274 - out_2_loss: 0.0654 - out_4_loss: 0.0620\n",
      "Epoch 9/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1198 - out_2_loss: 0.0616 - out_4_loss: 0.0582\n",
      "Epoch 00009: loss improved from 0.12742 to 0.11991, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 96ms/sample - loss: 0.1199 - out_2_loss: 0.0617 - out_4_loss: 0.0582\n",
      "Epoch 10/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1187 - out_2_loss: 0.0612 - out_4_loss: 0.0575\n",
      "Epoch 00010: loss improved from 0.11991 to 0.11869, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.1187 - out_2_loss: 0.0612 - out_4_loss: 0.0575\n",
      "Epoch 11/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1190 - out_2_loss: 0.0613 - out_4_loss: 0.0576\n",
      "Epoch 00011: loss did not improve from 0.11869\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.1189 - out_2_loss: 0.0613 - out_4_loss: 0.0576\n",
      "Epoch 12/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1275 - out_2_loss: 0.0653 - out_4_loss: 0.0622\n",
      "Epoch 00012: loss did not improve from 0.11869\n",
      "600/600 [==============================] - 60s 100ms/sample - loss: 0.1272 - out_2_loss: 0.0651 - out_4_loss: 0.0621\n",
      "Epoch 13/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1096 - out_2_loss: 0.0568 - out_4_loss: 0.0527\n",
      "Epoch 00013: loss improved from 0.11869 to 0.10926, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.1093 - out_2_loss: 0.0567 - out_4_loss: 0.0526\n",
      "Epoch 14/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1129 - out_2_loss: 0.0583 - out_4_loss: 0.0546\n",
      "Epoch 00014: loss did not improve from 0.10926\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.1126 - out_2_loss: 0.0581 - out_4_loss: 0.0545\n",
      "Epoch 15/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1074 - out_2_loss: 0.0557 - out_4_loss: 0.0517\n",
      "Epoch 00015: loss improved from 0.10926 to 0.10738, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.1074 - out_2_loss: 0.0557 - out_4_loss: 0.0516\n",
      "Epoch 16/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1010 - out_2_loss: 0.0527 - out_4_loss: 0.0483\n",
      "Epoch 00016: loss improved from 0.10738 to 0.10099, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.1010 - out_2_loss: 0.0527 - out_4_loss: 0.0483\n",
      "Epoch 17/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1028 - out_2_loss: 0.0534 - out_4_loss: 0.0494\n",
      "Epoch 00017: loss did not improve from 0.10099\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.1030 - out_2_loss: 0.0535 - out_4_loss: 0.0495\n",
      "Epoch 18/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.1059 - out_2_loss: 0.0551 - out_4_loss: 0.0509\n",
      "Epoch 00018: loss did not improve from 0.10099\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.1057 - out_2_loss: 0.0550 - out_4_loss: 0.0507\n",
      "Epoch 19/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0953 - out_2_loss: 0.0499 - out_4_loss: 0.0454\n",
      "Epoch 00019: loss improved from 0.10099 to 0.09515, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0951 - out_2_loss: 0.0498 - out_4_loss: 0.0453\n",
      "Epoch 20/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0921 - out_2_loss: 0.0485 - out_4_loss: 0.0436\n",
      "Epoch 00020: loss improved from 0.09515 to 0.09197, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0920 - out_2_loss: 0.0485 - out_4_loss: 0.0435\n",
      "Epoch 21/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0894 - out_2_loss: 0.0471 - out_4_loss: 0.0423\n",
      "Epoch 00021: loss improved from 0.09197 to 0.08965, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0896 - out_2_loss: 0.0472 - out_4_loss: 0.0424\n",
      "Epoch 22/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0879 - out_2_loss: 0.0464 - out_4_loss: 0.0415\n",
      "Epoch 00022: loss improved from 0.08965 to 0.08792, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0879 - out_2_loss: 0.0464 - out_4_loss: 0.0415\n",
      "Epoch 23/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0846 - out_2_loss: 0.0449 - out_4_loss: 0.0397\n",
      "Epoch 00023: loss improved from 0.08792 to 0.08450, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0845 - out_2_loss: 0.0448 - out_4_loss: 0.0397\n",
      "Epoch 24/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0879 - out_2_loss: 0.0464 - out_4_loss: 0.0416\n",
      "Epoch 00024: loss did not improve from 0.08450\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0879 - out_2_loss: 0.0463 - out_4_loss: 0.0415\n",
      "Epoch 25/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0862 - out_2_loss: 0.0455 - out_4_loss: 0.0407\n",
      "Epoch 00025: loss did not improve from 0.08450\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0863 - out_2_loss: 0.0456 - out_4_loss: 0.0408\n",
      "Epoch 26/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0800 - out_2_loss: 0.0426 - out_4_loss: 0.0373\n",
      "Epoch 00026: loss improved from 0.08450 to 0.08007, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 59s 99ms/sample - loss: 0.0801 - out_2_loss: 0.0427 - out_4_loss: 0.0374\n",
      "Epoch 27/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0752 - out_2_loss: 0.0404 - out_4_loss: 0.0347\n",
      "Epoch 00027: loss improved from 0.08007 to 0.07530, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0753 - out_2_loss: 0.0405 - out_4_loss: 0.0348\n",
      "Epoch 28/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0750 - out_2_loss: 0.0404 - out_4_loss: 0.0346\n",
      "Epoch 00028: loss improved from 0.07530 to 0.07519, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0752 - out_2_loss: 0.0405 - out_4_loss: 0.0347\n",
      "Epoch 29/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0777 - out_2_loss: 0.0416 - out_4_loss: 0.0361\n",
      "Epoch 00029: loss did not improve from 0.07519\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0777 - out_2_loss: 0.0416 - out_4_loss: 0.0361\n",
      "Epoch 30/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0857 - out_2_loss: 0.0453 - out_4_loss: 0.0404\n",
      "Epoch 00030: loss did not improve from 0.07519\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0855 - out_2_loss: 0.0452 - out_4_loss: 0.0403\n",
      "Epoch 31/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0699 - out_2_loss: 0.0379 - out_4_loss: 0.0320\n",
      "Epoch 00031: loss improved from 0.07519 to 0.06984, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 59s 98ms/sample - loss: 0.0698 - out_2_loss: 0.0378 - out_4_loss: 0.0320\n",
      "Epoch 32/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0659 - out_2_loss: 0.0360 - out_4_loss: 0.0299\n",
      "Epoch 00032: loss improved from 0.06984 to 0.06590, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0659 - out_2_loss: 0.0360 - out_4_loss: 0.0299\n",
      "Epoch 33/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0664 - out_2_loss: 0.0362 - out_4_loss: 0.0302\n",
      "Epoch 00033: loss did not improve from 0.06590\n",
      "600/600 [==============================] - 58s 97ms/sample - loss: 0.0664 - out_2_loss: 0.0362 - out_4_loss: 0.0302\n",
      "Epoch 34/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0710 - out_2_loss: 0.0383 - out_4_loss: 0.0327\n",
      "Epoch 00034: loss did not improve from 0.06590\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0710 - out_2_loss: 0.0383 - out_4_loss: 0.0327\n",
      "Epoch 35/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0719 - out_2_loss: 0.0387 - out_4_loss: 0.0331\n",
      "Epoch 00035: loss did not improve from 0.06590\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0718 - out_2_loss: 0.0387 - out_4_loss: 0.0331\n",
      "Epoch 36/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0618 - out_2_loss: 0.0341 - out_4_loss: 0.0277\n",
      "Epoch 00036: loss improved from 0.06590 to 0.06178, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0618 - out_2_loss: 0.0341 - out_4_loss: 0.0277\n",
      "Epoch 37/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0582 - out_2_loss: 0.0324 - out_4_loss: 0.0258\n",
      "Epoch 00037: loss improved from 0.06178 to 0.05856, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0586 - out_2_loss: 0.0326 - out_4_loss: 0.0259\n",
      "Epoch 38/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0563 - out_2_loss: 0.0316 - out_4_loss: 0.0247\n",
      "Epoch 00038: loss improved from 0.05856 to 0.05643, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0564 - out_2_loss: 0.0316 - out_4_loss: 0.0248\n",
      "Epoch 39/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0567 - out_2_loss: 0.0318 - out_4_loss: 0.0250\n",
      "Epoch 00039: loss did not improve from 0.05643\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0567 - out_2_loss: 0.0317 - out_4_loss: 0.0250\n",
      "Epoch 40/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0537 - out_2_loss: 0.0304 - out_4_loss: 0.0233\n",
      "Epoch 00040: loss improved from 0.05643 to 0.05392, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0539 - out_2_loss: 0.0305 - out_4_loss: 0.0234\n",
      "Epoch 41/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0540 - out_2_loss: 0.0305 - out_4_loss: 0.0235\n",
      "Epoch 00041: loss did not improve from 0.05392\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0541 - out_2_loss: 0.0306 - out_4_loss: 0.0235\n",
      "Epoch 42/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0535 - out_2_loss: 0.0303 - out_4_loss: 0.0232\n",
      "Epoch 00042: loss improved from 0.05392 to 0.05343, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0534 - out_2_loss: 0.0302 - out_4_loss: 0.0232\n",
      "Epoch 43/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0519 - out_2_loss: 0.0296 - out_4_loss: 0.0223\n",
      "Epoch 00043: loss improved from 0.05343 to 0.05185, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0518 - out_2_loss: 0.0296 - out_4_loss: 0.0223\n",
      "Epoch 44/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0497 - out_2_loss: 0.0287 - out_4_loss: 0.0211\n",
      "Epoch 00044: loss improved from 0.05185 to 0.04972, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0497 - out_2_loss: 0.0286 - out_4_loss: 0.0211\n",
      "Epoch 45/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0501 - out_2_loss: 0.0287 - out_4_loss: 0.0214\n",
      "Epoch 00045: loss did not improve from 0.04972\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0502 - out_2_loss: 0.0288 - out_4_loss: 0.0215\n",
      "Epoch 46/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0488 - out_2_loss: 0.0282 - out_4_loss: 0.0206\n",
      "Epoch 00046: loss improved from 0.04972 to 0.04873, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0487 - out_2_loss: 0.0282 - out_4_loss: 0.0205\n",
      "Epoch 47/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0475 - out_2_loss: 0.0276 - out_4_loss: 0.0198\n",
      "Epoch 00047: loss improved from 0.04873 to 0.04747, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0475 - out_2_loss: 0.0276 - out_4_loss: 0.0198\n",
      "Epoch 48/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0494 - out_2_loss: 0.0284 - out_4_loss: 0.0210\n",
      "Epoch 00048: loss did not improve from 0.04747\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0494 - out_2_loss: 0.0284 - out_4_loss: 0.0210\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/600 [============================>.] - ETA: 0s - loss: 0.0460 - out_2_loss: 0.0270 - out_4_loss: 0.0191\n",
      "Epoch 00049: loss improved from 0.04747 to 0.04621, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0462 - out_2_loss: 0.0271 - out_4_loss: 0.0192\n",
      "Epoch 50/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0474 - out_2_loss: 0.0275 - out_4_loss: 0.0199\n",
      "Epoch 00050: loss did not improve from 0.04621\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0475 - out_2_loss: 0.0275 - out_4_loss: 0.0200\n",
      "Epoch 51/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0468 - out_2_loss: 0.0273 - out_4_loss: 0.0195\n",
      "Epoch 00051: loss did not improve from 0.04621\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0468 - out_2_loss: 0.0273 - out_4_loss: 0.0195\n",
      "Epoch 52/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0451 - out_2_loss: 0.0266 - out_4_loss: 0.0185\n",
      "Epoch 00052: loss improved from 0.04621 to 0.04514, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0451 - out_2_loss: 0.0266 - out_4_loss: 0.0185\n",
      "Epoch 53/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0609 - out_2_loss: 0.0336 - out_4_loss: 0.0273\n",
      "Epoch 00053: loss did not improve from 0.04514\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0608 - out_2_loss: 0.0335 - out_4_loss: 0.0273\n",
      "Epoch 54/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0449 - out_2_loss: 0.0265 - out_4_loss: 0.0184\n",
      "Epoch 00054: loss improved from 0.04514 to 0.04485, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0448 - out_2_loss: 0.0264 - out_4_loss: 0.0184\n",
      "Epoch 55/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0416 - out_2_loss: 0.0251 - out_4_loss: 0.0165\n",
      "Epoch 00055: loss improved from 0.04485 to 0.04153, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0415 - out_2_loss: 0.0251 - out_4_loss: 0.0165\n",
      "Epoch 56/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0402 - out_2_loss: 0.0245 - out_4_loss: 0.0157\n",
      "Epoch 00056: loss improved from 0.04153 to 0.04018, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0402 - out_2_loss: 0.0245 - out_4_loss: 0.0157\n",
      "Epoch 57/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0395 - out_2_loss: 0.0242 - out_4_loss: 0.0153\n",
      "Epoch 00057: loss improved from 0.04018 to 0.03949, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0395 - out_2_loss: 0.0242 - out_4_loss: 0.0153\n",
      "Epoch 58/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0391 - out_2_loss: 0.0240 - out_4_loss: 0.0151\n",
      "Epoch 00058: loss improved from 0.03949 to 0.03912, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0391 - out_2_loss: 0.0240 - out_4_loss: 0.0151\n",
      "Epoch 59/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0398 - out_2_loss: 0.0243 - out_4_loss: 0.0155\n",
      "Epoch 00059: loss did not improve from 0.03912\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0398 - out_2_loss: 0.0243 - out_4_loss: 0.0155\n",
      "Epoch 60/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0390 - out_2_loss: 0.0240 - out_4_loss: 0.0150\n",
      "Epoch 00060: loss improved from 0.03912 to 0.03902, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0390 - out_2_loss: 0.0240 - out_4_loss: 0.0150\n",
      "Epoch 61/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0406 - out_2_loss: 0.0247 - out_4_loss: 0.0159\n",
      "Epoch 00061: loss did not improve from 0.03902\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0406 - out_2_loss: 0.0247 - out_4_loss: 0.0159\n",
      "Epoch 62/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0393 - out_2_loss: 0.0241 - out_4_loss: 0.0152\n",
      "Epoch 00062: loss did not improve from 0.03902\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0393 - out_2_loss: 0.0241 - out_4_loss: 0.0152\n",
      "Epoch 63/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0387 - out_2_loss: 0.0239 - out_4_loss: 0.0149\n",
      "Epoch 00063: loss improved from 0.03902 to 0.03871, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0387 - out_2_loss: 0.0239 - out_4_loss: 0.0149\n",
      "Epoch 64/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0378 - out_2_loss: 0.0235 - out_4_loss: 0.0143\n",
      "Epoch 00064: loss improved from 0.03871 to 0.03786, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0379 - out_2_loss: 0.0235 - out_4_loss: 0.0143\n",
      "Epoch 65/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0387 - out_2_loss: 0.0238 - out_4_loss: 0.0148\n",
      "Epoch 00065: loss did not improve from 0.03786\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0387 - out_2_loss: 0.0239 - out_4_loss: 0.0149\n",
      "Epoch 66/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0393 - out_2_loss: 0.0241 - out_4_loss: 0.0151\n",
      "Epoch 00066: loss did not improve from 0.03786\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0393 - out_2_loss: 0.0241 - out_4_loss: 0.0152\n",
      "Epoch 67/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0381 - out_2_loss: 0.0236 - out_4_loss: 0.0144\n",
      "Epoch 00067: loss did not improve from 0.03786\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0381 - out_2_loss: 0.0236 - out_4_loss: 0.0145\n",
      "Epoch 68/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0386 - out_2_loss: 0.0238 - out_4_loss: 0.0148\n",
      "Epoch 00068: loss did not improve from 0.03786\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0385 - out_2_loss: 0.0238 - out_4_loss: 0.0148\n",
      "Epoch 69/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0378 - out_2_loss: 0.0236 - out_4_loss: 0.0142\n",
      "Epoch 00069: loss improved from 0.03786 to 0.03777, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0378 - out_2_loss: 0.0235 - out_4_loss: 0.0142\n",
      "Epoch 70/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0418 - out_2_loss: 0.0253 - out_4_loss: 0.0165\n",
      "Epoch 00070: loss did not improve from 0.03777\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0418 - out_2_loss: 0.0253 - out_4_loss: 0.0165\n",
      "Epoch 71/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0415 - out_2_loss: 0.0249 - out_4_loss: 0.0165\n",
      "Epoch 00071: loss did not improve from 0.03777\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0415 - out_2_loss: 0.0249 - out_4_loss: 0.0165\n",
      "Epoch 72/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0383 - out_2_loss: 0.0237 - out_4_loss: 0.0147\n",
      "Epoch 00072: loss did not improve from 0.03777\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0383 - out_2_loss: 0.0237 - out_4_loss: 0.0146\n",
      "Epoch 73/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0369 - out_2_loss: 0.0232 - out_4_loss: 0.0137\n",
      "Epoch 00073: loss improved from 0.03777 to 0.03686, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0369 - out_2_loss: 0.0232 - out_4_loss: 0.0137\n",
      "Epoch 74/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0375 - out_2_loss: 0.0235 - out_4_loss: 0.0140\n",
      "Epoch 00074: loss did not improve from 0.03686\n",
      "600/600 [==============================] - 58s 96ms/sample - loss: 0.0375 - out_2_loss: 0.0235 - out_4_loss: 0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0385 - out_2_loss: 0.0238 - out_4_loss: 0.0148\n",
      "Epoch 00075: loss did not improve from 0.03686\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0385 - out_2_loss: 0.0238 - out_4_loss: 0.0147\n",
      "Epoch 76/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0357 - out_2_loss: 0.0228 - out_4_loss: 0.0130\n",
      "Epoch 00076: loss improved from 0.03686 to 0.03572, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0357 - out_2_loss: 0.0228 - out_4_loss: 0.0130\n",
      "Epoch 77/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0355 - out_2_loss: 0.0226 - out_4_loss: 0.0128\n",
      "Epoch 00077: loss improved from 0.03572 to 0.03545, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0354 - out_2_loss: 0.0226 - out_4_loss: 0.0128\n",
      "Epoch 78/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0348 - out_2_loss: 0.0224 - out_4_loss: 0.0124\n",
      "Epoch 00078: loss improved from 0.03545 to 0.03477, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0348 - out_2_loss: 0.0224 - out_4_loss: 0.0124\n",
      "Epoch 79/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0352 - out_2_loss: 0.0225 - out_4_loss: 0.0127\n",
      "Epoch 00079: loss did not improve from 0.03477\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0352 - out_2_loss: 0.0226 - out_4_loss: 0.0127\n",
      "Epoch 80/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0353 - out_2_loss: 0.0226 - out_4_loss: 0.0127\n",
      "Epoch 00080: loss did not improve from 0.03477\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0354 - out_2_loss: 0.0226 - out_4_loss: 0.0128\n",
      "Epoch 81/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0351 - out_2_loss: 0.0225 - out_4_loss: 0.0126\n",
      "Epoch 00081: loss did not improve from 0.03477\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0352 - out_2_loss: 0.0225 - out_4_loss: 0.0126\n",
      "Epoch 82/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0362 - out_2_loss: 0.0229 - out_4_loss: 0.0133\n",
      "Epoch 00082: loss did not improve from 0.03477\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0362 - out_2_loss: 0.0229 - out_4_loss: 0.0133\n",
      "Epoch 83/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0350 - out_2_loss: 0.0225 - out_4_loss: 0.0125\n",
      "Epoch 00083: loss did not improve from 0.03477\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0350 - out_2_loss: 0.0225 - out_4_loss: 0.0125\n",
      "Epoch 84/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0348 - out_2_loss: 0.0224 - out_4_loss: 0.0124\n",
      "Epoch 00084: loss did not improve from 0.03477\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0348 - out_2_loss: 0.0224 - out_4_loss: 0.0124\n",
      "Epoch 85/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0344 - out_2_loss: 0.0223 - out_4_loss: 0.0121\n",
      "Epoch 00085: loss improved from 0.03477 to 0.03440, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 94ms/sample - loss: 0.0344 - out_2_loss: 0.0223 - out_4_loss: 0.0121\n",
      "Epoch 86/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0344 - out_2_loss: 0.0223 - out_4_loss: 0.0122\n",
      "Epoch 00086: loss did not improve from 0.03440\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0345 - out_2_loss: 0.0223 - out_4_loss: 0.0122\n",
      "Epoch 87/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0347 - out_2_loss: 0.0223 - out_4_loss: 0.0124\n",
      "Epoch 00087: loss did not improve from 0.03440\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0347 - out_2_loss: 0.0224 - out_4_loss: 0.0124\n",
      "Epoch 88/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0352 - out_2_loss: 0.0226 - out_4_loss: 0.0126\n",
      "Epoch 00088: loss did not improve from 0.03440\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0352 - out_2_loss: 0.0226 - out_4_loss: 0.0126\n",
      "Epoch 89/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0345 - out_2_loss: 0.0224 - out_4_loss: 0.0122\n",
      "Epoch 00089: loss did not improve from 0.03440\n",
      "600/600 [==============================] - 55s 92ms/sample - loss: 0.0345 - out_2_loss: 0.0223 - out_4_loss: 0.0122\n",
      "Epoch 90/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0367 - out_2_loss: 0.0232 - out_4_loss: 0.0135\n",
      "Epoch 00090: loss did not improve from 0.03440\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0367 - out_2_loss: 0.0232 - out_4_loss: 0.0135\n",
      "Epoch 91/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0351 - out_2_loss: 0.0225 - out_4_loss: 0.0126\n",
      "Epoch 00091: loss did not improve from 0.03440\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0351 - out_2_loss: 0.0225 - out_4_loss: 0.0126\n",
      "Epoch 92/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0473 - out_2_loss: 0.0280 - out_4_loss: 0.0193\n",
      "Epoch 00092: loss did not improve from 0.03440\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0474 - out_2_loss: 0.0281 - out_4_loss: 0.0193\n",
      "Epoch 93/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0469 - out_2_loss: 0.0275 - out_4_loss: 0.0194\n",
      "Epoch 00093: loss did not improve from 0.03440\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0468 - out_2_loss: 0.0274 - out_4_loss: 0.0194\n",
      "Epoch 94/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0359 - out_2_loss: 0.0228 - out_4_loss: 0.0131\n",
      "Epoch 00094: loss did not improve from 0.03440\n",
      "600/600 [==============================] - 56s 94ms/sample - loss: 0.0359 - out_2_loss: 0.0228 - out_4_loss: 0.0131\n",
      "Epoch 95/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0333 - out_2_loss: 0.0219 - out_4_loss: 0.0114\n",
      "Epoch 00095: loss improved from 0.03440 to 0.03334, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0333 - out_2_loss: 0.0219 - out_4_loss: 0.0114\n",
      "Epoch 96/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0319 - out_2_loss: 0.0215 - out_4_loss: 0.0104\n",
      "Epoch 00096: loss improved from 0.03334 to 0.03186, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0319 - out_2_loss: 0.0215 - out_4_loss: 0.0104\n",
      "Epoch 97/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0314 - out_2_loss: 0.0213 - out_4_loss: 0.0101\n",
      "Epoch 00097: loss improved from 0.03186 to 0.03144, saving model to ../../result/model_save/CV/A2C_A4C_Deep_MVAU_Net_CV_4.h5\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0314 - out_2_loss: 0.0213 - out_4_loss: 0.0101\n",
      "Epoch 98/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0319 - out_2_loss: 0.0214 - out_4_loss: 0.0104\n",
      "Epoch 00098: loss did not improve from 0.03144\n",
      "600/600 [==============================] - 56s 93ms/sample - loss: 0.0319 - out_2_loss: 0.0214 - out_4_loss: 0.0104\n",
      "Epoch 99/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0317 - out_2_loss: 0.0214 - out_4_loss: 0.0104\n",
      "Epoch 00099: loss did not improve from 0.03144\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0317 - out_2_loss: 0.0214 - out_4_loss: 0.0104\n",
      "Epoch 100/100\n",
      "596/600 [============================>.] - ETA: 0s - loss: 0.0319 - out_2_loss: 0.0214 - out_4_loss: 0.0105\n",
      "Epoch 00100: loss did not improve from 0.03144\n",
      "600/600 [==============================] - 57s 95ms/sample - loss: 0.0319 - out_2_loss: 0.0214 - out_4_loss: 0.0105\n"
     ]
    }
   ],
   "source": [
    "print('Fitting model...')\n",
    "print('-'*200)\n",
    "hist = MVAU_Net.fit(train_image, [train_label, train_label], batch_size=4, epochs=100, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:59:28.208346Z",
     "start_time": "2021-12-07T07:59:19.381319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 8s 40ms/sample\n"
     ]
    }
   ],
   "source": [
    "a2c_a4c_pred_2, a2c_a4c_pred_4 = MVAU_Net.predict(validation_image, verbose=1)\n",
    "a2c_a4c_pred_4 = np.array(a2c_a4c_pred_4 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:59:18.848934Z",
     "start_time": "2021-12-07T07:59:14.343762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 4s 41ms/sample\n"
     ]
    }
   ],
   "source": [
    "_, test_prediction = MVAU_Net.predict(test_image, verbose=1)\n",
    "test_prediction = np.array(test_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:59:29.323955Z",
     "start_time": "2021-12-07T07:59:28.387661Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('../../result/CV/CV_4_valid_prediction.npy', a2c_a4c_pred_4)\n",
    "np.save('../../result/CV/CV_4_test_prediction.npy', test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:49:30.759860Z",
     "start_time": "2021-12-07T07:49:25.616705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall    :  0.941  0.048\n",
      "Precision :  0.929  0.112\n",
      "Accuracy  :  0.994  0.006\n",
      "DSC       :  0.929  0.069\n",
      "Jaccard   :  0.874  0.103\n"
     ]
    }
   ],
   "source": [
    "a2c_a4c_pred_2 = np.array(a2c_a4c_pred_2 > 0.5)\n",
    "a2c_a4c_pred_4 = np.array(a2c_a4c_pred_4 > 0.5)\n",
    "\n",
    "recall_list = []\n",
    "pricision_list = []\n",
    "acc_list = []\n",
    "dice_list = []\n",
    "jaccard_list = []\n",
    "\n",
    "\n",
    "for i in range(test_label.shape[0]):\n",
    "    \n",
    "    seg1 = a2c_a4c_pred_4[i,:,:,0,0]\n",
    "    gt1 = validation_label[i,:,:,0,0]\n",
    "\n",
    "    seg1_n = seg1 == 0\n",
    "    seg1_t = seg1 == 1\n",
    "\n",
    "    gt1_n = gt1 == 0\n",
    "    gt1_t = gt1 == 1\n",
    "\n",
    "\n",
    "    tp = np.sum(seg1_t&gt1_t)\n",
    "\n",
    "    fp = np.sum(seg1_t&gt1_n)\n",
    "\n",
    "    tn = np.sum(seg1_n&gt1_n)\n",
    "\n",
    "    fn = np.sum(gt1_t&seg1_n)\n",
    "\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "#     print('Sensitivity : ', sensitivity)\n",
    "\n",
    "\n",
    "    pricision = tp / (tp+fp)\n",
    "    pricision_list.append(pricision)\n",
    "\n",
    "#     print('Specificity : ', specificity)\n",
    "\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    acc_list.append(acc)\n",
    "#     print('Accuracy : ', acc)\n",
    "\n",
    "    dice = (2*tp) / (2*tp + fp + fn)\n",
    "    dice_list.append(dice)\n",
    "#     print('DSC : ', dice)\n",
    "    \n",
    "    jaccard_list.append(jaccard_score(gt1, seg1, average='micro'))\n",
    "    \n",
    "    \n",
    "dice_list_1 = np.array(dice_list)\n",
    "recall_list_1 = np.array(recall_list)\n",
    "pricision_list_1 = np.array(pricision_list)\n",
    "jaccard_list_1 = np.array(jaccard_list)\n",
    "\n",
    "dice_list_1 = dice_list_1[~np.isnan(dice_list_1)]\n",
    "recall_list_1 = recall_list_1[~np.isnan(recall_list_1)]\n",
    "pricision_list_1 = pricision_list_1[~np.isnan(pricision_list_1)]\n",
    "jaccard_list_1 = jaccard_list_1[~np.isnan(jaccard_list_1)]\n",
    "\n",
    "print('Recall    : ', round(np.mean(recall_list_1), 3), '', round(np.std(recall_list_1), 3))\n",
    "print('Precision : ', round( np.mean(pricision_list_1), 3), '', round( np.std(pricision_list_1), 3))\n",
    "print('Accuracy  : ', round(np.mean(acc_list), 3), '', round( np.std(acc_list), 3))\n",
    "print('DSC       : ', round(np.mean(dice_list_1), 3), '', round( np.std(dice_list_1), 3))\n",
    "print('Jaccard   : ', round(np.mean(jaccard_list_1), 3), '', round( np.std(jaccard_list_1), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:54:50.223666Z",
     "start_time": "2021-12-07T07:54:43.161533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall    :  0.955  0.033\n",
      "Precision :  0.965  0.039\n",
      "Accuracy  :  0.996  0.002\n",
      "DSC       :  0.959  0.021\n",
      "Jaccard   :  0.922  0.038\n"
     ]
    }
   ],
   "source": [
    "recall_list = []\n",
    "pricision_list = []\n",
    "acc_list = []\n",
    "dice_list = []\n",
    "jaccard_list = []\n",
    "\n",
    "\n",
    "for i in range(validation_label.shape[0]):\n",
    "    \n",
    "    seg1 = a2c_a4c_pred_4[i,:,:,0,1]\n",
    "    gt1 = validation_label[i,:,:,0,1]\n",
    "\n",
    "    seg1_n = seg1 == 0\n",
    "    seg1_t = seg1 == 1\n",
    "\n",
    "    gt1_n = gt1 == 0\n",
    "    gt1_t = gt1 == 1\n",
    "\n",
    "\n",
    "    tp = np.sum(seg1_t&gt1_t)\n",
    "\n",
    "    fp = np.sum(seg1_t&gt1_n)\n",
    "\n",
    "    tn = np.sum(seg1_n&gt1_n)\n",
    "\n",
    "    fn = np.sum(gt1_t&seg1_n)\n",
    "\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "#     print('Sensitivity : ', sensitivity)\n",
    "\n",
    "\n",
    "    pricision = tp / (tp+fp)\n",
    "    pricision_list.append(pricision)\n",
    "\n",
    "#     print('Specificity : ', specificity)\n",
    "\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    acc_list.append(acc)\n",
    "#     print('Accuracy : ', acc)\n",
    "\n",
    "    dice = (2*tp) / (2*tp + fp + fn)\n",
    "    dice_list.append(dice)\n",
    "#     print('DSC : ', dice)\n",
    "    \n",
    "    jaccard_list.append(jaccard_score(gt1, seg1, average='micro'))\n",
    "    \n",
    "    \n",
    "dice_list_1 = np.array(dice_list)\n",
    "recall_list_1 = np.array(recall_list)\n",
    "pricision_list_1 = np.array(pricision_list)\n",
    "jaccard_list_1 = np.array(jaccard_list)\n",
    "\n",
    "dice_list_1 = dice_list_1[~np.isnan(dice_list_1)]\n",
    "recall_list_1 = recall_list_1[~np.isnan(recall_list_1)]\n",
    "pricision_list_1 = pricision_list_1[~np.isnan(pricision_list_1)]\n",
    "jaccard_list_1 = jaccard_list_1[~np.isnan(jaccard_list_1)]\n",
    "\n",
    "print('Recall    : ', round(np.mean(recall_list_1), 3), '', round(np.std(recall_list_1), 3))\n",
    "print('Precision : ', round( np.mean(pricision_list_1), 3), '', round( np.std(pricision_list_1), 3))\n",
    "print('Accuracy  : ', round(np.mean(acc_list), 3), '', round( np.std(acc_list), 3))\n",
    "print('DSC       : ', round(np.mean(dice_list_1), 3), '', round( np.std(dice_list_1), 3))\n",
    "print('Jaccard   : ', round(np.mean(jaccard_list_1), 3), '', round( np.std(jaccard_list_1), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:49:49.298044Z",
     "start_time": "2021-12-07T07:49:34.289608Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sl in range(20):\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(test_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(test_label[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(test_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.imshow(test_label[sl,:,:,:,0], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(test_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.imshow(test_image[sl,:,:,:,0], cmap='gray')\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,0], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T07:50:04.531706Z",
     "start_time": "2021-12-07T07:49:49.299654Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sl in range(20):\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(test_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(test_label[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(test_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.imshow(test_label[sl,:,:,:,1], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(test_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.imshow(test_image[sl,:,:,:,1], cmap='gray')\n",
    "    plt.imshow(a2c_a4c_pred_4[sl,:,:,:,1], cmap='Reds', alpha=0.25)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
